2024-01-31 09:44:13,685 - train - INFO - aa: rand-m9-mstd0.5-inc1
amp: true
apex_amp: false
aq_asym: false
aq_bitw: null
aq_enable: false
aq_mode: lsq
aq_neg: null
aq_pos: null
as_enable: false
as_mode: Identity
as_patterns: '1:1'
aug_splits: 0
batch_size: 256
bn_eps: null
bn_momentum: null
bn_tf: false
channels_last: false
checkpoint_hist: 5
clip_grad: null
clip_mode: norm
color_jitter: 0.4
cooldown_epochs: 10
crop_pct: 1.0
cutmix: 1.0
cutmix_minmax: null
data_dir: /home/xts/code/dataset/cifar10
dataset: torch/cifar10
decay_epochs: 30
decay_rate: 0.1
dist_bn: ''
distributed: false
down_block_type: default
drop: 0.0
drop_block: null
drop_connect: null
drop_path: null
epoch_repeats: 0.0
epochs: 150
eval_metric: top1
experiment: ''
finetune: true
gp: null
hflip: 0.5
img_size: 32
initial_checkpoint: /home/xts/code/njeans/MySparsity/Ternary-ViT/output/train/20240130-151816-pretrain_cifar_cir_nas_mobilenetv2-32/model_best.pth.tar
input_size: null
interpolation: bicubic
jsd: false
kd_alpha: 4
kd_type: last
lasso_alpha: 3.0e-05
local_rank: 0
log_interval: 50
log_wandb: false
lr: 0.00055
lr_cycle_limit: 1
lr_cycle_mul: 1.0
lr_noise: null
lr_noise_pct: 0.67
lr_noise_std: 1.0
mean:
- 0.4914
- 0.4822
- 0.4465
min_lr: 1.0e-05
mixup: 0.8
mixup_mode: batch
mixup_off_epoch: 175
mixup_prob: 1.0
mixup_switch_prob: 0.5
model: cifar_cir_nas_mobilenetv2
model_ema: false
model_ema_decay: 0.9998
model_ema_force_cpu: false
momentum: 0.9
native_amp: false
no_aug: false
no_bn: false
no_prefetcher: false
no_resume_opt: false
num_classes: 10
opt: adamw
opt_betas: null
opt_eps: null
output: ''
patience_epochs: 10
pin_mem: false
post_res_bn: false
pretrain: false
pretrained: false
qmodules: []
quant_teacher: false
ratio:
- 0.75
- 1.3333333333333333
recount: 1
recovery_interval: 0
remode: pixel
replace_ln_by_bn: false
replace_relu: false
reprob: 0.25
resplit: false
resq_asym: false
resq_bitw: null
resq_enable: false
resq_mode: lsq
resq_modules: []
resq_neg: null
resq_pos: null
resume: ''
save_images: false
scale:
- 0.8
- 1.0
sched: cosine
seed: 3407
smoothing: 0.1
split_bn: false
start_epoch: null
std:
- 0.247
- 0.2435
- 0.2616
sync_bn: false
teacher: pretrain_cifar_cir_nas_mobilenetv2
teacher_checkpoint: /home/xts/code/njeans/MySparsity/Ternary-ViT/output/train/20240130-151816-pretrain_cifar_cir_nas_mobilenetv2-32/model_best.pth.tar
torchscript: false
train_interpolation: random
train_split: train
tta: 0
use_bn: true
use_distill_head: false
use_dual_skip: false
use_kd: true
use_layer_scale: false
use_multi_epochs_loader: false
use_relu: false
use_skip: false
use_token_kd: false
val_split: validation
validation_batch_size_multiplier: 1
vflip: 0.0
warmup_epochs: 0
warmup_lr: 1.0e-05
weight_decay: 0.06
workers: 32
wq_asym: false
wq_bitw: null
wq_enable: false
wq_mode: LSQ
wq_neg: null
wq_per_channel: false
wq_pos: null
ws_enable: false
ws_mode: Identity
ws_patterns: '1:1'

2024-01-31 09:44:13,686 - train - INFO - Training with a single process on 1 GPUs.
2024-01-31 09:44:14,568 - train - INFO - Model CirNasMobileNetV2(
  (features): Sequential(
    (0): Sequential(
      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
    )
    (1): CirNasInvertedResidual(
      (conv): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (7): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (8): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (9): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (10): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (11): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (12): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (13): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (14): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)
        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (15): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (16): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (17): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (18): Sequential(
      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
    )
  )
  (classifier): Sequential(
    (0): Dropout(p=0.2, inplace=False)
    (1): Linear(in_features=1280, out_features=10, bias=True)
  )
)
pretrain: False
fine-tune: False
2024-01-31 09:44:15,424 - train - INFO - Model cifar_cir_nas_mobilenetv2 created, param count:2236824
2024-01-31 09:44:15,438 - train - INFO - Using native Torch AMP. Training in mixed precision.
2024-01-31 09:44:15,438 - train - INFO - Scheduled epochs: 160
2024-01-31 09:44:16,640 - train - INFO - Trainer transform: Compose(
    RandomResizedCropAndInterpolation(size=(32, 32), scale=(0.8, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear bicubic)
    RandomHorizontalFlip(p=0.5)
    RandAugment(n=2, ops=
	AugmentOp(name=AutoContrast, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=Equalize, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=Invert, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=Rotate, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=PosterizeIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=SolarizeIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=SolarizeAdd, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ColorIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ContrastIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=BrightnessIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=SharpnessIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ShearX, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ShearY, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=TranslateXRel, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=TranslateYRel, p=0.5, m=9, mstd=0.5))
    <timm.data.transforms.ToNumpy object at 0x7efb15041bb0>
)
2024-01-31 09:44:16,640 - train - INFO - Validate transform: Compose(
    Resize(size=32, interpolation=bicubic, max_size=None, antialias=warn)
    CenterCrop(size=(32, 32))
    <timm.data.transforms.ToNumpy object at 0x7efb150416d0>
)
2024-01-31 09:44:16,641 - train - INFO - Train loss CrossEntropyLoss()
2024-01-31 09:44:16,641 - train - INFO - Verifying teacher model
2024-01-31 09:44:18,025 - train - INFO - Test: [   0/39]  Time: 1.383 (1.383s) Loss:  0.3721 (0.3721)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)
2024-01-31 09:44:18,717 - train - INFO - Test: [  39/39]  Time: 0.407 (2.076s) Loss:  0.4370 (0.3827)  Acc@1: 93.7500 (94.7700)  Acc@5: 100.0000 (99.8400)
2024-01-31 09:44:18,718 - train - INFO - Verifying initial model
2024-01-31 09:44:19,920 - train - INFO - Test: [   0/39]  Time: 1.201 (1.201s) Loss:  3.0508 (3.0508)  Acc@1:  8.9844 ( 8.9844)  Acc@5: 48.8281 (48.8281)
2024-01-31 09:45:11,446 - train - INFO - Test: [  39/39]  Time: 1.430 (52.727s) Loss:  2.7207 (2.9992)  Acc@1: 18.7500 (10.0000)  Acc@5: 50.0000 (50.0000)
2024-01-31 09:45:15,301 - train - INFO - Train: 0 [   0/195 (  0%)]  Loss:  2.150956 (2.1510)  Time: 3.847s (3.847s),   66.55/s  (3.847s,   66.55/s)  LR: 5.500e-04  Data: 0.976 (0.976)
2024-01-31 09:46:41,736 - train - INFO - Train: 0 [  50/195 ( 26%)]  Loss:  1.763748 (1.7794)  Time: 1.636s (90.279s),  156.48/s  (1.770s,  144.62/s)  LR: 5.500e-04  Data: 0.006 (0.026)
2024-01-31 09:48:09,091 - train - INFO - Train: 0 [ 100/195 ( 52%)]  Loss:  1.563580 (1.7004)  Time: 1.724s (177.631s),  148.49/s  (1.759s,  145.56/s)  LR: 5.500e-04  Data: 0.005 (0.017)
2024-01-31 09:49:34,029 - train - INFO - Train: 0 [ 150/195 ( 77%)]  Loss:  1.788524 (1.6709)  Time: 1.454s (262.568s),  176.12/s  (1.739s,  147.22/s)  LR: 5.500e-04  Data: 0.006 (0.014)
2024-01-31 09:50:50,177 - train - INFO - Train: 0 [ 194/195 (100%)]  Loss:  1.410563 (1.6447)  Time: 2.352s (338.714s),  108.86/s  (1.737s,  147.38/s)  LR: 5.500e-04  Data: 0.000 (0.012)
2024-01-31 09:50:50,233 - train - INFO - alphas:tensor([0.3576, 0.3236, 0.3188], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,234 - train - INFO - alphas:tensor([0.3595, 0.3193, 0.3212], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,234 - train - INFO - alphas:tensor([0.3621, 0.3205, 0.3174], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,235 - train - INFO - alphas:tensor([0.3568, 0.3231, 0.3202], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,236 - train - INFO - alphas:tensor([0.3598, 0.3201, 0.3201], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,237 - train - INFO - alphas:tensor([0.2160, 0.2015, 0.1922, 0.1940, 0.1963], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,237 - train - INFO - alphas:tensor([0.3611, 0.3207, 0.3182], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,238 - train - INFO - alphas:tensor([0.3588, 0.3215, 0.3197], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,239 - train - INFO - alphas:tensor([0.3608, 0.3189, 0.3203], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,240 - train - INFO - alphas:tensor([0.3575, 0.3225, 0.3200], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,240 - train - INFO - alphas:tensor([0.2195, 0.2037, 0.1911, 0.1917, 0.1940], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,241 - train - INFO - alphas:tensor([0.2177, 0.2021, 0.1926, 0.1931, 0.1945], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,242 - train - INFO - alphas:tensor([0.2196, 0.2036, 0.1922, 0.1911, 0.1936], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,243 - train - INFO - alphas:tensor([0.2199, 0.1995, 0.1898, 0.1924, 0.1985], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,244 - train - INFO - alphas:tensor([0.2214, 0.2015, 0.1900, 0.1915, 0.1955], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,245 - train - INFO - alphas:tensor([0.2188, 0.2020, 0.1894, 0.1928, 0.1970], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,245 - train - INFO - alphas:tensor([0.2201, 0.2011, 0.1916, 0.1924, 0.1948], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,246 - train - INFO - alphas:tensor([0.2174, 0.2009, 0.1901, 0.1918, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,247 - train - INFO - alphas:tensor([0.2232, 0.1995, 0.1913, 0.1917, 0.1943], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,248 - train - INFO - alphas:tensor([0.2219, 0.1999, 0.1913, 0.1925, 0.1944], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,249 - train - INFO - alphas:tensor([0.2229, 0.2011, 0.1906, 0.1914, 0.1940], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,250 - train - INFO - alphas:tensor([0.2204, 0.1993, 0.1914, 0.1935, 0.1954], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,250 - train - INFO - alphas:tensor([0.2233, 0.2003, 0.1903, 0.1919, 0.1942], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,251 - train - INFO - alphas:tensor([0.2208, 0.2000, 0.1909, 0.1917, 0.1966], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,252 - train - INFO - alphas:tensor([0.2228, 0.2002, 0.1910, 0.1917, 0.1943], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,253 - train - INFO - alphas:tensor([0.2219, 0.2005, 0.1916, 0.1918, 0.1942], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,254 - train - INFO - alphas:tensor([0.2221, 0.1995, 0.1911, 0.1919, 0.1954], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,255 - train - INFO - alphas:tensor([0.2215, 0.1991, 0.1906, 0.1922, 0.1966], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,256 - train - INFO - alphas:tensor([0.2242, 0.2032, 0.1891, 0.1906, 0.1929], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,256 - train - INFO - alphas:tensor([0.2176, 0.1979, 0.1909, 0.1919, 0.2016], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,257 - train - INFO - alphas:tensor([0.2222, 0.1995, 0.1917, 0.1926, 0.1940], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,258 - train - INFO - alphas:tensor([0.2154, 0.1985, 0.1911, 0.1922, 0.2028], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:50:50,264 - train - INFO - lasso_alpha:3e-05
2024-01-31 09:50:52,150 - train - INFO - Test: [   0/39]  Time: 1.877 (1.877s) Loss:  0.5518 (0.5518)  Acc@1: 89.8438 (89.8438)  Acc@5: 99.6094 (99.6094)
2024-01-31 09:52:06,135 - train - INFO - Test: [  39/39]  Time: 1.935 (75.862s) Loss:  0.5571 (0.5595)  Acc@1: 87.5000 (89.0100)  Acc@5: 100.0000 (99.3100)
2024-01-31 09:52:08,885 - train - INFO - Train: 1 [   0/195 (  0%)]  Loss:  1.397381 (1.3974)  Time: 2.644s (2.644s),   96.83/s  (2.644s,   96.83/s)  LR: 5.499e-04  Data: 0.293 (0.293)
2024-01-31 09:53:57,460 - train - INFO - Train: 1 [  50/195 ( 26%)]  Loss:  1.522508 (1.5312)  Time: 2.081s (111.218s),  123.04/s  (2.181s,  117.39/s)  LR: 5.499e-04  Data: 0.043 (0.015)
2024-01-31 09:55:48,453 - train - INFO - Train: 1 [ 100/195 ( 52%)]  Loss:  1.693873 (1.5201)  Time: 2.193s (222.209s),  116.74/s  (2.200s,  116.36/s)  LR: 5.499e-04  Data: 0.016 (0.012)
2024-01-31 09:57:41,994 - train - INFO - Train: 1 [ 150/195 ( 77%)]  Loss:  1.383873 (1.5094)  Time: 2.458s (335.745s),  104.13/s  (2.223s,  115.14/s)  LR: 5.499e-04  Data: 0.007 (0.011)
2024-01-31 09:59:22,593 - train - INFO - Train: 1 [ 194/195 (100%)]  Loss:  1.542737 (1.5134)  Time: 2.266s (436.342s),  112.98/s  (2.238s,  114.41/s)  LR: 5.499e-04  Data: 0.000 (0.010)
2024-01-31 09:59:22,594 - train - INFO - alphas:tensor([0.3794, 0.3122, 0.3084], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,595 - train - INFO - alphas:tensor([0.3759, 0.3105, 0.3136], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,596 - train - INFO - alphas:tensor([0.3824, 0.3103, 0.3073], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,597 - train - INFO - alphas:tensor([0.3741, 0.3155, 0.3104], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,598 - train - INFO - alphas:tensor([0.3792, 0.3108, 0.3100], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,599 - train - INFO - alphas:tensor([0.2271, 0.1994, 0.1874, 0.1914, 0.1947], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,599 - train - INFO - alphas:tensor([0.3836, 0.3091, 0.3073], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,601 - train - INFO - alphas:tensor([0.3786, 0.3110, 0.3104], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,602 - train - INFO - alphas:tensor([0.3839, 0.3079, 0.3082], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,603 - train - INFO - alphas:tensor([0.3773, 0.3106, 0.3120], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,604 - train - INFO - alphas:tensor([0.2349, 0.2019, 0.1848, 0.1869, 0.1914], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,604 - train - INFO - alphas:tensor([0.2318, 0.2000, 0.1872, 0.1888, 0.1922], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,605 - train - INFO - alphas:tensor([0.2359, 0.2016, 0.1858, 0.1859, 0.1908], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,606 - train - INFO - alphas:tensor([0.2342, 0.1979, 0.1828, 0.1873, 0.1978], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,607 - train - INFO - alphas:tensor([0.2379, 0.2009, 0.1831, 0.1857, 0.1924], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,608 - train - INFO - alphas:tensor([0.2332, 0.2004, 0.1823, 0.1872, 0.1968], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,609 - train - INFO - alphas:tensor([0.2381, 0.1980, 0.1851, 0.1870, 0.1918], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,609 - train - INFO - alphas:tensor([0.2306, 0.1992, 0.1825, 0.1868, 0.2009], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,610 - train - INFO - alphas:tensor([0.2422, 0.1956, 0.1845, 0.1863, 0.1913], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,611 - train - INFO - alphas:tensor([0.2386, 0.1983, 0.1856, 0.1874, 0.1900], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,612 - train - INFO - alphas:tensor([0.2425, 0.1988, 0.1832, 0.1850, 0.1905], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,613 - train - INFO - alphas:tensor([0.2372, 0.1976, 0.1848, 0.1880, 0.1924], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,613 - train - INFO - alphas:tensor([0.2426, 0.1967, 0.1836, 0.1864, 0.1907], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,614 - train - INFO - alphas:tensor([0.2373, 0.1969, 0.1836, 0.1863, 0.1959], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,615 - train - INFO - alphas:tensor([0.2424, 0.1968, 0.1850, 0.1862, 0.1896], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,616 - train - INFO - alphas:tensor([0.2397, 0.1987, 0.1852, 0.1858, 0.1907], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,617 - train - INFO - alphas:tensor([0.2417, 0.1980, 0.1836, 0.1850, 0.1917], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,618 - train - INFO - alphas:tensor([0.2387, 0.1941, 0.1817, 0.1863, 0.1991], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,618 - train - INFO - alphas:tensor([0.2447, 0.2004, 0.1819, 0.1845, 0.1886], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,619 - train - INFO - alphas:tensor([0.2306, 0.1936, 0.1824, 0.1868, 0.2065], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,620 - train - INFO - alphas:tensor([0.2426, 0.1970, 0.1846, 0.1861, 0.1897], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,621 - train - INFO - alphas:tensor([0.2270, 0.1964, 0.1833, 0.1867, 0.2066], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 09:59:22,621 - train - INFO - lasso_alpha:3e-05
2024-01-31 09:59:24,621 - train - INFO - Test: [   0/39]  Time: 1.992 (1.992s) Loss:  0.5200 (0.5200)  Acc@1: 90.2344 (90.2344)  Acc@5: 100.0000 (100.0000)
2024-01-31 10:00:38,805 - train - INFO - Test: [  39/39]  Time: 1.917 (76.176s) Loss:  0.5454 (0.5120)  Acc@1: 87.5000 (90.6300)  Acc@5: 100.0000 (99.6600)
2024-01-31 10:00:41,597 - train - INFO - Train: 2 [   0/195 (  0%)]  Loss:  1.697936 (1.6979)  Time: 2.615s (2.615s),   97.89/s  (2.615s,   97.89/s)  LR: 5.498e-04  Data: 0.211 (0.211)
2024-01-31 10:02:30,439 - train - INFO - Train: 2 [  50/195 ( 26%)]  Loss:  1.582821 (1.5114)  Time: 2.326s (111.456s),  110.06/s  (2.185s,  117.14/s)  LR: 5.498e-04  Data: 0.004 (0.012)
2024-01-31 10:04:29,206 - train - INFO - Train: 2 [ 100/195 ( 52%)]  Loss:  1.375568 (1.5099)  Time: 2.289s (230.222s),  111.84/s  (2.279s,  112.31/s)  LR: 5.498e-04  Data: 0.005 (0.010)
2024-01-31 10:06:25,361 - train - INFO - Train: 2 [ 150/195 ( 77%)]  Loss:  1.652750 (1.5070)  Time: 2.461s (346.374s),  104.04/s  (2.294s,  111.60/s)  LR: 5.498e-04  Data: 0.013 (0.010)
2024-01-31 10:08:04,149 - train - INFO - Train: 2 [ 194/195 (100%)]  Loss:  1.542066 (1.5072)  Time: 2.319s (445.159s),  110.39/s  (2.283s,  112.14/s)  LR: 5.498e-04  Data: 0.000 (0.010)
2024-01-31 10:08:04,153 - train - INFO - alphas:tensor([0.3975, 0.3032, 0.2992], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,154 - train - INFO - alphas:tensor([0.3912, 0.3020, 0.3068], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,155 - train - INFO - alphas:tensor([0.3999, 0.3014, 0.2987], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,156 - train - INFO - alphas:tensor([0.3871, 0.3087, 0.3042], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,156 - train - INFO - alphas:tensor([0.3966, 0.3010, 0.3024], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,157 - train - INFO - alphas:tensor([0.2370, 0.1966, 0.1837, 0.1886, 0.1941], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,158 - train - INFO - alphas:tensor([0.4023, 0.3018, 0.2959], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,159 - train - INFO - alphas:tensor([0.3940, 0.3028, 0.3032], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,159 - train - INFO - alphas:tensor([0.4029, 0.2994, 0.2977], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,160 - train - INFO - alphas:tensor([0.3928, 0.3020, 0.3052], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,161 - train - INFO - alphas:tensor([0.2490, 0.1998, 0.1794, 0.1829, 0.1890], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,162 - train - INFO - alphas:tensor([0.2440, 0.1976, 0.1827, 0.1854, 0.1902], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,162 - train - INFO - alphas:tensor([0.2523, 0.1971, 0.1799, 0.1813, 0.1894], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,163 - train - INFO - alphas:tensor([0.2487, 0.1943, 0.1757, 0.1821, 0.1992], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,164 - train - INFO - alphas:tensor([0.2554, 0.1972, 0.1765, 0.1805, 0.1905], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,165 - train - INFO - alphas:tensor([0.2462, 0.1973, 0.1753, 0.1832, 0.1980], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,166 - train - INFO - alphas:tensor([0.2566, 0.1951, 0.1779, 0.1821, 0.1883], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,166 - train - INFO - alphas:tensor([0.2407, 0.1933, 0.1762, 0.1844, 0.2054], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,167 - train - INFO - alphas:tensor([0.2595, 0.1914, 0.1796, 0.1817, 0.1877], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,168 - train - INFO - alphas:tensor([0.2559, 0.1951, 0.1795, 0.1823, 0.1871], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,169 - train - INFO - alphas:tensor([0.2606, 0.1951, 0.1769, 0.1802, 0.1872], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,169 - train - INFO - alphas:tensor([0.2524, 0.1940, 0.1786, 0.1833, 0.1917], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,170 - train - INFO - alphas:tensor([0.2623, 0.1934, 0.1768, 0.1804, 0.1870], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,171 - train - INFO - alphas:tensor([0.2512, 0.1934, 0.1770, 0.1817, 0.1967], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,172 - train - INFO - alphas:tensor([0.2602, 0.1930, 0.1786, 0.1815, 0.1867], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,172 - train - INFO - alphas:tensor([0.2558, 0.1950, 0.1799, 0.1813, 0.1881], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,173 - train - INFO - alphas:tensor([0.2606, 0.1931, 0.1770, 0.1799, 0.1894], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,174 - train - INFO - alphas:tensor([0.2531, 0.1883, 0.1745, 0.1808, 0.2034], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,175 - train - INFO - alphas:tensor([0.2645, 0.1957, 0.1755, 0.1786, 0.1857], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,176 - train - INFO - alphas:tensor([0.2404, 0.1872, 0.1745, 0.1828, 0.2151], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,176 - train - INFO - alphas:tensor([0.2620, 0.1935, 0.1788, 0.1802, 0.1856], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,177 - train - INFO - alphas:tensor([0.2374, 0.1932, 0.1760, 0.1821, 0.2114], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:08:04,177 - train - INFO - lasso_alpha:3e-05
2024-01-31 10:08:06,186 - train - INFO - Test: [   0/39]  Time: 2.001 (2.001s) Loss:  0.4956 (0.4956)  Acc@1: 89.8438 (89.8438)  Acc@5: 99.6094 (99.6094)
2024-01-31 10:09:20,644 - train - INFO - Test: [  39/39]  Time: 1.949 (76.459s) Loss:  0.5962 (0.5130)  Acc@1: 87.5000 (90.5500)  Acc@5: 100.0000 (99.6900)
2024-01-31 10:09:23,376 - train - INFO - Train: 3 [   0/195 (  0%)]  Loss:  1.273145 (1.2731)  Time: 2.627s (2.627s),   97.44/s  (2.627s,   97.44/s)  LR: 5.495e-04  Data: 0.223 (0.223)
2024-01-31 10:11:11,687 - train - INFO - Train: 3 [  50/195 ( 26%)]  Loss:  1.599715 (1.4884)  Time: 1.710s (110.937s),  149.70/s  (2.175s,  117.69/s)  LR: 5.495e-04  Data: 0.005 (0.014)
2024-01-31 10:13:03,560 - train - INFO - Train: 3 [ 100/195 ( 52%)]  Loss:  1.527824 (1.4846)  Time: 2.191s (222.807s),  116.86/s  (2.206s,  116.05/s)  LR: 5.495e-04  Data: 0.007 (0.012)
2024-01-31 10:14:55,786 - train - INFO - Train: 3 [ 150/195 ( 77%)]  Loss:  1.355269 (1.4816)  Time: 2.292s (335.024s),  111.68/s  (2.219s,  115.38/s)  LR: 5.495e-04  Data: 0.009 (0.011)
2024-01-31 10:16:32,236 - train - INFO - Train: 3 [ 194/195 (100%)]  Loss:  1.528866 (1.4794)  Time: 2.362s (431.473s),  108.40/s  (2.213s,  115.70/s)  LR: 5.495e-04  Data: 0.000 (0.010)
2024-01-31 10:16:32,240 - train - INFO - alphas:tensor([0.4118, 0.2963, 0.2918], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,241 - train - INFO - alphas:tensor([0.4040, 0.2942, 0.3018], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,242 - train - INFO - alphas:tensor([0.4164, 0.2935, 0.2902], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,242 - train - INFO - alphas:tensor([0.3995, 0.3019, 0.2986], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,243 - train - INFO - alphas:tensor([0.4102, 0.2943, 0.2954], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,244 - train - INFO - alphas:tensor([0.2460, 0.1927, 0.1802, 0.1870, 0.1942], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,245 - train - INFO - alphas:tensor([0.4196, 0.2923, 0.2880], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,245 - train - INFO - alphas:tensor([0.4065, 0.2955, 0.2981], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,246 - train - INFO - alphas:tensor([0.4208, 0.2892, 0.2900], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,247 - train - INFO - alphas:tensor([0.4036, 0.2945, 0.3020], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,248 - train - INFO - alphas:tensor([0.2623, 0.1973, 0.1745, 0.1787, 0.1871], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,248 - train - INFO - alphas:tensor([0.2563, 0.1948, 0.1782, 0.1824, 0.1882], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,249 - train - INFO - alphas:tensor([0.2671, 0.1936, 0.1749, 0.1774, 0.1870], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,250 - train - INFO - alphas:tensor([0.2601, 0.1906, 0.1705, 0.1783, 0.2003], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,251 - train - INFO - alphas:tensor([0.2712, 0.1937, 0.1709, 0.1755, 0.1886], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,252 - train - INFO - alphas:tensor([0.2567, 0.1910, 0.1695, 0.1803, 0.2025], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,252 - train - INFO - alphas:tensor([0.2726, 0.1914, 0.1719, 0.1776, 0.1865], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,253 - train - INFO - alphas:tensor([0.2493, 0.1883, 0.1702, 0.1820, 0.2102], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,254 - train - INFO - alphas:tensor([0.2759, 0.1867, 0.1748, 0.1775, 0.1850], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,255 - train - INFO - alphas:tensor([0.2718, 0.1912, 0.1741, 0.1777, 0.1853], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,255 - train - INFO - alphas:tensor([0.2781, 0.1907, 0.1712, 0.1755, 0.1846], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,256 - train - INFO - alphas:tensor([0.2675, 0.1897, 0.1728, 0.1792, 0.1908], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,257 - train - INFO - alphas:tensor([0.2792, 0.1892, 0.1712, 0.1761, 0.1843], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,258 - train - INFO - alphas:tensor([0.2621, 0.1889, 0.1715, 0.1788, 0.1987], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,258 - train - INFO - alphas:tensor([0.2774, 0.1885, 0.1736, 0.1772, 0.1833], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,259 - train - INFO - alphas:tensor([0.2714, 0.1913, 0.1749, 0.1767, 0.1858], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,260 - train - INFO - alphas:tensor([0.2772, 0.1905, 0.1716, 0.1751, 0.1856], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,261 - train - INFO - alphas:tensor([0.2647, 0.1807, 0.1676, 0.1769, 0.2102], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,262 - train - INFO - alphas:tensor([0.2825, 0.1897, 0.1697, 0.1744, 0.1837], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,262 - train - INFO - alphas:tensor([0.2481, 0.1803, 0.1675, 0.1794, 0.2247], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,263 - train - INFO - alphas:tensor([0.2799, 0.1895, 0.1731, 0.1752, 0.1823], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,264 - train - INFO - alphas:tensor([0.2450, 0.1892, 0.1701, 0.1787, 0.2170], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:16:32,264 - train - INFO - lasso_alpha:3e-05
2024-01-31 10:16:34,446 - train - INFO - Test: [   0/39]  Time: 2.174 (2.174s) Loss:  0.4539 (0.4539)  Acc@1: 91.7969 (91.7969)  Acc@5: 100.0000 (100.0000)
2024-01-31 10:17:48,508 - train - INFO - Test: [  39/39]  Time: 1.963 (76.221s) Loss:  0.4409 (0.4700)  Acc@1: 93.7500 (92.2500)  Acc@5: 100.0000 (99.8300)
2024-01-31 10:17:51,227 - train - INFO - Train: 4 [   0/195 (  0%)]  Loss:  1.451489 (1.4515)  Time: 2.626s (2.626s),   97.50/s  (2.626s,   97.50/s)  LR: 5.491e-04  Data: 0.229 (0.229)
2024-01-31 10:19:45,452 - train - INFO - Train: 4 [  50/195 ( 26%)]  Loss:  1.459310 (1.4926)  Time: 2.333s (116.849s),  109.75/s  (2.291s,  111.73/s)  LR: 5.491e-04  Data: 0.007 (0.013)
2024-01-31 10:21:39,603 - train - INFO - Train: 4 [ 100/195 ( 52%)]  Loss:  1.409131 (1.4689)  Time: 2.172s (230.999s),  117.88/s  (2.287s,  111.93/s)  LR: 5.491e-04  Data: 0.010 (0.011)
2024-01-31 10:23:24,962 - train - INFO - Train: 4 [ 150/195 ( 77%)]  Loss:  1.546178 (1.4701)  Time: 1.959s (336.356s),  130.69/s  (2.228s,  114.93/s)  LR: 5.491e-04  Data: 0.006 (0.010)
2024-01-31 10:25:05,134 - train - INFO - Train: 4 [ 194/195 (100%)]  Loss:  1.583718 (1.4740)  Time: 2.408s (436.525s),  106.30/s  (2.239s,  114.36/s)  LR: 5.491e-04  Data: 0.000 (0.010)
2024-01-31 10:25:05,155 - train - INFO - alphas:tensor([0.4258, 0.2881, 0.2861], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,165 - train - INFO - alphas:tensor([0.4146, 0.2883, 0.2971], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,166 - train - INFO - alphas:tensor([0.4324, 0.2846, 0.2830], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,166 - train - INFO - alphas:tensor([0.4096, 0.2965, 0.2939], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,167 - train - INFO - alphas:tensor([0.4259, 0.2863, 0.2878], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,168 - train - INFO - alphas:tensor([0.2541, 0.1908, 0.1764, 0.1848, 0.1940], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,177 - train - INFO - alphas:tensor([0.4371, 0.2828, 0.2801], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,178 - train - INFO - alphas:tensor([0.4156, 0.2906, 0.2938], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,179 - train - INFO - alphas:tensor([0.4347, 0.2822, 0.2831], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,180 - train - INFO - alphas:tensor([0.4125, 0.2883, 0.2993], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,180 - train - INFO - alphas:tensor([0.2742, 0.1939, 0.1706, 0.1760, 0.1853], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,181 - train - INFO - alphas:tensor([0.2679, 0.1917, 0.1744, 0.1791, 0.1868], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,191 - train - INFO - alphas:tensor([0.2810, 0.1902, 0.1703, 0.1736, 0.1850], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,191 - train - INFO - alphas:tensor([0.2710, 0.1852, 0.1647, 0.1758, 0.2034], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,192 - train - INFO - alphas:tensor([0.2860, 0.1900, 0.1659, 0.1712, 0.1869], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,193 - train - INFO - alphas:tensor([0.2668, 0.1850, 0.1638, 0.1778, 0.2066], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,194 - train - INFO - alphas:tensor([0.2862, 0.1880, 0.1665, 0.1738, 0.1854], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,195 - train - INFO - alphas:tensor([0.2572, 0.1825, 0.1646, 0.1798, 0.2160], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,202 - train - INFO - alphas:tensor([0.2917, 0.1818, 0.1704, 0.1739, 0.1823], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,203 - train - INFO - alphas:tensor([0.2869, 0.1858, 0.1695, 0.1741, 0.1837], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,208 - train - INFO - alphas:tensor([0.2953, 0.1869, 0.1658, 0.1703, 0.1818], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,209 - train - INFO - alphas:tensor([0.2800, 0.1848, 0.1678, 0.1765, 0.1910], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,210 - train - INFO - alphas:tensor([0.2967, 0.1833, 0.1658, 0.1720, 0.1822], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,211 - train - INFO - alphas:tensor([0.2756, 0.1830, 0.1663, 0.1752, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,212 - train - INFO - alphas:tensor([0.2939, 0.1836, 0.1692, 0.1734, 0.1800], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,212 - train - INFO - alphas:tensor([0.2867, 0.1868, 0.1704, 0.1729, 0.1832], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,213 - train - INFO - alphas:tensor([0.2941, 0.1856, 0.1660, 0.1711, 0.1832], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,214 - train - INFO - alphas:tensor([0.2741, 0.1740, 0.1613, 0.1726, 0.2180], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,215 - train - INFO - alphas:tensor([0.3000, 0.1842, 0.1640, 0.1700, 0.1817], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,220 - train - INFO - alphas:tensor([0.2539, 0.1735, 0.1609, 0.1764, 0.2354], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,221 - train - INFO - alphas:tensor([0.2977, 0.1845, 0.1681, 0.1702, 0.1794], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,222 - train - INFO - alphas:tensor([0.2509, 0.1844, 0.1653, 0.1760, 0.2233], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:25:05,222 - train - INFO - lasso_alpha:3e-05
2024-01-31 10:25:07,241 - train - INFO - Test: [   0/39]  Time: 1.998 (1.998s) Loss:  0.4656 (0.4656)  Acc@1: 92.1875 (92.1875)  Acc@5: 99.6094 (99.6094)
2024-01-31 10:26:20,323 - train - INFO - Test: [  39/39]  Time: 1.831 (75.080s) Loss:  0.4651 (0.4674)  Acc@1: 93.7500 (91.9300)  Acc@5: 100.0000 (99.7100)
2024-01-31 10:26:23,094 - train - INFO - Train: 5 [   0/195 (  0%)]  Loss:  1.253191 (1.2532)  Time: 2.662s (2.662s),   96.15/s  (2.662s,   96.15/s)  LR: 5.485e-04  Data: 0.373 (0.373)
2024-01-31 10:28:14,893 - train - INFO - Train: 5 [  50/195 ( 26%)]  Loss:  1.572211 (1.4858)  Time: 2.384s (114.458s),  107.37/s  (2.244s,  114.07/s)  LR: 5.485e-04  Data: 0.017 (0.016)
2024-01-31 10:30:09,990 - train - INFO - Train: 5 [ 100/195 ( 52%)]  Loss:  1.643008 (1.4767)  Time: 2.305s (229.553s),  111.04/s  (2.273s,  112.64/s)  LR: 5.485e-04  Data: 0.005 (0.013)
2024-01-31 10:31:59,133 - train - INFO - Train: 5 [ 150/195 ( 77%)]  Loss:  1.657686 (1.4766)  Time: 2.274s (338.693s),  112.57/s  (2.243s,  114.13/s)  LR: 5.485e-04  Data: 0.017 (0.011)
2024-01-31 10:33:38,185 - train - INFO - Train: 5 [ 194/195 (100%)]  Loss:  1.395658 (1.4720)  Time: 2.452s (437.742s),  104.39/s  (2.245s,  114.04/s)  LR: 5.485e-04  Data: 0.000 (0.011)
2024-01-31 10:33:38,193 - train - INFO - alphas:tensor([0.4379, 0.2818, 0.2803], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,194 - train - INFO - alphas:tensor([0.4264, 0.2822, 0.2914], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,195 - train - INFO - alphas:tensor([0.4472, 0.2775, 0.2753], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,196 - train - INFO - alphas:tensor([0.4197, 0.2901, 0.2902], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,196 - train - INFO - alphas:tensor([0.4392, 0.2786, 0.2822], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,197 - train - INFO - alphas:tensor([0.2636, 0.1871, 0.1727, 0.1826, 0.1940], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,198 - train - INFO - alphas:tensor([0.4512, 0.2751, 0.2737], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,199 - train - INFO - alphas:tensor([0.4251, 0.2848, 0.2901], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,200 - train - INFO - alphas:tensor([0.4515, 0.2724, 0.2762], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,200 - train - INFO - alphas:tensor([0.4206, 0.2825, 0.2969], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,201 - train - INFO - alphas:tensor([0.2865, 0.1905, 0.1668, 0.1730, 0.1833], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,202 - train - INFO - alphas:tensor([0.2787, 0.1879, 0.1709, 0.1767, 0.1858], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,203 - train - INFO - alphas:tensor([0.2935, 0.1866, 0.1660, 0.1702, 0.1838], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,203 - train - INFO - alphas:tensor([0.2817, 0.1803, 0.1592, 0.1728, 0.2060], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,204 - train - INFO - alphas:tensor([0.3009, 0.1851, 0.1606, 0.1677, 0.1858], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,205 - train - INFO - alphas:tensor([0.2759, 0.1794, 0.1581, 0.1752, 0.2114], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,206 - train - INFO - alphas:tensor([0.3016, 0.1825, 0.1616, 0.1701, 0.1843], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,207 - train - INFO - alphas:tensor([0.2645, 0.1772, 0.1600, 0.1777, 0.2205], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,207 - train - INFO - alphas:tensor([0.3075, 0.1769, 0.1660, 0.1702, 0.1794], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,208 - train - INFO - alphas:tensor([0.3026, 0.1816, 0.1646, 0.1703, 0.1810], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,209 - train - INFO - alphas:tensor([0.3132, 0.1824, 0.1606, 0.1656, 0.1782], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,210 - train - INFO - alphas:tensor([0.2935, 0.1798, 0.1624, 0.1729, 0.1912], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,210 - train - INFO - alphas:tensor([0.3131, 0.1793, 0.1614, 0.1675, 0.1788], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,211 - train - INFO - alphas:tensor([0.2883, 0.1790, 0.1605, 0.1713, 0.2009], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,212 - train - INFO - alphas:tensor([0.3104, 0.1790, 0.1646, 0.1692, 0.1768], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,213 - train - INFO - alphas:tensor([0.3004, 0.1826, 0.1661, 0.1692, 0.1818], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,214 - train - INFO - alphas:tensor([0.3092, 0.1798, 0.1608, 0.1676, 0.1827], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,214 - train - INFO - alphas:tensor([0.2825, 0.1662, 0.1550, 0.1692, 0.2272], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,215 - train - INFO - alphas:tensor([0.3169, 0.1790, 0.1588, 0.1659, 0.1794], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,216 - train - INFO - alphas:tensor([0.2595, 0.1662, 0.1546, 0.1733, 0.2463], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,217 - train - INFO - alphas:tensor([0.3149, 0.1781, 0.1634, 0.1665, 0.1771], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,217 - train - INFO - alphas:tensor([0.2570, 0.1796, 0.1596, 0.1729, 0.2308], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:33:38,218 - train - INFO - lasso_alpha:3e-05
2024-01-31 10:33:40,379 - train - INFO - Test: [   0/39]  Time: 2.148 (2.148s) Loss:  0.4539 (0.4539)  Acc@1: 92.1875 (92.1875)  Acc@5: 100.0000 (100.0000)
2024-01-31 10:34:53,567 - train - INFO - Test: [  39/39]  Time: 1.921 (75.336s) Loss:  0.4241 (0.4549)  Acc@1: 93.7500 (92.5500)  Acc@5: 100.0000 (99.8200)
2024-01-31 10:34:56,314 - train - INFO - Train: 6 [   0/195 (  0%)]  Loss:  1.468005 (1.4680)  Time: 2.658s (2.658s),   96.30/s  (2.658s,   96.30/s)  LR: 5.479e-04  Data: 0.305 (0.305)
2024-01-31 10:36:54,865 - train - INFO - Train: 6 [  50/195 ( 26%)]  Loss:  1.626621 (1.5002)  Time: 1.976s (121.208s),  129.56/s  (2.377s,  107.72/s)  LR: 5.479e-04  Data: 0.006 (0.014)
2024-01-31 10:38:48,840 - train - INFO - Train: 6 [ 100/195 ( 52%)]  Loss:  1.415903 (1.4810)  Time: 2.275s (235.181s),  112.54/s  (2.329s,  109.94/s)  LR: 5.479e-04  Data: 0.005 (0.012)
2024-01-31 10:40:36,975 - train - INFO - Train: 6 [ 150/195 ( 77%)]  Loss:  1.418365 (1.4872)  Time: 2.404s (343.299s),  106.49/s  (2.274s,  112.60/s)  LR: 5.479e-04  Data: 0.011 (0.011)
2024-01-31 10:42:19,784 - train - INFO - Train: 6 [ 194/195 (100%)]  Loss:  1.513910 (1.4824)  Time: 2.359s (446.095s),  108.54/s  (2.288s,  111.90/s)  LR: 5.479e-04  Data: 0.000 (0.010)
2024-01-31 10:42:19,788 - train - INFO - alphas:tensor([0.4507, 0.2756, 0.2737], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,790 - train - INFO - alphas:tensor([0.4361, 0.2754, 0.2884], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,791 - train - INFO - alphas:tensor([0.4603, 0.2709, 0.2688], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,792 - train - INFO - alphas:tensor([0.4292, 0.2844, 0.2865], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,792 - train - INFO - alphas:tensor([0.4527, 0.2713, 0.2760], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,793 - train - INFO - alphas:tensor([0.2715, 0.1836, 0.1701, 0.1810, 0.1938], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,794 - train - INFO - alphas:tensor([0.4658, 0.2672, 0.2671], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,795 - train - INFO - alphas:tensor([0.4356, 0.2780, 0.2864], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,795 - train - INFO - alphas:tensor([0.4646, 0.2655, 0.2699], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,796 - train - INFO - alphas:tensor([0.4282, 0.2775, 0.2943], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,797 - train - INFO - alphas:tensor([0.2981, 0.1868, 0.1637, 0.1703, 0.1810], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,798 - train - INFO - alphas:tensor([0.2903, 0.1846, 0.1670, 0.1737, 0.1845], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,799 - train - INFO - alphas:tensor([0.3060, 0.1834, 0.1615, 0.1670, 0.1821], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,799 - train - INFO - alphas:tensor([0.2914, 0.1750, 0.1546, 0.1700, 0.2091], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,800 - train - INFO - alphas:tensor([0.3141, 0.1816, 0.1561, 0.1640, 0.1842], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,801 - train - INFO - alphas:tensor([0.2839, 0.1734, 0.1530, 0.1726, 0.2170], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,802 - train - INFO - alphas:tensor([0.3160, 0.1782, 0.1565, 0.1671, 0.1822], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,802 - train - INFO - alphas:tensor([0.2718, 0.1713, 0.1543, 0.1760, 0.2266], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,803 - train - INFO - alphas:tensor([0.3231, 0.1727, 0.1611, 0.1661, 0.1769], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,804 - train - INFO - alphas:tensor([0.3169, 0.1760, 0.1602, 0.1671, 0.1799], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,805 - train - INFO - alphas:tensor([0.3290, 0.1772, 0.1559, 0.1616, 0.1764], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,806 - train - INFO - alphas:tensor([0.3065, 0.1745, 0.1574, 0.1691, 0.1924], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,806 - train - INFO - alphas:tensor([0.3286, 0.1754, 0.1567, 0.1635, 0.1758], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,807 - train - INFO - alphas:tensor([0.2987, 0.1729, 0.1560, 0.1678, 0.2047], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,808 - train - INFO - alphas:tensor([0.3263, 0.1741, 0.1603, 0.1653, 0.1741], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,809 - train - INFO - alphas:tensor([0.3152, 0.1772, 0.1616, 0.1656, 0.1804], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,810 - train - INFO - alphas:tensor([0.3247, 0.1749, 0.1560, 0.1635, 0.1808], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,810 - train - INFO - alphas:tensor([0.2878, 0.1587, 0.1492, 0.1661, 0.2381], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,811 - train - INFO - alphas:tensor([0.3331, 0.1733, 0.1537, 0.1620, 0.1780], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,812 - train - INFO - alphas:tensor([0.2633, 0.1587, 0.1480, 0.1704, 0.2596], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,813 - train - INFO - alphas:tensor([0.3308, 0.1731, 0.1591, 0.1624, 0.1747], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,813 - train - INFO - alphas:tensor([0.2616, 0.1746, 0.1549, 0.1701, 0.2388], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:42:19,814 - train - INFO - lasso_alpha:3.3e-05
2024-01-31 10:42:21,854 - train - INFO - Test: [   0/39]  Time: 2.029 (2.029s) Loss:  0.4175 (0.4175)  Acc@1: 94.5312 (94.5312)  Acc@5: 99.6094 (99.6094)
2024-01-31 10:43:34,917 - train - INFO - Test: [  39/39]  Time: 1.861 (75.093s) Loss:  0.4771 (0.4388)  Acc@1: 93.7500 (92.7900)  Acc@5: 100.0000 (99.7700)
2024-01-31 10:43:37,379 - train - INFO - Train: 7 [   0/195 (  0%)]  Loss:  1.586876 (1.5869)  Time: 2.358s (2.358s),  108.55/s  (2.358s,  108.55/s)  LR: 5.471e-04  Data: 0.193 (0.193)
2024-01-31 10:45:29,435 - train - INFO - Train: 7 [  50/195 ( 26%)]  Loss:  1.474964 (1.4505)  Time: 2.320s (114.412s),  110.33/s  (2.243s,  114.11/s)  LR: 5.471e-04  Data: 0.006 (0.013)
2024-01-31 10:47:21,783 - train - INFO - Train: 7 [ 100/195 ( 52%)]  Loss:  1.371158 (1.4604)  Time: 1.931s (226.759s),  132.59/s  (2.245s,  114.02/s)  LR: 5.471e-04  Data: 0.016 (0.011)
2024-01-31 10:49:13,059 - train - INFO - Train: 7 [ 150/195 ( 77%)]  Loss:  1.501252 (1.4558)  Time: 2.293s (338.033s),  111.65/s  (2.239s,  114.36/s)  LR: 5.471e-04  Data: 0.006 (0.011)
2024-01-31 10:50:55,945 - train - INFO - Train: 7 [ 194/195 (100%)]  Loss:  1.639148 (1.4578)  Time: 2.365s (440.917s),  108.23/s  (2.261s,  113.22/s)  LR: 5.471e-04  Data: 0.000 (0.010)
2024-01-31 10:50:55,948 - train - INFO - alphas:tensor([0.4620, 0.2708, 0.2672], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,949 - train - INFO - alphas:tensor([0.4429, 0.2712, 0.2859], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,950 - train - INFO - alphas:tensor([0.4700, 0.2656, 0.2644], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,951 - train - INFO - alphas:tensor([0.4357, 0.2803, 0.2840], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,951 - train - INFO - alphas:tensor([0.4634, 0.2655, 0.2711], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,952 - train - INFO - alphas:tensor([0.2795, 0.1817, 0.1669, 0.1786, 0.1933], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,953 - train - INFO - alphas:tensor([0.4765, 0.2619, 0.2617], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,954 - train - INFO - alphas:tensor([0.4414, 0.2729, 0.2857], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,954 - train - INFO - alphas:tensor([0.4766, 0.2587, 0.2647], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,955 - train - INFO - alphas:tensor([0.4341, 0.2734, 0.2925], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,956 - train - INFO - alphas:tensor([0.3090, 0.1833, 0.1601, 0.1677, 0.1799], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,957 - train - INFO - alphas:tensor([0.3002, 0.1816, 0.1638, 0.1709, 0.1835], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,957 - train - INFO - alphas:tensor([0.3168, 0.1795, 0.1585, 0.1641, 0.1810], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,958 - train - INFO - alphas:tensor([0.2995, 0.1703, 0.1493, 0.1671, 0.2139], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,959 - train - INFO - alphas:tensor([0.3255, 0.1779, 0.1525, 0.1611, 0.1830], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,960 - train - INFO - alphas:tensor([0.2890, 0.1680, 0.1478, 0.1709, 0.2243], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,960 - train - INFO - alphas:tensor([0.3268, 0.1735, 0.1526, 0.1655, 0.1816], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,961 - train - INFO - alphas:tensor([0.2749, 0.1657, 0.1492, 0.1742, 0.2360], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,962 - train - INFO - alphas:tensor([0.3380, 0.1679, 0.1574, 0.1623, 0.1743], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,963 - train - INFO - alphas:tensor([0.3296, 0.1716, 0.1561, 0.1632, 0.1795], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,964 - train - INFO - alphas:tensor([0.3440, 0.1728, 0.1513, 0.1579, 0.1741], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,964 - train - INFO - alphas:tensor([0.3174, 0.1692, 0.1531, 0.1662, 0.1942], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,965 - train - INFO - alphas:tensor([0.3430, 0.1719, 0.1516, 0.1597, 0.1738], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,966 - train - INFO - alphas:tensor([0.3094, 0.1673, 0.1508, 0.1642, 0.2082], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,967 - train - INFO - alphas:tensor([0.3399, 0.1698, 0.1564, 0.1615, 0.1724], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,967 - train - INFO - alphas:tensor([0.3293, 0.1718, 0.1569, 0.1623, 0.1798], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,968 - train - INFO - alphas:tensor([0.3385, 0.1699, 0.1513, 0.1597, 0.1805], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,969 - train - INFO - alphas:tensor([0.2925, 0.1515, 0.1434, 0.1631, 0.2495], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,970 - train - INFO - alphas:tensor([0.3463, 0.1674, 0.1490, 0.1590, 0.1783], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,970 - train - INFO - alphas:tensor([0.2641, 0.1518, 0.1420, 0.1670, 0.2750], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,971 - train - INFO - alphas:tensor([0.3479, 0.1682, 0.1544, 0.1580, 0.1715], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,972 - train - INFO - alphas:tensor([0.2651, 0.1692, 0.1493, 0.1675, 0.2488], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:50:55,972 - train - INFO - lasso_alpha:3.3e-05
2024-01-31 10:50:58,103 - train - INFO - Test: [   0/39]  Time: 2.123 (2.123s) Loss:  0.4487 (0.4487)  Acc@1: 91.4062 (91.4062)  Acc@5: 99.6094 (99.6094)
2024-01-31 10:52:11,068 - train - INFO - Test: [  39/39]  Time: 2.148 (75.081s) Loss:  0.3938 (0.4448)  Acc@1: 93.7500 (92.3500)  Acc@5: 100.0000 (99.7600)
2024-01-31 10:52:13,824 - train - INFO - Train: 8 [   0/195 (  0%)]  Loss:  1.470962 (1.4710)  Time: 2.665s (2.665s),   96.04/s  (2.665s,   96.04/s)  LR: 5.462e-04  Data: 0.201 (0.201)
2024-01-31 10:54:07,191 - train - INFO - Train: 8 [  50/195 ( 26%)]  Loss:  1.395975 (1.4708)  Time: 2.357s (116.031s),  108.61/s  (2.275s,  112.52/s)  LR: 5.462e-04  Data: 0.009 (0.014)
2024-01-31 10:56:01,555 - train - INFO - Train: 8 [ 100/195 ( 52%)]  Loss:  1.601051 (1.4666)  Time: 2.354s (230.393s),  108.77/s  (2.281s,  112.23/s)  LR: 5.462e-04  Data: 0.013 (0.011)
2024-01-31 10:57:53,955 - train - INFO - Train: 8 [ 150/195 ( 77%)]  Loss:  1.530255 (1.4569)  Time: 2.192s (342.788s),  116.81/s  (2.270s,  112.77/s)  LR: 5.462e-04  Data: 0.005 (0.011)
2024-01-31 10:59:34,803 - train - INFO - Train: 8 [ 194/195 (100%)]  Loss:  1.581687 (1.4503)  Time: 2.294s (443.635s),  111.60/s  (2.275s,  112.53/s)  LR: 5.462e-04  Data: 0.000 (0.010)
2024-01-31 10:59:34,804 - train - INFO - alphas:tensor([0.4729, 0.2650, 0.2621], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,804 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,805 - train - INFO - alphas:tensor([0.4515, 0.2662, 0.2824], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,805 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,806 - train - INFO - alphas:tensor([0.4825, 0.2597, 0.2578], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,806 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,807 - train - INFO - alphas:tensor([0.4411, 0.2773, 0.2816], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,807 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,808 - train - INFO - alphas:tensor([0.4764, 0.2589, 0.2648], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,808 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,808 - train - INFO - alphas:tensor([0.2866, 0.1791, 0.1638, 0.1771, 0.1934], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,808 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,809 - train - INFO - alphas:tensor([0.4870, 0.2560, 0.2570], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,809 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,810 - train - INFO - alphas:tensor([0.4459, 0.2679, 0.2862], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,810 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,811 - train - INFO - alphas:tensor([0.4876, 0.2525, 0.2599], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,811 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,812 - train - INFO - alphas:tensor([0.4376, 0.2692, 0.2931], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,812 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,813 - train - INFO - alphas:tensor([0.3199, 0.1802, 0.1567, 0.1651, 0.1781], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,813 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,813 - train - INFO - alphas:tensor([0.3097, 0.1775, 0.1605, 0.1691, 0.1832], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,813 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,814 - train - INFO - alphas:tensor([0.3278, 0.1759, 0.1546, 0.1614, 0.1803], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,814 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,815 - train - INFO - alphas:tensor([0.3057, 0.1638, 0.1452, 0.1653, 0.2201], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,815 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,816 - train - INFO - alphas:tensor([0.3370, 0.1746, 0.1487, 0.1573, 0.1824], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,816 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,817 - train - INFO - alphas:tensor([0.2941, 0.1604, 0.1430, 0.1691, 0.2335], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,817 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,818 - train - INFO - alphas:tensor([0.3398, 0.1696, 0.1489, 0.1614, 0.1804], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,818 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,819 - train - INFO - alphas:tensor([0.2746, 0.1588, 0.1455, 0.1742, 0.2468], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,819 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,819 - train - INFO - alphas:tensor([0.3513, 0.1639, 0.1536, 0.1589, 0.1723], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,820 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,820 - train - INFO - alphas:tensor([0.3417, 0.1667, 0.1517, 0.1606, 0.1793], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,820 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,821 - train - INFO - alphas:tensor([0.3567, 0.1688, 0.1473, 0.1552, 0.1720], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,821 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,822 - train - INFO - alphas:tensor([0.3262, 0.1639, 0.1484, 0.1631, 0.1984], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,822 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,823 - train - INFO - alphas:tensor([0.3580, 0.1668, 0.1471, 0.1555, 0.1726], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,823 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,824 - train - INFO - alphas:tensor([0.3168, 0.1619, 0.1461, 0.1618, 0.2135], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,824 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,825 - train - INFO - alphas:tensor([0.3538, 0.1648, 0.1523, 0.1586, 0.1705], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,825 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,825 - train - INFO - alphas:tensor([0.3428, 0.1667, 0.1527, 0.1592, 0.1787], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,825 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,826 - train - INFO - alphas:tensor([0.3516, 0.1651, 0.1474, 0.1557, 0.1802], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,826 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,827 - train - INFO - alphas:tensor([0.2952, 0.1440, 0.1373, 0.1595, 0.2640], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,827 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,828 - train - INFO - alphas:tensor([0.3593, 0.1621, 0.1446, 0.1561, 0.1779], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,828 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,829 - train - INFO - alphas:tensor([0.2618, 0.1441, 0.1362, 0.1652, 0.2927], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,829 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,830 - train - INFO - alphas:tensor([0.3630, 0.1636, 0.1503, 0.1538, 0.1691], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,830 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,830 - train - INFO - alphas:tensor([0.2661, 0.1635, 0.1443, 0.1656, 0.2605], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 10:59:34,831 - train - INFO - tau:0.16471290567571928
2024-01-31 10:59:34,831 - train - INFO - lasso_alpha:3.3e-05
2024-01-31 10:59:36,899 - train - INFO - Test: [   0/39]  Time: 2.049 (2.049s) Loss:  0.4402 (0.4402)  Acc@1: 93.3594 (93.3594)  Acc@5: 100.0000 (100.0000)
2024-01-31 11:00:50,660 - train - INFO - Test: [  39/39]  Time: 1.926 (75.809s) Loss:  0.5303 (0.4505)  Acc@1: 93.7500 (92.7700)  Acc@5: 100.0000 (99.7500)
2024-01-31 11:00:53,393 - train - INFO - Train: 9 [   0/195 (  0%)]  Loss:  1.405313 (1.4053)  Time: 2.599s (2.599s),   98.48/s  (2.599s,   98.48/s)  LR: 5.452e-04  Data: 0.225 (0.225)
2024-01-31 11:02:46,609 - train - INFO - Train: 9 [  50/195 ( 26%)]  Loss:  1.580358 (1.4687)  Time: 2.377s (115.812s),  107.69/s  (2.271s,  112.73/s)  LR: 5.452e-04  Data: 0.008 (0.013)
2024-01-31 11:04:40,364 - train - INFO - Train: 9 [ 100/195 ( 52%)]  Loss:  1.565139 (1.4690)  Time: 2.204s (229.564s),  116.16/s  (2.273s,  112.63/s)  LR: 5.452e-04  Data: 0.008 (0.011)
2024-01-31 11:06:33,528 - train - INFO - Train: 9 [ 150/195 ( 77%)]  Loss:  1.545435 (1.4645)  Time: 2.314s (342.727s),  110.62/s  (2.270s,  112.79/s)  LR: 5.452e-04  Data: 0.006 (0.011)
2024-01-31 11:08:16,503 - train - INFO - Train: 9 [ 194/195 (100%)]  Loss:  1.593160 (1.4643)  Time: 2.382s (445.701s),  107.49/s  (2.286s,  112.00/s)  LR: 5.452e-04  Data: 0.000 (0.010)
2024-01-31 11:08:16,507 - train - INFO - alphas:tensor([0.4835, 0.2596, 0.2569], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,507 - train - INFO - alphas:tensor([0.4586, 0.2622, 0.2792], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,508 - train - INFO - alphas:tensor([0.4918, 0.2551, 0.2531], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,509 - train - INFO - alphas:tensor([0.4472, 0.2726, 0.2802], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,510 - train - INFO - alphas:tensor([0.4858, 0.2539, 0.2604], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,511 - train - INFO - alphas:tensor([0.2941, 0.1757, 0.1614, 0.1748, 0.1939], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,511 - train - INFO - alphas:tensor([0.4983, 0.2491, 0.2525], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,512 - train - INFO - alphas:tensor([0.4518, 0.2630, 0.2852], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,513 - train - INFO - alphas:tensor([0.4962, 0.2475, 0.2562], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,514 - train - INFO - alphas:tensor([0.4424, 0.2639, 0.2936], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,514 - train - INFO - alphas:tensor([0.3300, 0.1770, 0.1536, 0.1631, 0.1764], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,515 - train - INFO - alphas:tensor([0.3196, 0.1733, 0.1573, 0.1668, 0.1831], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,516 - train - INFO - alphas:tensor([0.3397, 0.1722, 0.1514, 0.1583, 0.1785], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,517 - train - INFO - alphas:tensor([0.3100, 0.1588, 0.1410, 0.1636, 0.2266], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,517 - train - INFO - alphas:tensor([0.3468, 0.1716, 0.1452, 0.1550, 0.1814], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,518 - train - INFO - alphas:tensor([0.2957, 0.1546, 0.1386, 0.1685, 0.2427], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,519 - train - INFO - alphas:tensor([0.3499, 0.1658, 0.1450, 0.1593, 0.1800], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,520 - train - INFO - alphas:tensor([0.2781, 0.1532, 0.1400, 0.1722, 0.2566], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,520 - train - INFO - alphas:tensor([0.3633, 0.1591, 0.1504, 0.1568, 0.1704], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,521 - train - INFO - alphas:tensor([0.3535, 0.1631, 0.1480, 0.1571, 0.1782], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,522 - train - INFO - alphas:tensor([0.3701, 0.1638, 0.1434, 0.1524, 0.1703], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,523 - train - INFO - alphas:tensor([0.3347, 0.1590, 0.1439, 0.1603, 0.2021], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,523 - train - INFO - alphas:tensor([0.3715, 0.1616, 0.1437, 0.1525, 0.1707], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,524 - train - INFO - alphas:tensor([0.3246, 0.1553, 0.1420, 0.1592, 0.2190], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,525 - train - INFO - alphas:tensor([0.3681, 0.1597, 0.1478, 0.1551, 0.1693], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,526 - train - INFO - alphas:tensor([0.3555, 0.1617, 0.1488, 0.1555, 0.1785], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,527 - train - INFO - alphas:tensor([0.3623, 0.1595, 0.1433, 0.1536, 0.1813], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,527 - train - INFO - alphas:tensor([0.2954, 0.1367, 0.1318, 0.1562, 0.2799], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,528 - train - INFO - alphas:tensor([0.3702, 0.1574, 0.1412, 0.1529, 0.1782], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,529 - train - INFO - alphas:tensor([0.2591, 0.1364, 0.1306, 0.1630, 0.3109], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,530 - train - INFO - alphas:tensor([0.3767, 0.1603, 0.1465, 0.1501, 0.1663], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,530 - train - INFO - alphas:tensor([0.2682, 0.1584, 0.1396, 0.1630, 0.2708], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:08:16,531 - train - INFO - lasso_alpha:3.630000000000001e-05
2024-01-31 11:08:18,621 - train - INFO - Test: [   0/39]  Time: 2.080 (2.080s) Loss:  0.4707 (0.4707)  Acc@1: 91.0156 (91.0156)  Acc@5: 99.2188 (99.2188)
2024-01-31 11:09:31,463 - train - INFO - Test: [  39/39]  Time: 1.833 (74.922s) Loss:  0.5083 (0.4657)  Acc@1: 87.5000 (92.4400)  Acc@5: 100.0000 (99.7000)
2024-01-31 11:09:34,134 - train - INFO - Train: 10 [   0/195 (  0%)]  Loss:  1.414227 (1.4142)  Time: 2.546s (2.546s),  100.55/s  (2.546s,  100.55/s)  LR: 5.441e-04  Data: 0.155 (0.155)
2024-01-31 11:11:26,140 - train - INFO - Train: 10 [  50/195 ( 26%)]  Loss:  1.554032 (1.4763)  Time: 2.281s (114.550s),  112.25/s  (2.246s,  113.98/s)  LR: 5.441e-04  Data: 0.008 (0.012)
2024-01-31 11:13:17,200 - train - INFO - Train: 10 [ 100/195 ( 52%)]  Loss:  1.634177 (1.4612)  Time: 2.404s (225.609s),  106.47/s  (2.234s,  114.61/s)  LR: 5.441e-04  Data: 0.042 (0.011)
2024-01-31 11:15:10,722 - train - INFO - Train: 10 [ 150/195 ( 77%)]  Loss:  1.436769 (1.4616)  Time: 2.439s (339.129s),  104.95/s  (2.246s,  113.99/s)  LR: 5.441e-04  Data: 0.006 (0.010)
2024-01-31 11:16:52,150 - train - INFO - Train: 10 [ 194/195 (100%)]  Loss:  1.472508 (1.4609)  Time: 2.292s (440.555s),  111.68/s  (2.259s,  113.31/s)  LR: 5.441e-04  Data: 0.000 (0.010)
2024-01-31 11:16:52,156 - train - INFO - alphas:tensor([0.4908, 0.2569, 0.2524], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,166 - train - INFO - alphas:tensor([0.4631, 0.2596, 0.2772], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,171 - train - INFO - alphas:tensor([0.4973, 0.2527, 0.2500], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,172 - train - INFO - alphas:tensor([0.4534, 0.2686, 0.2780], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,173 - train - INFO - alphas:tensor([0.4956, 0.2476, 0.2568], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,174 - train - INFO - alphas:tensor([0.3011, 0.1719, 0.1588, 0.1739, 0.1943], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,179 - train - INFO - alphas:tensor([0.5065, 0.2445, 0.2490], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,184 - train - INFO - alphas:tensor([0.4563, 0.2585, 0.2852], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,185 - train - INFO - alphas:tensor([0.5034, 0.2441, 0.2525], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,186 - train - INFO - alphas:tensor([0.4406, 0.2618, 0.2976], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,186 - train - INFO - alphas:tensor([0.3387, 0.1742, 0.1510, 0.1607, 0.1753], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,187 - train - INFO - alphas:tensor([0.3302, 0.1706, 0.1536, 0.1641, 0.1814], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,197 - train - INFO - alphas:tensor([0.3494, 0.1678, 0.1477, 0.1564, 0.1787], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,198 - train - INFO - alphas:tensor([0.3129, 0.1534, 0.1366, 0.1620, 0.2350], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,198 - train - INFO - alphas:tensor([0.3561, 0.1675, 0.1423, 0.1529, 0.1812], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,204 - train - INFO - alphas:tensor([0.2946, 0.1486, 0.1340, 0.1675, 0.2552], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,205 - train - INFO - alphas:tensor([0.3602, 0.1613, 0.1417, 0.1568, 0.1800], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,205 - train - INFO - alphas:tensor([0.2743, 0.1478, 0.1358, 0.1716, 0.2705], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,215 - train - INFO - alphas:tensor([0.3756, 0.1556, 0.1468, 0.1533, 0.1686], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,216 - train - INFO - alphas:tensor([0.3647, 0.1591, 0.1440, 0.1541, 0.1782], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,217 - train - INFO - alphas:tensor([0.3827, 0.1599, 0.1395, 0.1493, 0.1686], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,217 - train - INFO - alphas:tensor([0.3407, 0.1532, 0.1397, 0.1586, 0.2078], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,218 - train - INFO - alphas:tensor([0.3867, 0.1569, 0.1391, 0.1486, 0.1687], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,219 - train - INFO - alphas:tensor([0.3298, 0.1495, 0.1379, 0.1574, 0.2253], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,229 - train - INFO - alphas:tensor([0.3814, 0.1555, 0.1440, 0.1521, 0.1670], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,229 - train - INFO - alphas:tensor([0.3668, 0.1575, 0.1455, 0.1525, 0.1777], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,230 - train - INFO - alphas:tensor([0.3732, 0.1544, 0.1396, 0.1508, 0.1821], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,231 - train - INFO - alphas:tensor([0.2942, 0.1301, 0.1263, 0.1536, 0.2957], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,232 - train - INFO - alphas:tensor([0.3819, 0.1530, 0.1366, 0.1499, 0.1787], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,241 - train - INFO - alphas:tensor([0.2564, 0.1298, 0.1248, 0.1607, 0.3283], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,242 - train - INFO - alphas:tensor([0.3903, 0.1559, 0.1426, 0.1464, 0.1648], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,243 - train - INFO - alphas:tensor([0.2678, 0.1527, 0.1346, 0.1608, 0.2841], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:16:52,243 - train - INFO - lasso_alpha:3.630000000000001e-05
2024-01-31 11:16:54,204 - train - INFO - Test: [   0/39]  Time: 1.952 (1.952s) Loss:  0.4602 (0.4602)  Acc@1: 93.3594 (93.3594)  Acc@5: 100.0000 (100.0000)
2024-01-31 11:18:07,768 - train - INFO - Test: [  39/39]  Time: 1.767 (75.515s) Loss:  0.5288 (0.4513)  Acc@1: 81.2500 (92.8900)  Acc@5: 100.0000 (99.8000)
2024-01-31 11:18:10,370 - train - INFO - Train: 11 [   0/195 (  0%)]  Loss:  1.571791 (1.5718)  Time: 2.507s (2.507s),  102.10/s  (2.507s,  102.10/s)  LR: 5.429e-04  Data: 0.248 (0.248)
2024-01-31 11:20:04,829 - train - INFO - Train: 11 [  50/195 ( 26%)]  Loss:  1.425760 (1.4734)  Time: 2.236s (116.963s),  114.50/s  (2.293s,  111.63/s)  LR: 5.429e-04  Data: 0.004 (0.014)
2024-01-31 11:22:00,959 - train - INFO - Train: 11 [ 100/195 ( 52%)]  Loss:  1.455560 (1.4636)  Time: 2.391s (233.090s),  107.07/s  (2.308s,  110.93/s)  LR: 5.429e-04  Data: 0.008 (0.010)
2024-01-31 11:23:55,310 - train - INFO - Train: 11 [ 150/195 ( 77%)]  Loss:  1.625422 (1.4688)  Time: 1.968s (347.439s),  130.11/s  (2.301s,  111.26/s)  LR: 5.429e-04  Data: 0.022 (0.010)
2024-01-31 11:25:35,728 - train - INFO - Train: 11 [ 194/195 (100%)]  Loss:  1.410945 (1.4653)  Time: 2.401s (447.853s),  106.64/s  (2.297s,  111.47/s)  LR: 5.429e-04  Data: 0.000 (0.009)
2024-01-31 11:25:35,731 - train - INFO - alphas:tensor([0.4991, 0.2520, 0.2490], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,732 - train - INFO - alphas:tensor([0.4713, 0.2545, 0.2741], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,732 - train - INFO - alphas:tensor([0.5072, 0.2468, 0.2460], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,733 - train - INFO - alphas:tensor([0.4559, 0.2665, 0.2775], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,734 - train - INFO - alphas:tensor([0.5036, 0.2433, 0.2532], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,735 - train - INFO - alphas:tensor([0.3074, 0.1691, 0.1556, 0.1725, 0.1953], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,736 - train - INFO - alphas:tensor([0.5136, 0.2411, 0.2452], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,736 - train - INFO - alphas:tensor([0.4608, 0.2545, 0.2847], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,737 - train - INFO - alphas:tensor([0.5137, 0.2384, 0.2479], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,738 - train - INFO - alphas:tensor([0.4391, 0.2599, 0.3010], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,739 - train - INFO - alphas:tensor([0.3476, 0.1708, 0.1484, 0.1586, 0.1746], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,739 - train - INFO - alphas:tensor([0.3419, 0.1664, 0.1499, 0.1616, 0.1801], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,740 - train - INFO - alphas:tensor([0.3587, 0.1658, 0.1445, 0.1532, 0.1777], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,741 - train - INFO - alphas:tensor([0.3132, 0.1479, 0.1332, 0.1614, 0.2443], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,742 - train - INFO - alphas:tensor([0.3656, 0.1641, 0.1389, 0.1499, 0.1815], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,743 - train - INFO - alphas:tensor([0.2940, 0.1427, 0.1302, 0.1660, 0.2671], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,744 - train - INFO - alphas:tensor([0.3709, 0.1582, 0.1379, 0.1538, 0.1791], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,744 - train - INFO - alphas:tensor([0.2738, 0.1429, 0.1308, 0.1702, 0.2824], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,745 - train - INFO - alphas:tensor([0.3885, 0.1513, 0.1438, 0.1503, 0.1662], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,746 - train - INFO - alphas:tensor([0.3751, 0.1554, 0.1403, 0.1508, 0.1785], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,747 - train - INFO - alphas:tensor([0.3945, 0.1564, 0.1359, 0.1462, 0.1670], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,747 - train - INFO - alphas:tensor([0.3471, 0.1471, 0.1357, 0.1566, 0.2135], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,748 - train - INFO - alphas:tensor([0.3971, 0.1530, 0.1362, 0.1463, 0.1674], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,749 - train - INFO - alphas:tensor([0.3354, 0.1442, 0.1337, 0.1547, 0.2321], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,750 - train - INFO - alphas:tensor([0.3958, 0.1507, 0.1407, 0.1487, 0.1641], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,751 - train - INFO - alphas:tensor([0.3790, 0.1524, 0.1417, 0.1498, 0.1771], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,751 - train - INFO - alphas:tensor([0.3810, 0.1498, 0.1361, 0.1486, 0.1844], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,752 - train - INFO - alphas:tensor([0.2929, 0.1234, 0.1205, 0.1499, 0.3133], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,753 - train - INFO - alphas:tensor([0.3914, 0.1487, 0.1330, 0.1477, 0.1792], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,754 - train - INFO - alphas:tensor([0.2531, 0.1231, 0.1191, 0.1577, 0.3470], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,755 - train - INFO - alphas:tensor([0.4040, 0.1513, 0.1389, 0.1431, 0.1627], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,755 - train - INFO - alphas:tensor([0.2666, 0.1471, 0.1305, 0.1587, 0.2971], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:25:35,756 - train - INFO - lasso_alpha:3.630000000000001e-05
2024-01-31 11:25:37,939 - train - INFO - Test: [   0/39]  Time: 2.175 (2.175s) Loss:  0.4077 (0.4077)  Acc@1: 94.1406 (94.1406)  Acc@5: 100.0000 (100.0000)
2024-01-31 11:26:51,369 - train - INFO - Test: [  39/39]  Time: 1.743 (75.596s) Loss:  0.4087 (0.4400)  Acc@1: 93.7500 (92.5700)  Acc@5: 100.0000 (99.7400)
2024-01-31 11:26:53,836 - train - INFO - Train: 12 [   0/195 (  0%)]  Loss:  1.389904 (1.3899)  Time: 2.326s (2.326s),  110.05/s  (2.326s,  110.05/s)  LR: 5.415e-04  Data: 0.202 (0.202)
2024-01-31 11:28:46,380 - train - INFO - Train: 12 [  50/195 ( 26%)]  Loss:  1.618287 (1.4478)  Time: 2.329s (114.869s),  109.93/s  (2.252s,  113.66/s)  LR: 5.415e-04  Data: 0.007 (0.012)
2024-01-31 11:30:42,181 - train - INFO - Train: 12 [ 100/195 ( 52%)]  Loss:  1.554770 (1.4468)  Time: 2.427s (230.667s),  105.49/s  (2.284s,  112.09/s)  LR: 5.415e-04  Data: 0.010 (0.010)
2024-01-31 11:32:32,679 - train - INFO - Train: 12 [ 150/195 ( 77%)]  Loss:  1.439533 (1.4538)  Time: 2.059s (341.161s),  124.32/s  (2.259s,  113.31/s)  LR: 5.415e-04  Data: 0.005 (0.009)
2024-01-31 11:34:07,375 - train - INFO - Train: 12 [ 194/195 (100%)]  Loss:  1.315264 (1.4545)  Time: 2.292s (435.856s),  111.67/s  (2.235s,  114.53/s)  LR: 5.415e-04  Data: 0.000 (0.009)
2024-01-31 11:34:07,377 - train - INFO - alphas:tensor([0.5074, 0.2468, 0.2458], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,377 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,378 - train - INFO - alphas:tensor([0.4769, 0.2510, 0.2721], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,378 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,378 - train - INFO - alphas:tensor([0.5148, 0.2431, 0.2421], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,379 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,379 - train - INFO - alphas:tensor([0.4596, 0.2626, 0.2778], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,379 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,380 - train - INFO - alphas:tensor([0.5112, 0.2388, 0.2501], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,380 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,381 - train - INFO - alphas:tensor([0.3136, 0.1668, 0.1524, 0.1704, 0.1968], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,381 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,382 - train - INFO - alphas:tensor([0.5195, 0.2379, 0.2426], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,382 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,383 - train - INFO - alphas:tensor([0.4628, 0.2517, 0.2856], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,383 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,383 - train - INFO - alphas:tensor([0.5235, 0.2326, 0.2439], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,383 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,384 - train - INFO - alphas:tensor([0.4378, 0.2572, 0.3050], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,384 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,385 - train - INFO - alphas:tensor([0.3559, 0.1684, 0.1461, 0.1565, 0.1730], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,385 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,386 - train - INFO - alphas:tensor([0.3488, 0.1637, 0.1476, 0.1601, 0.1797], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,386 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,387 - train - INFO - alphas:tensor([0.3662, 0.1620, 0.1418, 0.1517, 0.1783], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,387 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,388 - train - INFO - alphas:tensor([0.3156, 0.1432, 0.1292, 0.1595, 0.2524], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,388 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,389 - train - INFO - alphas:tensor([0.3758, 0.1590, 0.1357, 0.1473, 0.1822], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,389 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,389 - train - INFO - alphas:tensor([0.2927, 0.1362, 0.1258, 0.1649, 0.2803], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,389 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,390 - train - INFO - alphas:tensor([0.3799, 0.1537, 0.1345, 0.1520, 0.1799], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,390 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,391 - train - INFO - alphas:tensor([0.2712, 0.1373, 0.1270, 0.1698, 0.2946], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,391 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,392 - train - INFO - alphas:tensor([0.3993, 0.1489, 0.1405, 0.1477, 0.1636], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,392 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,393 - train - INFO - alphas:tensor([0.3846, 0.1511, 0.1369, 0.1485, 0.1789], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,393 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,394 - train - INFO - alphas:tensor([0.4054, 0.1528, 0.1325, 0.1435, 0.1658], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,394 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,395 - train - INFO - alphas:tensor([0.3537, 0.1427, 0.1316, 0.1540, 0.2180], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,395 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,395 - train - INFO - alphas:tensor([0.4081, 0.1492, 0.1327, 0.1434, 0.1665], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,395 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,396 - train - INFO - alphas:tensor([0.3382, 0.1403, 0.1299, 0.1524, 0.2392], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,396 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,397 - train - INFO - alphas:tensor([0.4079, 0.1467, 0.1371, 0.1459, 0.1624], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,397 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,398 - train - INFO - alphas:tensor([0.3901, 0.1480, 0.1377, 0.1470, 0.1773], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,398 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,399 - train - INFO - alphas:tensor([0.3895, 0.1456, 0.1321, 0.1461, 0.1867], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,399 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,400 - train - INFO - alphas:tensor([0.2909, 0.1170, 0.1158, 0.1463, 0.3300], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,400 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,401 - train - INFO - alphas:tensor([0.4001, 0.1440, 0.1299, 0.1456, 0.1805], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,401 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,401 - train - INFO - alphas:tensor([0.2481, 0.1172, 0.1139, 0.1551, 0.3656], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,401 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,402 - train - INFO - alphas:tensor([0.4167, 0.1466, 0.1354, 0.1402, 0.1610], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,402 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,403 - train - INFO - alphas:tensor([0.2649, 0.1422, 0.1265, 0.1567, 0.3097], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:34:07,403 - train - INFO - tau:0.13177032454057544
2024-01-31 11:34:07,403 - train - INFO - lasso_alpha:3.993000000000001e-05
2024-01-31 11:34:09,394 - train - INFO - Test: [   0/39]  Time: 1.980 (1.980s) Loss:  0.4309 (0.4309)  Acc@1: 94.5312 (94.5312)  Acc@5: 100.0000 (100.0000)
2024-01-31 11:35:24,221 - train - INFO - Test: [  39/39]  Time: 1.735 (76.807s) Loss:  0.5259 (0.4444)  Acc@1: 87.5000 (92.7200)  Acc@5: 100.0000 (99.7400)
2024-01-31 11:35:27,034 - train - INFO - Train: 13 [   0/195 (  0%)]  Loss:  1.462556 (1.4626)  Time: 2.654s (2.654s),   96.46/s  (2.654s,   96.46/s)  LR: 5.401e-04  Data: 0.295 (0.295)
2024-01-31 11:37:18,582 - train - INFO - Train: 13 [  50/195 ( 26%)]  Loss:  1.610322 (1.4651)  Time: 2.372s (114.201s),  107.95/s  (2.239s,  114.33/s)  LR: 5.401e-04  Data: 0.005 (0.013)
2024-01-31 11:39:17,275 - train - INFO - Train: 13 [ 100/195 ( 52%)]  Loss:  1.618250 (1.4552)  Time: 2.456s (232.892s),  104.25/s  (2.306s,  111.02/s)  LR: 5.401e-04  Data: 0.008 (0.011)
2024-01-31 11:41:15,992 - train - INFO - Train: 13 [ 150/195 ( 77%)]  Loss:  1.285486 (1.4523)  Time: 2.427s (351.607s),  105.49/s  (2.329s,  109.94/s)  LR: 5.401e-04  Data: 0.008 (0.010)
2024-01-31 11:42:54,718 - train - INFO - Train: 13 [ 194/195 (100%)]  Loss:  1.325294 (1.4512)  Time: 2.077s (450.332s),  123.27/s  (2.309s,  110.85/s)  LR: 5.401e-04  Data: 0.000 (0.009)
2024-01-31 11:42:54,720 - train - INFO - alphas:tensor([0.5158, 0.2427, 0.2414], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,721 - train - INFO - alphas:tensor([0.4810, 0.2468, 0.2721], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,722 - train - INFO - alphas:tensor([0.5196, 0.2408, 0.2396], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,723 - train - INFO - alphas:tensor([0.4617, 0.2597, 0.2785], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,724 - train - INFO - alphas:tensor([0.5172, 0.2360, 0.2468], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,725 - train - INFO - alphas:tensor([0.3180, 0.1648, 0.1502, 0.1691, 0.1979], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,726 - train - INFO - alphas:tensor([0.5239, 0.2348, 0.2413], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,727 - train - INFO - alphas:tensor([0.4632, 0.2482, 0.2887], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,727 - train - INFO - alphas:tensor([0.5295, 0.2290, 0.2415], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,728 - train - INFO - alphas:tensor([0.4396, 0.2528, 0.3076], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,729 - train - INFO - alphas:tensor([0.3643, 0.1667, 0.1438, 0.1541, 0.1710], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,730 - train - INFO - alphas:tensor([0.3563, 0.1609, 0.1448, 0.1584, 0.1796], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,730 - train - INFO - alphas:tensor([0.3725, 0.1585, 0.1397, 0.1503, 0.1789], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,731 - train - INFO - alphas:tensor([0.3128, 0.1386, 0.1259, 0.1582, 0.2645], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,732 - train - INFO - alphas:tensor([0.3825, 0.1566, 0.1321, 0.1454, 0.1834], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,733 - train - INFO - alphas:tensor([0.2888, 0.1309, 0.1214, 0.1631, 0.2958], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,733 - train - INFO - alphas:tensor([0.3871, 0.1505, 0.1313, 0.1498, 0.1813], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,734 - train - INFO - alphas:tensor([0.2684, 0.1318, 0.1229, 0.1676, 0.3093], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,735 - train - INFO - alphas:tensor([0.4111, 0.1455, 0.1374, 0.1446, 0.1614], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,736 - train - INFO - alphas:tensor([0.3934, 0.1464, 0.1336, 0.1466, 0.1801], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,737 - train - INFO - alphas:tensor([0.4156, 0.1490, 0.1296, 0.1407, 0.1650], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,737 - train - INFO - alphas:tensor([0.3558, 0.1382, 0.1278, 0.1520, 0.2262], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,738 - train - INFO - alphas:tensor([0.4178, 0.1457, 0.1298, 0.1415, 0.1653], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,739 - train - INFO - alphas:tensor([0.3381, 0.1361, 0.1263, 0.1514, 0.2482], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,740 - train - INFO - alphas:tensor([0.4167, 0.1443, 0.1343, 0.1435, 0.1612], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,740 - train - INFO - alphas:tensor([0.3985, 0.1438, 0.1348, 0.1449, 0.1780], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,741 - train - INFO - alphas:tensor([0.3967, 0.1417, 0.1288, 0.1441, 0.1887], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,742 - train - INFO - alphas:tensor([0.2847, 0.1111, 0.1105, 0.1424, 0.3513], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,743 - train - INFO - alphas:tensor([0.4068, 0.1402, 0.1274, 0.1434, 0.1823], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,743 - train - INFO - alphas:tensor([0.2417, 0.1116, 0.1084, 0.1516, 0.3868], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,744 - train - INFO - alphas:tensor([0.4287, 0.1426, 0.1322, 0.1373, 0.1593], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,745 - train - INFO - alphas:tensor([0.2599, 0.1364, 0.1222, 0.1551, 0.3264], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:42:54,745 - train - INFO - lasso_alpha:3.993000000000001e-05
2024-01-31 11:42:56,594 - train - INFO - Test: [   0/39]  Time: 1.841 (1.841s) Loss:  0.4258 (0.4258)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)
2024-01-31 11:44:10,954 - train - INFO - Test: [  39/39]  Time: 1.804 (76.195s) Loss:  0.5103 (0.4558)  Acc@1: 93.7500 (92.4100)  Acc@5: 100.0000 (99.7200)
2024-01-31 11:44:13,568 - train - INFO - Train: 14 [   0/195 (  0%)]  Loss:  1.357016 (1.3570)  Time: 2.524s (2.524s),  101.44/s  (2.524s,  101.44/s)  LR: 5.385e-04  Data: 0.254 (0.254)
2024-01-31 11:46:04,811 - train - INFO - Train: 14 [  50/195 ( 26%)]  Loss:  1.634218 (1.4810)  Time: 2.427s (113.766s),  105.49/s  (2.231s,  114.76/s)  LR: 5.385e-04  Data: 0.004 (0.013)
2024-01-31 11:48:03,388 - train - INFO - Train: 14 [ 100/195 ( 52%)]  Loss:  1.295195 (1.4676)  Time: 2.271s (232.341s),  112.71/s  (2.300s,  111.28/s)  LR: 5.385e-04  Data: 0.006 (0.010)
2024-01-31 11:49:53,085 - train - INFO - Train: 14 [ 150/195 ( 77%)]  Loss:  1.577994 (1.4650)  Time: 2.076s (342.037s),  123.33/s  (2.265s,  113.02/s)  LR: 5.385e-04  Data: 0.006 (0.009)
2024-01-31 11:51:32,704 - train - INFO - Train: 14 [ 194/195 (100%)]  Loss:  1.491299 (1.4649)  Time: 2.460s (441.654s),  104.06/s  (2.265s,  113.03/s)  LR: 5.385e-04  Data: 0.000 (0.009)
2024-01-31 11:51:32,707 - train - INFO - alphas:tensor([0.5201, 0.2396, 0.2403], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,708 - train - INFO - alphas:tensor([0.4846, 0.2444, 0.2710], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,708 - train - INFO - alphas:tensor([0.5236, 0.2377, 0.2387], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,709 - train - INFO - alphas:tensor([0.4623, 0.2578, 0.2799], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,710 - train - INFO - alphas:tensor([0.5263, 0.2311, 0.2425], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,711 - train - INFO - alphas:tensor([0.3236, 0.1613, 0.1477, 0.1678, 0.1996], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,713 - train - INFO - alphas:tensor([0.5283, 0.2319, 0.2398], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,713 - train - INFO - alphas:tensor([0.4611, 0.2476, 0.2913], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,714 - train - INFO - alphas:tensor([0.5324, 0.2268, 0.2407], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,715 - train - INFO - alphas:tensor([0.4371, 0.2511, 0.3118], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,716 - train - INFO - alphas:tensor([0.3736, 0.1639, 0.1413, 0.1520, 0.1692], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,716 - train - INFO - alphas:tensor([0.3644, 0.1590, 0.1422, 0.1557, 0.1787], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,717 - train - INFO - alphas:tensor([0.3819, 0.1542, 0.1365, 0.1488, 0.1787], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,718 - train - INFO - alphas:tensor([0.3124, 0.1337, 0.1225, 0.1569, 0.2745], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,719 - train - INFO - alphas:tensor([0.3878, 0.1523, 0.1299, 0.1442, 0.1858], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,720 - train - INFO - alphas:tensor([0.2846, 0.1261, 0.1173, 0.1613, 0.3107], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,720 - train - INFO - alphas:tensor([0.3946, 0.1469, 0.1281, 0.1483, 0.1821], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,721 - train - INFO - alphas:tensor([0.2649, 0.1275, 0.1193, 0.1661, 0.3222], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,722 - train - INFO - alphas:tensor([0.4210, 0.1426, 0.1344, 0.1419, 0.1600], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,723 - train - INFO - alphas:tensor([0.3991, 0.1433, 0.1310, 0.1448, 0.1819], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,724 - train - INFO - alphas:tensor([0.4257, 0.1452, 0.1268, 0.1388, 0.1635], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,724 - train - INFO - alphas:tensor([0.3589, 0.1340, 0.1243, 0.1500, 0.2329], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,725 - train - INFO - alphas:tensor([0.4270, 0.1416, 0.1271, 0.1393, 0.1649], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,726 - train - INFO - alphas:tensor([0.3398, 0.1313, 0.1228, 0.1494, 0.2567], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,727 - train - INFO - alphas:tensor([0.4283, 0.1405, 0.1305, 0.1411, 0.1596], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,728 - train - INFO - alphas:tensor([0.4069, 0.1393, 0.1315, 0.1425, 0.1798], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,728 - train - INFO - alphas:tensor([0.4020, 0.1377, 0.1259, 0.1420, 0.1925], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,729 - train - INFO - alphas:tensor([0.2800, 0.1051, 0.1048, 0.1385, 0.3716], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,730 - train - INFO - alphas:tensor([0.4131, 0.1363, 0.1238, 0.1415, 0.1853], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,731 - train - INFO - alphas:tensor([0.2362, 0.1055, 0.1037, 0.1483, 0.4062], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,731 - train - INFO - alphas:tensor([0.4400, 0.1381, 0.1290, 0.1350, 0.1579], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,732 - train - INFO - alphas:tensor([0.2560, 0.1316, 0.1179, 0.1531, 0.3413], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 11:51:32,732 - train - INFO - lasso_alpha:3.993000000000001e-05
2024-01-31 11:51:34,802 - train - INFO - Test: [   0/39]  Time: 2.048 (2.048s) Loss:  0.4272 (0.4272)  Acc@1: 93.3594 (93.3594)  Acc@5: 100.0000 (100.0000)
2024-01-31 11:52:49,329 - train - INFO - Test: [  39/39]  Time: 2.060 (76.575s) Loss:  0.5220 (0.4446)  Acc@1: 93.7500 (93.1900)  Acc@5: 100.0000 (99.7600)
2024-01-31 11:52:51,940 - train - INFO - Train: 15 [   0/195 (  0%)]  Loss:  1.535339 (1.5353)  Time: 2.462s (2.462s),  103.98/s  (2.462s,  103.98/s)  LR: 5.368e-04  Data: 0.173 (0.173)
2024-01-31 11:54:38,580 - train - INFO - Train: 15 [  50/195 ( 26%)]  Loss:  1.590274 (1.4396)  Time: 2.167s (109.101s),  118.12/s  (2.139s,  119.67/s)  LR: 5.368e-04  Data: 0.017 (0.012)
2024-01-31 11:56:36,863 - train - INFO - Train: 15 [ 100/195 ( 52%)]  Loss:  1.401095 (1.4365)  Time: 2.350s (227.382s),  108.94/s  (2.251s,  113.71/s)  LR: 5.368e-04  Data: 0.009 (0.010)
2024-01-31 11:58:30,234 - train - INFO - Train: 15 [ 150/195 ( 77%)]  Loss:  1.308843 (1.4394)  Time: 2.263s (340.750s),  113.13/s  (2.257s,  113.44/s)  LR: 5.368e-04  Data: 0.006 (0.010)
2024-01-31 12:00:07,945 - train - INFO - Train: 15 [ 194/195 (100%)]  Loss:  1.612375 (1.4485)  Time: 2.428s (438.459s),  105.44/s  (2.249s,  113.85/s)  LR: 5.368e-04  Data: 0.000 (0.010)
2024-01-31 12:00:07,947 - train - INFO - alphas:tensor([0.5258, 0.2370, 0.2371], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,948 - train - INFO - alphas:tensor([0.4894, 0.2406, 0.2699], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,949 - train - INFO - alphas:tensor([0.5262, 0.2364, 0.2374], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,950 - train - INFO - alphas:tensor([0.4635, 0.2553, 0.2813], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,951 - train - INFO - alphas:tensor([0.5310, 0.2286, 0.2404], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,952 - train - INFO - alphas:tensor([0.3282, 0.1586, 0.1454, 0.1667, 0.2010], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,953 - train - INFO - alphas:tensor([0.5336, 0.2279, 0.2384], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,954 - train - INFO - alphas:tensor([0.4611, 0.2454, 0.2934], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,954 - train - INFO - alphas:tensor([0.5377, 0.2226, 0.2397], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,955 - train - INFO - alphas:tensor([0.4367, 0.2475, 0.3158], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,956 - train - INFO - alphas:tensor([0.3796, 0.1623, 0.1391, 0.1505, 0.1685], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,957 - train - INFO - alphas:tensor([0.3724, 0.1553, 0.1398, 0.1540, 0.1785], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,958 - train - INFO - alphas:tensor([0.3869, 0.1509, 0.1343, 0.1477, 0.1802], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,958 - train - INFO - alphas:tensor([0.3102, 0.1287, 0.1183, 0.1560, 0.2868], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,959 - train - INFO - alphas:tensor([0.3953, 0.1484, 0.1270, 0.1420, 0.1873], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,960 - train - INFO - alphas:tensor([0.2791, 0.1211, 0.1140, 0.1600, 0.3257], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,961 - train - INFO - alphas:tensor([0.4002, 0.1438, 0.1258, 0.1468, 0.1833], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,961 - train - INFO - alphas:tensor([0.2595, 0.1225, 0.1152, 0.1648, 0.3380], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,962 - train - INFO - alphas:tensor([0.4320, 0.1383, 0.1313, 0.1396, 0.1587], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,963 - train - INFO - alphas:tensor([0.4061, 0.1397, 0.1277, 0.1428, 0.1837], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,964 - train - INFO - alphas:tensor([0.4342, 0.1413, 0.1242, 0.1367, 0.1636], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,964 - train - INFO - alphas:tensor([0.3596, 0.1295, 0.1212, 0.1490, 0.2408], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,965 - train - INFO - alphas:tensor([0.4365, 0.1381, 0.1244, 0.1373, 0.1637], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,966 - train - INFO - alphas:tensor([0.3384, 0.1267, 0.1194, 0.1481, 0.2673], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,967 - train - INFO - alphas:tensor([0.4380, 0.1375, 0.1277, 0.1387, 0.1581], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,968 - train - INFO - alphas:tensor([0.4143, 0.1357, 0.1287, 0.1402, 0.1811], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,968 - train - INFO - alphas:tensor([0.4049, 0.1343, 0.1234, 0.1407, 0.1968], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,969 - train - INFO - alphas:tensor([0.2744, 0.1000, 0.1000, 0.1347, 0.3909], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,970 - train - INFO - alphas:tensor([0.4177, 0.1325, 0.1210, 0.1399, 0.1889], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,971 - train - INFO - alphas:tensor([0.2327, 0.1008, 0.0990, 0.1452, 0.4223], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,971 - train - INFO - alphas:tensor([0.4501, 0.1354, 0.1256, 0.1319, 0.1571], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,972 - train - INFO - alphas:tensor([0.2528, 0.1272, 0.1148, 0.1511, 0.3542], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:00:07,972 - train - INFO - lasso_alpha:4.392300000000002e-05
2024-01-31 12:00:10,197 - train - INFO - Test: [   0/39]  Time: 2.216 (2.216s) Loss:  0.4204 (0.4204)  Acc@1: 92.5781 (92.5781)  Acc@5: 100.0000 (100.0000)
2024-01-31 12:01:24,840 - train - INFO - Test: [  39/39]  Time: 1.831 (76.859s) Loss:  0.5005 (0.4126)  Acc@1: 93.7500 (93.0900)  Acc@5: 100.0000 (99.8300)
2024-01-31 12:01:27,729 - train - INFO - Train: 16 [   0/195 (  0%)]  Loss:  1.533334 (1.5333)  Time: 2.804s (2.804s),   91.30/s  (2.804s,   91.30/s)  LR: 5.350e-04  Data: 0.276 (0.276)
2024-01-31 12:03:24,443 - train - INFO - Train: 16 [  50/195 ( 26%)]  Loss:  1.606150 (1.4664)  Time: 2.444s (119.516s),  104.77/s  (2.343s,  109.24/s)  LR: 5.350e-04  Data: 0.009 (0.013)
2024-01-31 12:05:14,430 - train - INFO - Train: 16 [ 100/195 ( 52%)]  Loss:  1.313017 (1.4629)  Time: 2.306s (229.502s),  111.00/s  (2.272s,  112.66/s)  LR: 5.350e-04  Data: 0.010 (0.011)
2024-01-31 12:07:03,936 - train - INFO - Train: 16 [ 150/195 ( 77%)]  Loss:  1.294442 (1.4714)  Time: 1.812s (339.006s),  141.26/s  (2.245s,  114.03/s)  LR: 5.350e-04  Data: 0.018 (0.010)
2024-01-31 12:08:42,688 - train - INFO - Train: 16 [ 194/195 (100%)]  Loss:  1.482878 (1.4710)  Time: 2.450s (437.756s),  104.49/s  (2.245s,  114.04/s)  LR: 5.350e-04  Data: 0.000 (0.010)
2024-01-31 12:08:42,690 - train - INFO - alphas:tensor([0.5297, 0.2347, 0.2356], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,690 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,691 - train - INFO - alphas:tensor([0.4929, 0.2376, 0.2695], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,691 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,692 - train - INFO - alphas:tensor([0.5340, 0.2315, 0.2345], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,692 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,693 - train - INFO - alphas:tensor([0.4627, 0.2535, 0.2838], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,693 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,694 - train - INFO - alphas:tensor([0.5378, 0.2258, 0.2365], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,694 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,694 - train - INFO - alphas:tensor([0.3342, 0.1553, 0.1426, 0.1649, 0.2030], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,695 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,697 - train - INFO - alphas:tensor([0.5411, 0.2238, 0.2351], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,697 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,697 - train - INFO - alphas:tensor([0.4569, 0.2448, 0.2983], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,697 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,698 - train - INFO - alphas:tensor([0.5403, 0.2209, 0.2388], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,698 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,699 - train - INFO - alphas:tensor([0.4342, 0.2451, 0.3207], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,699 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,700 - train - INFO - alphas:tensor([0.3871, 0.1601, 0.1368, 0.1486, 0.1675], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,700 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,701 - train - INFO - alphas:tensor([0.3784, 0.1528, 0.1374, 0.1527, 0.1788], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,701 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,702 - train - INFO - alphas:tensor([0.3896, 0.1485, 0.1321, 0.1468, 0.1830], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,702 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,703 - train - INFO - alphas:tensor([0.3052, 0.1239, 0.1147, 0.1546, 0.3016], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,703 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,703 - train - INFO - alphas:tensor([0.4005, 0.1460, 0.1244, 0.1407, 0.1884], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,704 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,704 - train - INFO - alphas:tensor([0.2768, 0.1164, 0.1107, 0.1579, 0.3382], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,704 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,705 - train - INFO - alphas:tensor([0.4058, 0.1405, 0.1230, 0.1453, 0.1853], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,705 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,706 - train - INFO - alphas:tensor([0.2557, 0.1176, 0.1106, 0.1621, 0.3540], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,706 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,707 - train - INFO - alphas:tensor([0.4416, 0.1351, 0.1287, 0.1379, 0.1567], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,707 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,708 - train - INFO - alphas:tensor([0.4128, 0.1359, 0.1244, 0.1413, 0.1856], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,708 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,709 - train - INFO - alphas:tensor([0.4415, 0.1380, 0.1218, 0.1346, 0.1642], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,709 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,710 - train - INFO - alphas:tensor([0.3577, 0.1252, 0.1182, 0.1481, 0.2507], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,710 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,710 - train - INFO - alphas:tensor([0.4466, 0.1344, 0.1212, 0.1348, 0.1631], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,711 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,711 - train - INFO - alphas:tensor([0.3349, 0.1221, 0.1153, 0.1459, 0.2818], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,711 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,712 - train - INFO - alphas:tensor([0.4474, 0.1344, 0.1249, 0.1361, 0.1571], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,712 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,713 - train - INFO - alphas:tensor([0.4206, 0.1328, 0.1256, 0.1379, 0.1830], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,713 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,714 - train - INFO - alphas:tensor([0.4067, 0.1299, 0.1210, 0.1402, 0.2022], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,714 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,715 - train - INFO - alphas:tensor([0.2688, 0.0952, 0.0957, 0.1309, 0.4094], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,715 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,716 - train - INFO - alphas:tensor([0.4215, 0.1285, 0.1181, 0.1382, 0.1937], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,716 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,717 - train - INFO - alphas:tensor([0.2265, 0.0964, 0.0945, 0.1409, 0.4418], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,717 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,718 - train - INFO - alphas:tensor([0.4608, 0.1322, 0.1225, 0.1289, 0.1556], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,718 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,719 - train - INFO - alphas:tensor([0.2477, 0.1226, 0.1109, 0.1484, 0.3703], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:08:42,719 - train - INFO - tau:0.10541625963246036
2024-01-31 12:08:42,719 - train - INFO - lasso_alpha:4.392300000000002e-05
2024-01-31 12:08:44,773 - train - INFO - Test: [   0/39]  Time: 2.046 (2.046s) Loss:  0.4229 (0.4229)  Acc@1: 92.9688 (92.9688)  Acc@5: 100.0000 (100.0000)
2024-01-31 12:09:58,397 - train - INFO - Test: [  39/39]  Time: 1.654 (75.670s) Loss:  0.5698 (0.4342)  Acc@1: 93.7500 (93.3200)  Acc@5: 100.0000 (99.7400)
2024-01-31 12:10:00,726 - train - INFO - Train: 17 [   0/195 (  0%)]  Loss:  1.614591 (1.6146)  Time: 2.173s (2.173s),  117.81/s  (2.173s,  117.81/s)  LR: 5.331e-04  Data: 0.278 (0.278)
2024-01-31 12:11:51,833 - train - INFO - Train: 17 [  50/195 ( 26%)]  Loss:  1.567468 (1.4664)  Time: 2.109s (113.279s),  121.38/s  (2.221s,  115.26/s)  LR: 5.331e-04  Data: 0.004 (0.014)
2024-01-31 12:13:50,791 - train - INFO - Train: 17 [ 100/195 ( 52%)]  Loss:  1.498588 (1.4658)  Time: 2.308s (232.235s),  110.93/s  (2.299s,  111.34/s)  LR: 5.331e-04  Data: 0.007 (0.011)
2024-01-31 12:15:42,796 - train - INFO - Train: 17 [ 150/195 ( 77%)]  Loss:  1.577174 (1.4669)  Time: 2.353s (344.239s),  108.80/s  (2.280s,  112.29/s)  LR: 5.331e-04  Data: 0.005 (0.010)
2024-01-31 12:17:20,075 - train - INFO - Train: 17 [ 194/195 (100%)]  Loss:  1.565454 (1.4634)  Time: 2.389s (441.516s),  107.14/s  (2.264s,  113.06/s)  LR: 5.331e-04  Data: 0.000 (0.009)
2024-01-31 12:17:20,077 - train - INFO - alphas:tensor([0.5365, 0.2319, 0.2316], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,078 - train - INFO - alphas:tensor([0.4940, 0.2360, 0.2700], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,079 - train - INFO - alphas:tensor([0.5391, 0.2295, 0.2314], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,080 - train - INFO - alphas:tensor([0.4630, 0.2518, 0.2853], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,080 - train - INFO - alphas:tensor([0.5422, 0.2232, 0.2346], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,081 - train - INFO - alphas:tensor([0.3375, 0.1529, 0.1403, 0.1640, 0.2053], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,082 - train - INFO - alphas:tensor([0.5449, 0.2216, 0.2335], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,083 - train - INFO - alphas:tensor([0.4575, 0.2404, 0.3021], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,083 - train - INFO - alphas:tensor([0.5448, 0.2174, 0.2378], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,084 - train - INFO - alphas:tensor([0.4315, 0.2414, 0.3271], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,085 - train - INFO - alphas:tensor([0.3937, 0.1578, 0.1348, 0.1472, 0.1664], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,086 - train - INFO - alphas:tensor([0.3854, 0.1504, 0.1351, 0.1509, 0.1782], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,087 - train - INFO - alphas:tensor([0.3938, 0.1462, 0.1303, 0.1451, 0.1846], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,087 - train - INFO - alphas:tensor([0.3030, 0.1186, 0.1106, 0.1527, 0.3152], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,088 - train - INFO - alphas:tensor([0.4052, 0.1423, 0.1221, 0.1385, 0.1919], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,089 - train - INFO - alphas:tensor([0.2722, 0.1113, 0.1066, 0.1554, 0.3545], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,090 - train - INFO - alphas:tensor([0.4087, 0.1384, 0.1212, 0.1444, 0.1872], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,091 - train - INFO - alphas:tensor([0.2492, 0.1123, 0.1061, 0.1601, 0.3723], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,091 - train - INFO - alphas:tensor([0.4508, 0.1326, 0.1267, 0.1351, 0.1547], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,092 - train - INFO - alphas:tensor([0.4195, 0.1322, 0.1215, 0.1393, 0.1875], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,093 - train - INFO - alphas:tensor([0.4492, 0.1353, 0.1191, 0.1321, 0.1643], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,094 - train - INFO - alphas:tensor([0.3562, 0.1216, 0.1148, 0.1465, 0.2609], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,095 - train - INFO - alphas:tensor([0.4563, 0.1306, 0.1179, 0.1323, 0.1630], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,095 - train - INFO - alphas:tensor([0.3337, 0.1180, 0.1114, 0.1443, 0.2926], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,096 - train - INFO - alphas:tensor([0.4552, 0.1315, 0.1227, 0.1343, 0.1563], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,097 - train - INFO - alphas:tensor([0.4274, 0.1292, 0.1220, 0.1358, 0.1855], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,098 - train - INFO - alphas:tensor([0.4117, 0.1260, 0.1176, 0.1379, 0.2067], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,099 - train - INFO - alphas:tensor([0.2631, 0.0913, 0.0916, 0.1275, 0.4265], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,099 - train - INFO - alphas:tensor([0.4251, 0.1252, 0.1150, 0.1363, 0.1983], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,100 - train - INFO - alphas:tensor([0.2232, 0.0927, 0.0903, 0.1370, 0.4567], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,101 - train - INFO - alphas:tensor([0.4687, 0.1289, 0.1204, 0.1268, 0.1553], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,102 - train - INFO - alphas:tensor([0.2438, 0.1185, 0.1072, 0.1460, 0.3846], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:17:20,102 - train - INFO - lasso_alpha:4.392300000000002e-05
2024-01-31 12:17:22,177 - train - INFO - Test: [   0/39]  Time: 2.068 (2.068s) Loss:  0.4119 (0.4119)  Acc@1: 94.1406 (94.1406)  Acc@5: 100.0000 (100.0000)
2024-01-31 12:18:37,323 - train - INFO - Test: [  39/39]  Time: 1.888 (77.214s) Loss:  0.4524 (0.4384)  Acc@1: 93.7500 (93.0600)  Acc@5: 100.0000 (99.7900)
2024-01-31 12:18:39,671 - train - INFO - Train: 18 [   0/195 (  0%)]  Loss:  1.422210 (1.4222)  Time: 2.261s (2.261s),  113.21/s  (2.261s,  113.21/s)  LR: 5.310e-04  Data: 0.179 (0.179)
2024-01-31 12:20:31,832 - train - INFO - Train: 18 [  50/195 ( 26%)]  Loss:  1.442219 (1.4680)  Time: 2.500s (114.421s),  102.39/s  (2.244s,  114.10/s)  LR: 5.310e-04  Data: 0.004 (0.011)
2024-01-31 12:22:19,804 - train - INFO - Train: 18 [ 100/195 ( 52%)]  Loss:  1.492175 (1.4505)  Time: 1.982s (222.392s),  129.14/s  (2.202s,  116.26/s)  LR: 5.310e-04  Data: 0.006 (0.010)
2024-01-31 12:24:04,577 - train - INFO - Train: 18 [ 150/195 ( 77%)]  Loss:  1.571305 (1.4472)  Time: 2.188s (327.164s),  117.01/s  (2.167s,  118.15/s)  LR: 5.310e-04  Data: 0.011 (0.009)
2024-01-31 12:25:45,073 - train - INFO - Train: 18 [ 194/195 (100%)]  Loss:  1.394678 (1.4481)  Time: 2.333s (427.659s),  109.75/s  (2.193s,  116.73/s)  LR: 5.310e-04  Data: 0.000 (0.009)
2024-01-31 12:25:45,075 - train - INFO - alphas:tensor([0.5410, 0.2292, 0.2298], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,076 - train - INFO - alphas:tensor([0.4966, 0.2340, 0.2694], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,077 - train - INFO - alphas:tensor([0.5455, 0.2260, 0.2285], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,078 - train - INFO - alphas:tensor([0.4647, 0.2491, 0.2861], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,078 - train - INFO - alphas:tensor([0.5483, 0.2204, 0.2313], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,079 - train - INFO - alphas:tensor([0.3412, 0.1506, 0.1380, 0.1632, 0.2071], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,080 - train - INFO - alphas:tensor([0.5492, 0.2191, 0.2316], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,081 - train - INFO - alphas:tensor([0.4515, 0.2397, 0.3088], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,081 - train - INFO - alphas:tensor([0.5479, 0.2150, 0.2370], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,082 - train - INFO - alphas:tensor([0.4282, 0.2390, 0.3327], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,083 - train - INFO - alphas:tensor([0.4004, 0.1545, 0.1326, 0.1459, 0.1666], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,084 - train - INFO - alphas:tensor([0.3926, 0.1480, 0.1321, 0.1488, 0.1785], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,084 - train - INFO - alphas:tensor([0.4004, 0.1426, 0.1279, 0.1428, 0.1862], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,085 - train - INFO - alphas:tensor([0.3000, 0.1146, 0.1066, 0.1507, 0.3281], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,086 - train - INFO - alphas:tensor([0.4093, 0.1381, 0.1194, 0.1381, 0.1951], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,087 - train - INFO - alphas:tensor([0.2649, 0.1076, 0.1033, 0.1540, 0.3702], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,088 - train - INFO - alphas:tensor([0.4108, 0.1362, 0.1194, 0.1432, 0.1903], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,088 - train - INFO - alphas:tensor([0.2460, 0.1077, 0.1019, 0.1575, 0.3869], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,089 - train - INFO - alphas:tensor([0.4591, 0.1303, 0.1244, 0.1328, 0.1535], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,090 - train - INFO - alphas:tensor([0.4247, 0.1291, 0.1185, 0.1377, 0.1901], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,091 - train - INFO - alphas:tensor([0.4540, 0.1341, 0.1178, 0.1301, 0.1640], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,091 - train - INFO - alphas:tensor([0.3557, 0.1176, 0.1111, 0.1445, 0.2710], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,092 - train - INFO - alphas:tensor([0.4629, 0.1282, 0.1159, 0.1301, 0.1629], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,093 - train - INFO - alphas:tensor([0.3286, 0.1138, 0.1082, 0.1436, 0.3058], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,094 - train - INFO - alphas:tensor([0.4644, 0.1281, 0.1202, 0.1319, 0.1554], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,095 - train - INFO - alphas:tensor([0.4334, 0.1255, 0.1192, 0.1342, 0.1877], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,095 - train - INFO - alphas:tensor([0.4106, 0.1231, 0.1153, 0.1375, 0.2136], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,096 - train - INFO - alphas:tensor([0.2595, 0.0871, 0.0876, 0.1239, 0.4420], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,097 - train - INFO - alphas:tensor([0.4256, 0.1223, 0.1126, 0.1354, 0.2042], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,098 - train - INFO - alphas:tensor([0.2200, 0.0889, 0.0864, 0.1328, 0.4718], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,098 - train - INFO - alphas:tensor([0.4775, 0.1255, 0.1173, 0.1244, 0.1552], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,099 - train - INFO - alphas:tensor([0.2402, 0.1143, 0.1043, 0.1437, 0.3975], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:25:45,100 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 12:25:47,071 - train - INFO - Test: [   0/39]  Time: 1.962 (1.962s) Loss:  0.4434 (0.4434)  Acc@1: 92.9688 (92.9688)  Acc@5: 100.0000 (100.0000)
2024-01-31 12:27:00,826 - train - INFO - Test: [  39/39]  Time: 1.619 (75.717s) Loss:  0.4502 (0.4493)  Acc@1: 93.7500 (92.8100)  Acc@5: 100.0000 (99.7500)
2024-01-31 12:27:03,367 - train - INFO - Train: 19 [   0/195 (  0%)]  Loss:  1.600539 (1.6005)  Time: 2.444s (2.444s),  104.77/s  (2.444s,  104.77/s)  LR: 5.289e-04  Data: 0.228 (0.228)
2024-01-31 12:28:52,614 - train - INFO - Train: 19 [  50/195 ( 26%)]  Loss:  1.488990 (1.4691)  Time: 2.369s (111.689s),  108.06/s  (2.190s,  116.90/s)  LR: 5.289e-04  Data: 0.010 (0.013)
2024-01-31 12:30:43,892 - train - INFO - Train: 19 [ 100/195 ( 52%)]  Loss:  1.356889 (1.4536)  Time: 2.419s (222.966s),  105.84/s  (2.208s,  115.96/s)  LR: 5.289e-04  Data: 0.009 (0.011)
2024-01-31 12:32:35,911 - train - INFO - Train: 19 [ 150/195 ( 77%)]  Loss:  1.372827 (1.4519)  Time: 2.031s (334.982s),  126.06/s  (2.218s,  115.40/s)  LR: 5.289e-04  Data: 0.012 (0.010)
2024-01-31 12:34:10,942 - train - INFO - Train: 19 [ 194/195 (100%)]  Loss:  1.648233 (1.4506)  Time: 2.249s (430.010s),  113.83/s  (2.205s,  116.09/s)  LR: 5.289e-04  Data: 0.000 (0.010)
2024-01-31 12:34:10,954 - train - INFO - alphas:tensor([0.5465, 0.2269, 0.2266], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,955 - train - INFO - alphas:tensor([0.4973, 0.2327, 0.2700], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,955 - train - INFO - alphas:tensor([0.5495, 0.2235, 0.2270], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,956 - train - INFO - alphas:tensor([0.4626, 0.2480, 0.2894], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,957 - train - INFO - alphas:tensor([0.5507, 0.2190, 0.2304], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,958 - train - INFO - alphas:tensor([0.3423, 0.1482, 0.1365, 0.1624, 0.2107], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,958 - train - INFO - alphas:tensor([0.5524, 0.2173, 0.2303], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,959 - train - INFO - alphas:tensor([0.4489, 0.2379, 0.3132], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,960 - train - INFO - alphas:tensor([0.5482, 0.2149, 0.2369], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,961 - train - INFO - alphas:tensor([0.4207, 0.2371, 0.3421], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,961 - train - INFO - alphas:tensor([0.4072, 0.1528, 0.1303, 0.1443, 0.1653], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,962 - train - INFO - alphas:tensor([0.3971, 0.1458, 0.1299, 0.1475, 0.1796], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,967 - train - INFO - alphas:tensor([0.4014, 0.1398, 0.1262, 0.1434, 0.1892], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,968 - train - INFO - alphas:tensor([0.2922, 0.1110, 0.1036, 0.1495, 0.3437], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,969 - train - INFO - alphas:tensor([0.4125, 0.1359, 0.1173, 0.1372, 0.1971], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,970 - train - INFO - alphas:tensor([0.2583, 0.1032, 0.0997, 0.1520, 0.3869], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,971 - train - INFO - alphas:tensor([0.4090, 0.1341, 0.1180, 0.1435, 0.1954], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,971 - train - INFO - alphas:tensor([0.2397, 0.1034, 0.0981, 0.1554, 0.4035], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,972 - train - INFO - alphas:tensor([0.4665, 0.1284, 0.1223, 0.1310, 0.1518], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,973 - train - INFO - alphas:tensor([0.4275, 0.1261, 0.1161, 0.1366, 0.1936], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,978 - train - INFO - alphas:tensor([0.4614, 0.1314, 0.1149, 0.1279, 0.1644], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,979 - train - INFO - alphas:tensor([0.3543, 0.1131, 0.1077, 0.1428, 0.2821], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,979 - train - INFO - alphas:tensor([0.4686, 0.1252, 0.1133, 0.1287, 0.1642], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,980 - train - INFO - alphas:tensor([0.3226, 0.1097, 0.1052, 0.1421, 0.3204], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,981 - train - INFO - alphas:tensor([0.4696, 0.1260, 0.1184, 0.1303, 0.1557], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,982 - train - INFO - alphas:tensor([0.4365, 0.1224, 0.1165, 0.1330, 0.1917], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,983 - train - INFO - alphas:tensor([0.4114, 0.1190, 0.1120, 0.1359, 0.2217], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,983 - train - INFO - alphas:tensor([0.2536, 0.0835, 0.0836, 0.1195, 0.4598], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,989 - train - INFO - alphas:tensor([0.4268, 0.1192, 0.1100, 0.1339, 0.2101], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,989 - train - INFO - alphas:tensor([0.2134, 0.0844, 0.0823, 0.1295, 0.4904], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,990 - train - INFO - alphas:tensor([0.4851, 0.1220, 0.1146, 0.1225, 0.1558], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,991 - train - INFO - alphas:tensor([0.2360, 0.1103, 0.1007, 0.1408, 0.4122], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:34:10,991 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 12:34:13,110 - train - INFO - Test: [   0/39]  Time: 2.111 (2.111s) Loss:  0.4417 (0.4417)  Acc@1: 92.9688 (92.9688)  Acc@5: 100.0000 (100.0000)
2024-01-31 12:35:28,046 - train - INFO - Test: [  39/39]  Time: 1.701 (77.046s) Loss:  0.4775 (0.4442)  Acc@1: 87.5000 (93.0800)  Acc@5: 100.0000 (99.8200)
2024-01-31 12:35:30,608 - train - INFO - Train: 20 [   0/195 (  0%)]  Loss:  1.348833 (1.3488)  Time: 2.466s (2.466s),  103.79/s  (2.466s,  103.79/s)  LR: 5.267e-04  Data: 0.290 (0.290)
2024-01-31 12:37:19,732 - train - INFO - Train: 20 [  50/195 ( 26%)]  Loss:  1.359614 (1.4881)  Time: 2.338s (111.589s),  109.50/s  (2.188s,  117.00/s)  LR: 5.267e-04  Data: 0.005 (0.015)
2024-01-31 12:39:08,715 - train - INFO - Train: 20 [ 100/195 ( 52%)]  Loss:  1.534066 (1.4719)  Time: 2.363s (220.571s),  108.35/s  (2.184s,  117.22/s)  LR: 5.267e-04  Data: 0.010 (0.013)
2024-01-31 12:41:00,706 - train - INFO - Train: 20 [ 150/195 ( 77%)]  Loss:  1.355330 (1.4645)  Time: 2.209s (332.560s),  115.91/s  (2.202s,  116.24/s)  LR: 5.267e-04  Data: 0.007 (0.011)
2024-01-31 12:42:37,963 - train - INFO - Train: 20 [ 194/195 (100%)]  Loss:  1.602524 (1.4639)  Time: 2.438s (429.815s),  105.01/s  (2.204s,  116.14/s)  LR: 5.267e-04  Data: 0.000 (0.010)
2024-01-31 12:42:37,967 - train - INFO - alphas:tensor([0.5493, 0.2249, 0.2258], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,967 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,968 - train - INFO - alphas:tensor([0.4980, 0.2311, 0.2709], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,968 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,969 - train - INFO - alphas:tensor([0.5538, 0.2209, 0.2254], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,970 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,971 - train - INFO - alphas:tensor([0.4630, 0.2460, 0.2910], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,971 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,972 - train - INFO - alphas:tensor([0.5546, 0.2162, 0.2292], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,972 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,973 - train - INFO - alphas:tensor([0.3461, 0.1454, 0.1338, 0.1611, 0.2135], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,973 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,974 - train - INFO - alphas:tensor([0.5535, 0.2157, 0.2307], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,974 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,975 - train - INFO - alphas:tensor([0.4460, 0.2355, 0.3186], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,975 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,976 - train - INFO - alphas:tensor([0.5490, 0.2134, 0.2377], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,976 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,976 - train - INFO - alphas:tensor([0.4158, 0.2336, 0.3506], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,977 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,978 - train - INFO - alphas:tensor([0.4125, 0.1514, 0.1284, 0.1430, 0.1647], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,978 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,979 - train - INFO - alphas:tensor([0.4022, 0.1441, 0.1277, 0.1456, 0.1804], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,979 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,980 - train - INFO - alphas:tensor([0.4035, 0.1376, 0.1235, 0.1424, 0.1930], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,980 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,981 - train - INFO - alphas:tensor([0.2867, 0.1065, 0.1004, 0.1466, 0.3597], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,981 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,982 - train - INFO - alphas:tensor([0.4130, 0.1327, 0.1153, 0.1369, 0.2020], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,982 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,983 - train - INFO - alphas:tensor([0.2537, 0.0994, 0.0960, 0.1497, 0.4012], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,983 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,984 - train - INFO - alphas:tensor([0.4094, 0.1313, 0.1156, 0.1426, 0.2010], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,984 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,985 - train - INFO - alphas:tensor([0.2352, 0.0990, 0.0944, 0.1530, 0.4183], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,985 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,986 - train - INFO - alphas:tensor([0.4760, 0.1255, 0.1191, 0.1290, 0.1505], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,986 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,987 - train - INFO - alphas:tensor([0.4335, 0.1224, 0.1131, 0.1343, 0.1968], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,987 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,988 - train - INFO - alphas:tensor([0.4682, 0.1289, 0.1120, 0.1260, 0.1648], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,988 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,989 - train - INFO - alphas:tensor([0.3513, 0.1098, 0.1044, 0.1413, 0.2933], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,989 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,990 - train - INFO - alphas:tensor([0.4737, 0.1226, 0.1112, 0.1276, 0.1649], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,990 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,990 - train - INFO - alphas:tensor([0.3180, 0.1052, 0.1020, 0.1402, 0.3346], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,991 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,991 - train - INFO - alphas:tensor([0.4764, 0.1235, 0.1160, 0.1285, 0.1556], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,992 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,992 - train - INFO - alphas:tensor([0.4401, 0.1191, 0.1137, 0.1312, 0.1959], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,992 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,993 - train - INFO - alphas:tensor([0.4096, 0.1165, 0.1097, 0.1356, 0.2286], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,993 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,994 - train - INFO - alphas:tensor([0.2479, 0.0805, 0.0804, 0.1158, 0.4753], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,994 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,995 - train - INFO - alphas:tensor([0.4281, 0.1159, 0.1076, 0.1328, 0.2156], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,995 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,996 - train - INFO - alphas:tensor([0.2100, 0.0812, 0.0787, 0.1258, 0.5044], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,996 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,997 - train - INFO - alphas:tensor([0.4934, 0.1187, 0.1119, 0.1202, 0.1558], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,997 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,998 - train - INFO - alphas:tensor([0.2340, 0.1075, 0.0973, 0.1379, 0.4234], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:42:37,998 - train - INFO - tau:0.0843330077059683
2024-01-31 12:42:37,998 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 12:42:40,064 - train - INFO - Test: [   0/39]  Time: 2.057 (2.057s) Loss:  0.4299 (0.4299)  Acc@1: 94.5312 (94.5312)  Acc@5: 99.6094 (99.6094)
2024-01-31 12:43:54,759 - train - INFO - Test: [  39/39]  Time: 1.993 (76.751s) Loss:  0.4287 (0.4495)  Acc@1: 93.7500 (92.9900)  Acc@5: 100.0000 (99.8100)
2024-01-31 12:43:57,157 - train - INFO - Train: 21 [   0/195 (  0%)]  Loss:  1.336036 (1.3360)  Time: 2.275s (2.275s),  112.54/s  (2.275s,  112.54/s)  LR: 5.243e-04  Data: 0.139 (0.139)
2024-01-31 12:45:49,196 - train - INFO - Train: 21 [  50/195 ( 26%)]  Loss:  1.271145 (1.4599)  Time: 2.241s (114.312s),  114.24/s  (2.241s,  114.21/s)  LR: 5.243e-04  Data: 0.005 (0.013)
2024-01-31 12:47:41,926 - train - INFO - Train: 21 [ 100/195 ( 52%)]  Loss:  1.606884 (1.4609)  Time: 2.202s (227.040s),  116.25/s  (2.248s,  113.88/s)  LR: 5.243e-04  Data: 0.027 (0.013)
2024-01-31 12:49:32,642 - train - INFO - Train: 21 [ 150/195 ( 77%)]  Loss:  1.334015 (1.4596)  Time: 2.421s (337.755s),  105.73/s  (2.237s,  114.45/s)  LR: 5.243e-04  Data: 0.032 (0.012)
2024-01-31 12:51:16,148 - train - INFO - Train: 21 [ 194/195 (100%)]  Loss:  1.412197 (1.4629)  Time: 2.449s (441.255s),  104.53/s  (2.263s,  113.13/s)  LR: 5.243e-04  Data: 0.000 (0.011)
2024-01-31 12:51:16,149 - train - INFO - alphas:tensor([0.5543, 0.2229, 0.2228], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,150 - train - INFO - alphas:tensor([0.4973, 0.2298, 0.2729], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,151 - train - INFO - alphas:tensor([0.5560, 0.2196, 0.2244], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,152 - train - INFO - alphas:tensor([0.4628, 0.2441, 0.2932], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,152 - train - INFO - alphas:tensor([0.5599, 0.2133, 0.2268], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,153 - train - INFO - alphas:tensor([0.3480, 0.1430, 0.1320, 0.1604, 0.2167], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,154 - train - INFO - alphas:tensor([0.5555, 0.2140, 0.2304], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,155 - train - INFO - alphas:tensor([0.4419, 0.2333, 0.3247], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,155 - train - INFO - alphas:tensor([0.5531, 0.2109, 0.2360], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,156 - train - INFO - alphas:tensor([0.4118, 0.2298, 0.3584], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,157 - train - INFO - alphas:tensor([0.4189, 0.1498, 0.1266, 0.1410, 0.1637], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,158 - train - INFO - alphas:tensor([0.4070, 0.1408, 0.1259, 0.1445, 0.1818], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,158 - train - INFO - alphas:tensor([0.4076, 0.1350, 0.1218, 0.1405, 0.1952], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,159 - train - INFO - alphas:tensor([0.2843, 0.1033, 0.0972, 0.1438, 0.3715], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,160 - train - INFO - alphas:tensor([0.4142, 0.1309, 0.1139, 0.1363, 0.2047], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,161 - train - INFO - alphas:tensor([0.2508, 0.0964, 0.0925, 0.1466, 0.4137], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,162 - train - INFO - alphas:tensor([0.4120, 0.1277, 0.1128, 0.1418, 0.2056], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,162 - train - INFO - alphas:tensor([0.2336, 0.0962, 0.0918, 0.1499, 0.4284], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,163 - train - INFO - alphas:tensor([0.4823, 0.1237, 0.1175, 0.1276, 0.1489], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,164 - train - INFO - alphas:tensor([0.4355, 0.1201, 0.1107, 0.1333, 0.2004], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,165 - train - INFO - alphas:tensor([0.4724, 0.1267, 0.1102, 0.1251, 0.1656], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,166 - train - INFO - alphas:tensor([0.3480, 0.1062, 0.1020, 0.1392, 0.3047], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,167 - train - INFO - alphas:tensor([0.4807, 0.1201, 0.1087, 0.1254, 0.1651], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,167 - train - INFO - alphas:tensor([0.3154, 0.1010, 0.0987, 0.1391, 0.3458], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,168 - train - INFO - alphas:tensor([0.4846, 0.1208, 0.1135, 0.1263, 0.1547], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,169 - train - INFO - alphas:tensor([0.4430, 0.1160, 0.1110, 0.1294, 0.2006], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,170 - train - INFO - alphas:tensor([0.4106, 0.1135, 0.1073, 0.1342, 0.2343], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,171 - train - INFO - alphas:tensor([0.2481, 0.0776, 0.0773, 0.1125, 0.4845], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,172 - train - INFO - alphas:tensor([0.4290, 0.1126, 0.1050, 0.1311, 0.2222], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,172 - train - INFO - alphas:tensor([0.2059, 0.0778, 0.0752, 0.1222, 0.5189], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,173 - train - INFO - alphas:tensor([0.5004, 0.1162, 0.1099, 0.1187, 0.1547], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,174 - train - INFO - alphas:tensor([0.2324, 0.1047, 0.0942, 0.1351, 0.4336], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:51:16,174 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 12:51:18,384 - train - INFO - Test: [   0/39]  Time: 2.203 (2.203s) Loss:  0.4358 (0.4358)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)
2024-01-31 12:52:32,843 - train - INFO - Test: [  39/39]  Time: 1.883 (76.662s) Loss:  0.5435 (0.4648)  Acc@1: 87.5000 (92.5200)  Acc@5: 100.0000 (99.7500)
2024-01-31 12:52:35,307 - train - INFO - Train: 22 [   0/195 (  0%)]  Loss:  1.593504 (1.5935)  Time: 2.343s (2.343s),  109.28/s  (2.343s,  109.28/s)  LR: 5.218e-04  Data: 0.220 (0.220)
2024-01-31 12:54:23,887 - train - INFO - Train: 22 [  50/195 ( 26%)]  Loss:  1.532627 (1.4889)  Time: 2.308s (110.920s),  110.92/s  (2.175s,  117.71/s)  LR: 5.218e-04  Data: 0.005 (0.014)
2024-01-31 12:56:13,920 - train - INFO - Train: 22 [ 100/195 ( 52%)]  Loss:  1.397114 (1.4822)  Time: 2.436s (220.949s),  105.10/s  (2.188s,  117.02/s)  LR: 5.218e-04  Data: 0.009 (0.012)
2024-01-31 12:58:09,615 - train - INFO - Train: 22 [ 150/195 ( 77%)]  Loss:  1.327144 (1.4737)  Time: 2.301s (336.643s),  111.24/s  (2.229s,  114.83/s)  LR: 5.218e-04  Data: 0.005 (0.011)
2024-01-31 12:59:49,264 - train - INFO - Train: 22 [ 194/195 (100%)]  Loss:  1.343830 (1.4704)  Time: 2.379s (436.289s),  107.60/s  (2.237s,  114.42/s)  LR: 5.218e-04  Data: 0.000 (0.010)
2024-01-31 12:59:49,268 - train - INFO - alphas:tensor([0.5580, 0.2212, 0.2209], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,269 - train - INFO - alphas:tensor([0.4985, 0.2281, 0.2734], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,269 - train - INFO - alphas:tensor([0.5578, 0.2185, 0.2237], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,271 - train - INFO - alphas:tensor([0.4607, 0.2431, 0.2963], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,272 - train - INFO - alphas:tensor([0.5656, 0.2104, 0.2239], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,273 - train - INFO - alphas:tensor([0.3505, 0.1413, 0.1301, 0.1591, 0.2190], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,273 - train - INFO - alphas:tensor([0.5571, 0.2120, 0.2309], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,274 - train - INFO - alphas:tensor([0.4396, 0.2297, 0.3307], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,275 - train - INFO - alphas:tensor([0.5549, 0.2101, 0.2350], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,276 - train - INFO - alphas:tensor([0.4087, 0.2274, 0.3640], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,277 - train - INFO - alphas:tensor([0.4237, 0.1480, 0.1253, 0.1399, 0.1630], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,278 - train - INFO - alphas:tensor([0.4130, 0.1385, 0.1244, 0.1429, 0.1812], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,278 - train - INFO - alphas:tensor([0.4097, 0.1322, 0.1198, 0.1398, 0.1985], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,279 - train - INFO - alphas:tensor([0.2799, 0.0996, 0.0936, 0.1420, 0.3849], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,280 - train - INFO - alphas:tensor([0.4155, 0.1288, 0.1120, 0.1367, 0.2070], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,281 - train - INFO - alphas:tensor([0.2491, 0.0927, 0.0887, 0.1444, 0.4252], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,281 - train - INFO - alphas:tensor([0.4101, 0.1255, 0.1112, 0.1415, 0.2117], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,282 - train - INFO - alphas:tensor([0.2295, 0.0925, 0.0883, 0.1472, 0.4426], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,283 - train - INFO - alphas:tensor([0.4897, 0.1211, 0.1151, 0.1259, 0.1482], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,284 - train - INFO - alphas:tensor([0.4370, 0.1168, 0.1084, 0.1326, 0.2052], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,285 - train - INFO - alphas:tensor([0.4750, 0.1240, 0.1091, 0.1244, 0.1675], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,286 - train - INFO - alphas:tensor([0.3454, 0.1027, 0.0989, 0.1371, 0.3159], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,287 - train - INFO - alphas:tensor([0.4873, 0.1173, 0.1058, 0.1233, 0.1663], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,287 - train - INFO - alphas:tensor([0.3102, 0.0972, 0.0953, 0.1372, 0.3601], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,288 - train - INFO - alphas:tensor([0.4912, 0.1184, 0.1111, 0.1249, 0.1544], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,289 - train - INFO - alphas:tensor([0.4462, 0.1130, 0.1084, 0.1283, 0.2040], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,290 - train - INFO - alphas:tensor([0.4101, 0.1096, 0.1048, 0.1330, 0.2425], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,291 - train - INFO - alphas:tensor([0.2448, 0.0750, 0.0743, 0.1093, 0.4967], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,292 - train - INFO - alphas:tensor([0.4265, 0.1095, 0.1024, 0.1310, 0.2306], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,292 - train - INFO - alphas:tensor([0.2039, 0.0758, 0.0727, 0.1192, 0.5283], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,293 - train - INFO - alphas:tensor([0.5074, 0.1133, 0.1077, 0.1166, 0.1549], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,294 - train - INFO - alphas:tensor([0.2274, 0.1014, 0.0915, 0.1326, 0.4471], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 12:59:49,295 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 12:59:51,447 - train - INFO - Test: [   0/39]  Time: 2.146 (2.146s) Loss:  0.4102 (0.4102)  Acc@1: 92.5781 (92.5781)  Acc@5: 100.0000 (100.0000)
2024-01-31 13:01:05,521 - train - INFO - Test: [  39/39]  Time: 1.864 (76.220s) Loss:  0.6079 (0.4269)  Acc@1: 81.2500 (93.2000)  Acc@5: 100.0000 (99.7700)
2024-01-31 13:01:07,892 - train - INFO - Train: 23 [   0/195 (  0%)]  Loss:  1.508451 (1.5085)  Time: 2.158s (2.158s),  118.61/s  (2.158s,  118.61/s)  LR: 5.193e-04  Data: 0.160 (0.160)
2024-01-31 13:03:04,058 - train - INFO - Train: 23 [  50/195 ( 26%)]  Loss:  1.334534 (1.4750)  Time: 2.310s (118.321s),  110.83/s  (2.320s,  110.34/s)  LR: 5.193e-04  Data: 0.009 (0.012)
2024-01-31 13:04:52,233 - train - INFO - Train: 23 [ 100/195 ( 52%)]  Loss:  1.612065 (1.4589)  Time: 2.122s (226.493s),  120.63/s  (2.243s,  114.16/s)  LR: 5.193e-04  Data: 0.011 (0.011)
2024-01-31 13:06:42,998 - train - INFO - Train: 23 [ 150/195 ( 77%)]  Loss:  1.299906 (1.4571)  Time: 2.443s (337.257s),  104.81/s  (2.233s,  114.62/s)  LR: 5.193e-04  Data: 0.010 (0.010)
2024-01-31 13:08:29,559 - train - INFO - Train: 23 [ 194/195 (100%)]  Loss:  1.605380 (1.4617)  Time: 2.451s (443.816s),  104.44/s  (2.276s,  112.48/s)  LR: 5.193e-04  Data: 0.000 (0.009)
2024-01-31 13:08:29,563 - train - INFO - alphas:tensor([0.5599, 0.2204, 0.2197], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,564 - train - INFO - alphas:tensor([0.4987, 0.2270, 0.2743], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,564 - train - INFO - alphas:tensor([0.5596, 0.2172, 0.2232], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,565 - train - INFO - alphas:tensor([0.4603, 0.2415, 0.2982], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,566 - train - INFO - alphas:tensor([0.5665, 0.2099, 0.2237], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,567 - train - INFO - alphas:tensor([0.3529, 0.1398, 0.1273, 0.1580, 0.2220], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,568 - train - INFO - alphas:tensor([0.5554, 0.2123, 0.2323], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,569 - train - INFO - alphas:tensor([0.4363, 0.2278, 0.3358], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,569 - train - INFO - alphas:tensor([0.5602, 0.2052, 0.2346], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,570 - train - INFO - alphas:tensor([0.4040, 0.2246, 0.3714], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,571 - train - INFO - alphas:tensor([0.4301, 0.1464, 0.1234, 0.1378, 0.1624], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,572 - train - INFO - alphas:tensor([0.4190, 0.1354, 0.1216, 0.1413, 0.1827], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,573 - train - INFO - alphas:tensor([0.4089, 0.1303, 0.1183, 0.1393, 0.2032], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,574 - train - INFO - alphas:tensor([0.2768, 0.0963, 0.0905, 0.1396, 0.3968], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,575 - train - INFO - alphas:tensor([0.4133, 0.1269, 0.1106, 0.1364, 0.2128], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,575 - train - INFO - alphas:tensor([0.2434, 0.0895, 0.0853, 0.1411, 0.4406], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,576 - train - INFO - alphas:tensor([0.4083, 0.1224, 0.1092, 0.1421, 0.2180], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,577 - train - INFO - alphas:tensor([0.2235, 0.0889, 0.0856, 0.1447, 0.4573], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,578 - train - INFO - alphas:tensor([0.4964, 0.1196, 0.1131, 0.1238, 0.1470], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,579 - train - INFO - alphas:tensor([0.4416, 0.1128, 0.1049, 0.1312, 0.2095], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,580 - train - INFO - alphas:tensor([0.4820, 0.1215, 0.1065, 0.1226, 0.1674], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,581 - train - INFO - alphas:tensor([0.3413, 0.0996, 0.0967, 0.1365, 0.3259], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,582 - train - INFO - alphas:tensor([0.4925, 0.1142, 0.1034, 0.1218, 0.1681], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,582 - train - INFO - alphas:tensor([0.3070, 0.0945, 0.0918, 0.1348, 0.3719], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,583 - train - INFO - alphas:tensor([0.4988, 0.1158, 0.1088, 0.1226, 0.1540], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,584 - train - INFO - alphas:tensor([0.4462, 0.1104, 0.1063, 0.1275, 0.2096], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,585 - train - INFO - alphas:tensor([0.4080, 0.1065, 0.1019, 0.1323, 0.2513], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,586 - train - INFO - alphas:tensor([0.2442, 0.0724, 0.0719, 0.1065, 0.5050], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,587 - train - INFO - alphas:tensor([0.4255, 0.1073, 0.1004, 0.1296, 0.2373], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,588 - train - INFO - alphas:tensor([0.2020, 0.0732, 0.0701, 0.1164, 0.5383], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,588 - train - INFO - alphas:tensor([0.5125, 0.1105, 0.1053, 0.1155, 0.1561], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,589 - train - INFO - alphas:tensor([0.2255, 0.0987, 0.0887, 0.1299, 0.4573], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:08:29,590 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 13:08:31,754 - train - INFO - Test: [   0/39]  Time: 2.158 (2.158s) Loss:  0.4272 (0.4272)  Acc@1: 92.1875 (92.1875)  Acc@5: 100.0000 (100.0000)
2024-01-31 13:09:45,816 - train - INFO - Test: [  39/39]  Time: 1.841 (76.219s) Loss:  0.4343 (0.4292)  Acc@1: 93.7500 (93.3900)  Acc@5: 100.0000 (99.8300)
2024-01-31 13:09:48,443 - train - INFO - Train: 24 [   0/195 (  0%)]  Loss:  1.500462 (1.5005)  Time: 2.478s (2.478s),  103.32/s  (2.478s,  103.32/s)  LR: 5.166e-04  Data: 0.212 (0.212)
2024-01-31 13:11:47,310 - train - INFO - Train: 24 [  50/195 ( 26%)]  Loss:  1.433321 (1.4941)  Time: 2.312s (121.344s),  110.74/s  (2.379s,  107.60/s)  LR: 5.166e-04  Data: 0.011 (0.012)
2024-01-31 13:13:35,156 - train - INFO - Train: 24 [ 100/195 ( 52%)]  Loss:  1.409034 (1.4788)  Time: 2.127s (229.187s),  120.33/s  (2.269s,  112.82/s)  LR: 5.166e-04  Data: 0.013 (0.011)
2024-01-31 13:15:21,702 - train - INFO - Train: 24 [ 150/195 ( 77%)]  Loss:  1.303857 (1.4734)  Time: 2.288s (335.730s),  111.90/s  (2.223s,  115.14/s)  LR: 5.166e-04  Data: 0.005 (0.010)
2024-01-31 13:17:02,761 - train - INFO - Train: 24 [ 194/195 (100%)]  Loss:  1.615541 (1.4717)  Time: 2.428s (436.787s),  105.42/s  (2.240s,  114.29/s)  LR: 5.166e-04  Data: 0.000 (0.009)
2024-01-31 13:17:02,764 - train - INFO - alphas:tensor([0.5631, 0.2190, 0.2179], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,764 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,765 - train - INFO - alphas:tensor([0.4982, 0.2249, 0.2769], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,765 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,766 - train - INFO - alphas:tensor([0.5632, 0.2155, 0.2213], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,766 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,767 - train - INFO - alphas:tensor([0.4589, 0.2394, 0.3017], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,767 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,768 - train - INFO - alphas:tensor([0.5682, 0.2082, 0.2236], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,768 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,769 - train - INFO - alphas:tensor([0.3550, 0.1369, 0.1259, 0.1568, 0.2253], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,769 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,770 - train - INFO - alphas:tensor([0.5612, 0.2082, 0.2307], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,770 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,771 - train - INFO - alphas:tensor([0.4338, 0.2254, 0.3407], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,771 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,772 - train - INFO - alphas:tensor([0.5605, 0.2048, 0.2347], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,772 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,773 - train - INFO - alphas:tensor([0.3994, 0.2227, 0.3779], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,773 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,774 - train - INFO - alphas:tensor([0.4342, 0.1450, 0.1224, 0.1371, 0.1613], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,774 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,775 - train - INFO - alphas:tensor([0.4239, 0.1335, 0.1199, 0.1400, 0.1827], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,775 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,776 - train - INFO - alphas:tensor([0.4077, 0.1287, 0.1171, 0.1395, 0.2071], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,776 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,777 - train - INFO - alphas:tensor([0.2733, 0.0931, 0.0881, 0.1376, 0.4079], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,777 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,778 - train - INFO - alphas:tensor([0.4162, 0.1249, 0.1079, 0.1354, 0.2156], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,778 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,779 - train - INFO - alphas:tensor([0.2402, 0.0860, 0.0825, 0.1381, 0.4532], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,779 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,780 - train - INFO - alphas:tensor([0.4106, 0.1201, 0.1071, 0.1412, 0.2211], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,780 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,781 - train - INFO - alphas:tensor([0.2203, 0.0861, 0.0827, 0.1421, 0.4689], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,781 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,782 - train - INFO - alphas:tensor([0.5010, 0.1170, 0.1113, 0.1227, 0.1480], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,782 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,783 - train - INFO - alphas:tensor([0.4414, 0.1108, 0.1034, 0.1304, 0.2140], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,783 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,784 - train - INFO - alphas:tensor([0.4887, 0.1190, 0.1039, 0.1206, 0.1678], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,784 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,785 - train - INFO - alphas:tensor([0.3411, 0.0960, 0.0936, 0.1347, 0.3345], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,785 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,786 - train - INFO - alphas:tensor([0.4941, 0.1126, 0.1023, 0.1208, 0.1702], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,786 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,787 - train - INFO - alphas:tensor([0.3065, 0.0919, 0.0887, 0.1317, 0.3811], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,787 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,788 - train - INFO - alphas:tensor([0.5046, 0.1145, 0.1070, 0.1206, 0.1533], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,788 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,789 - train - INFO - alphas:tensor([0.4494, 0.1069, 0.1037, 0.1257, 0.2143], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,789 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,790 - train - INFO - alphas:tensor([0.4060, 0.1048, 0.0997, 0.1311, 0.2583], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,790 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,791 - train - INFO - alphas:tensor([0.2412, 0.0693, 0.0693, 0.1040, 0.5162], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,791 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,792 - train - INFO - alphas:tensor([0.4242, 0.1047, 0.0976, 0.1279, 0.2456], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,792 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,793 - train - INFO - alphas:tensor([0.2011, 0.0710, 0.0673, 0.1129, 0.5477], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,793 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,794 - train - INFO - alphas:tensor([0.5194, 0.1080, 0.1035, 0.1137, 0.1553], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,794 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,795 - train - INFO - alphas:tensor([0.2234, 0.0965, 0.0863, 0.1274, 0.4664], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:17:02,795 - train - INFO - tau:0.06746640616477464
2024-01-31 13:17:02,795 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 13:17:05,031 - train - INFO - Test: [   0/39]  Time: 2.227 (2.227s) Loss:  0.4011 (0.4011)  Acc@1: 93.3594 (93.3594)  Acc@5: 100.0000 (100.0000)
2024-01-31 13:18:17,685 - train - INFO - Test: [  39/39]  Time: 1.646 (74.880s) Loss:  0.4688 (0.4273)  Acc@1: 93.7500 (93.0500)  Acc@5: 100.0000 (99.7400)
2024-01-31 13:18:20,051 - train - INFO - Train: 25 [   0/195 (  0%)]  Loss:  1.294918 (1.2949)  Time: 2.172s (2.172s),  117.88/s  (2.172s,  117.88/s)  LR: 5.138e-04  Data: 0.253 (0.253)
2024-01-31 13:20:12,414 - train - INFO - Train: 25 [  50/195 ( 26%)]  Loss:  1.299874 (1.4391)  Time: 2.350s (114.532s),  108.91/s  (2.246s,  113.99/s)  LR: 5.138e-04  Data: 0.004 (0.013)
2024-01-31 13:22:09,457 - train - INFO - Train: 25 [ 100/195 ( 52%)]  Loss:  1.445797 (1.4500)  Time: 2.203s (231.574s),  116.23/s  (2.293s,  111.65/s)  LR: 5.138e-04  Data: 0.006 (0.011)
2024-01-31 13:23:53,824 - train - INFO - Train: 25 [ 150/195 ( 77%)]  Loss:  1.695178 (1.4599)  Time: 1.887s (335.939s),  135.69/s  (2.225s,  115.07/s)  LR: 5.138e-04  Data: 0.005 (0.010)
2024-01-31 13:25:35,111 - train - INFO - Train: 25 [ 194/195 (100%)]  Loss:  1.513454 (1.4594)  Time: 2.386s (437.223s),  107.29/s  (2.242s,  114.18/s)  LR: 5.138e-04  Data: 0.000 (0.010)
2024-01-31 13:25:35,113 - train - INFO - alphas:tensor([0.5642, 0.2176, 0.2182], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,114 - train - INFO - alphas:tensor([0.4978, 0.2231, 0.2791], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,115 - train - INFO - alphas:tensor([0.5672, 0.2131, 0.2197], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,115 - train - INFO - alphas:tensor([0.4575, 0.2378, 0.3047], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,116 - train - INFO - alphas:tensor([0.5716, 0.2069, 0.2215], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,117 - train - INFO - alphas:tensor([0.3575, 0.1348, 0.1244, 0.1557, 0.2277], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,118 - train - INFO - alphas:tensor([0.5590, 0.2076, 0.2334], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,118 - train - INFO - alphas:tensor([0.4313, 0.2240, 0.3446], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,119 - train - INFO - alphas:tensor([0.5610, 0.2042, 0.2348], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,120 - train - INFO - alphas:tensor([0.3962, 0.2198, 0.3839], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,121 - train - INFO - alphas:tensor([0.4411, 0.1429, 0.1197, 0.1355, 0.1608], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,122 - train - INFO - alphas:tensor([0.4270, 0.1318, 0.1177, 0.1392, 0.1842], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,123 - train - INFO - alphas:tensor([0.4098, 0.1267, 0.1153, 0.1383, 0.2099], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,124 - train - INFO - alphas:tensor([0.2702, 0.0908, 0.0856, 0.1350, 0.4183], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,124 - train - INFO - alphas:tensor([0.4165, 0.1220, 0.1065, 0.1350, 0.2202], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,125 - train - INFO - alphas:tensor([0.2369, 0.0835, 0.0803, 0.1356, 0.4638], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,126 - train - INFO - alphas:tensor([0.4047, 0.1181, 0.1061, 0.1420, 0.2292], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,127 - train - INFO - alphas:tensor([0.2171, 0.0831, 0.0797, 0.1398, 0.4804], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,128 - train - INFO - alphas:tensor([0.5075, 0.1151, 0.1096, 0.1209, 0.1468], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,129 - train - INFO - alphas:tensor([0.4429, 0.1087, 0.1015, 0.1290, 0.2179], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,129 - train - INFO - alphas:tensor([0.4917, 0.1165, 0.1022, 0.1196, 0.1699], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,130 - train - INFO - alphas:tensor([0.3391, 0.0935, 0.0914, 0.1333, 0.3427], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,131 - train - INFO - alphas:tensor([0.4973, 0.1109, 0.1013, 0.1203, 0.1702], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,132 - train - INFO - alphas:tensor([0.3061, 0.0892, 0.0853, 0.1292, 0.3903], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,133 - train - INFO - alphas:tensor([0.5122, 0.1119, 0.1051, 0.1184, 0.1524], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,133 - train - INFO - alphas:tensor([0.4492, 0.1037, 0.1016, 0.1247, 0.2207], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,134 - train - INFO - alphas:tensor([0.4020, 0.1027, 0.0982, 0.1308, 0.2663], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,135 - train - INFO - alphas:tensor([0.2380, 0.0673, 0.0671, 0.1014, 0.5261], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,136 - train - INFO - alphas:tensor([0.4236, 0.1021, 0.0957, 0.1268, 0.2517], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,137 - train - INFO - alphas:tensor([0.1998, 0.0695, 0.0654, 0.1104, 0.5549], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,138 - train - INFO - alphas:tensor([0.5246, 0.1056, 0.1014, 0.1122, 0.1563], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,138 - train - INFO - alphas:tensor([0.2207, 0.0943, 0.0844, 0.1258, 0.4747], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:25:35,139 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 13:25:37,293 - train - INFO - Test: [   0/39]  Time: 2.147 (2.147s) Loss:  0.4255 (0.4255)  Acc@1: 94.1406 (94.1406)  Acc@5: 99.6094 (99.6094)
2024-01-31 13:26:49,816 - train - INFO - Test: [  39/39]  Time: 2.000 (74.670s) Loss:  0.5166 (0.4280)  Acc@1: 93.7500 (93.2500)  Acc@5: 100.0000 (99.8300)
2024-01-31 13:26:52,564 - train - INFO - Train: 26 [   0/195 (  0%)]  Loss:  1.644635 (1.6446)  Time: 2.658s (2.658s),   96.30/s  (2.658s,   96.30/s)  LR: 5.109e-04  Data: 0.243 (0.243)
2024-01-31 13:28:44,019 - train - INFO - Train: 26 [  50/195 ( 26%)]  Loss:  1.636619 (1.4665)  Time: 2.354s (114.109s),  108.75/s  (2.237s,  114.42/s)  LR: 5.109e-04  Data: 0.004 (0.013)
2024-01-31 13:30:33,560 - train - INFO - Train: 26 [ 100/195 ( 52%)]  Loss:  1.323968 (1.4721)  Time: 2.199s (223.640s),  116.39/s  (2.214s,  115.61/s)  LR: 5.109e-04  Data: 0.006 (0.011)
2024-01-31 13:32:49,699 - train - INFO - Train: 26 [ 150/195 ( 77%)]  Loss:  1.328286 (1.4700)  Time: 2.622s (359.777s),   97.63/s  (2.383s,  107.44/s)  LR: 5.109e-04  Data: 0.005 (0.010)
2024-01-31 13:34:59,117 - train - INFO - Train: 26 [ 194/195 (100%)]  Loss:  1.554536 (1.4671)  Time: 3.021s (489.190s),   84.75/s  (2.509s,  102.05/s)  LR: 5.109e-04  Data: 0.000 (0.010)
2024-01-31 13:34:59,118 - train - INFO - alphas:tensor([0.5652, 0.2169, 0.2180], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,119 - train - INFO - alphas:tensor([0.5000, 0.2205, 0.2795], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,120 - train - INFO - alphas:tensor([0.5663, 0.2129, 0.2208], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,121 - train - INFO - alphas:tensor([0.4543, 0.2372, 0.3085], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,122 - train - INFO - alphas:tensor([0.5749, 0.2052, 0.2199], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,122 - train - INFO - alphas:tensor([0.3576, 0.1330, 0.1224, 0.1551, 0.2319], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,123 - train - INFO - alphas:tensor([0.5608, 0.2055, 0.2337], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,125 - train - INFO - alphas:tensor([0.4261, 0.2224, 0.3515], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,126 - train - INFO - alphas:tensor([0.5582, 0.2051, 0.2366], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,127 - train - INFO - alphas:tensor([0.3941, 0.2167, 0.3893], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,128 - train - INFO - alphas:tensor([0.4455, 0.1416, 0.1184, 0.1347, 0.1598], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,128 - train - INFO - alphas:tensor([0.4318, 0.1299, 0.1157, 0.1375, 0.1850], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,129 - train - INFO - alphas:tensor([0.4138, 0.1244, 0.1128, 0.1377, 0.2113], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,130 - train - INFO - alphas:tensor([0.2666, 0.0881, 0.0827, 0.1323, 0.4304], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,131 - train - INFO - alphas:tensor([0.4161, 0.1203, 0.1051, 0.1340, 0.2245], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,132 - train - INFO - alphas:tensor([0.2335, 0.0807, 0.0774, 0.1335, 0.4748], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,133 - train - INFO - alphas:tensor([0.4057, 0.1158, 0.1039, 0.1408, 0.2338], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,133 - train - INFO - alphas:tensor([0.2145, 0.0814, 0.0769, 0.1367, 0.4904], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,134 - train - INFO - alphas:tensor([0.5160, 0.1129, 0.1074, 0.1190, 0.1448], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,135 - train - INFO - alphas:tensor([0.4423, 0.1066, 0.0998, 0.1277, 0.2235], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,136 - train - INFO - alphas:tensor([0.4908, 0.1147, 0.1013, 0.1198, 0.1734], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,137 - train - INFO - alphas:tensor([0.3378, 0.0904, 0.0887, 0.1319, 0.3513], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,138 - train - INFO - alphas:tensor([0.5008, 0.1089, 0.0995, 0.1193, 0.1715], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,138 - train - INFO - alphas:tensor([0.3033, 0.0862, 0.0826, 0.1281, 0.3998], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,139 - train - INFO - alphas:tensor([0.5162, 0.1106, 0.1033, 0.1172, 0.1527], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,140 - train - INFO - alphas:tensor([0.4477, 0.1009, 0.0997, 0.1241, 0.2276], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,141 - train - INFO - alphas:tensor([0.3996, 0.1011, 0.0968, 0.1293, 0.2731], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,142 - train - INFO - alphas:tensor([0.2357, 0.0653, 0.0649, 0.0989, 0.5352], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,142 - train - INFO - alphas:tensor([0.4189, 0.0999, 0.0942, 0.1265, 0.2605], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,143 - train - INFO - alphas:tensor([0.1982, 0.0672, 0.0631, 0.1072, 0.5642], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,144 - train - INFO - alphas:tensor([0.5291, 0.1034, 0.0991, 0.1109, 0.1574], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,145 - train - INFO - alphas:tensor([0.2200, 0.0923, 0.0820, 0.1232, 0.4825], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:34:59,145 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 13:35:01,884 - train - INFO - Test: [   0/39]  Time: 2.731 (2.731s) Loss:  0.4377 (0.4377)  Acc@1: 91.7969 (91.7969)  Acc@5: 99.6094 (99.6094)
2024-01-31 13:36:32,188 - train - INFO - Test: [  39/39]  Time: 1.843 (93.019s) Loss:  0.4878 (0.4386)  Acc@1: 93.7500 (93.0000)  Acc@5: 100.0000 (99.7800)
2024-01-31 13:36:34,989 - train - INFO - Train: 27 [   0/195 (  0%)]  Loss:  1.645821 (1.6458)  Time: 2.514s (2.514s),  101.82/s  (2.514s,  101.82/s)  LR: 5.080e-04  Data: 0.213 (0.213)
2024-01-31 13:38:58,334 - train - INFO - Train: 27 [  50/195 ( 26%)]  Loss:  1.523127 (1.4547)  Time: 2.936s (145.858s),   87.20/s  (2.860s,   89.51/s)  LR: 5.080e-04  Data: 0.018 (0.016)
2024-01-31 13:41:21,747 - train - INFO - Train: 27 [ 100/195 ( 52%)]  Loss:  1.667271 (1.4571)  Time: 2.733s (289.265s),   93.66/s  (2.864s,   89.39/s)  LR: 5.080e-04  Data: 0.005 (0.014)
2024-01-31 13:43:43,847 - train - INFO - Train: 27 [ 150/195 ( 77%)]  Loss:  1.628827 (1.4590)  Time: 2.651s (431.363s),   96.56/s  (2.857s,   89.61/s)  LR: 5.080e-04  Data: 0.006 (0.013)
2024-01-31 13:45:47,565 - train - INFO - Train: 27 [ 194/195 (100%)]  Loss:  1.504843 (1.4600)  Time: 2.985s (555.079s),   85.77/s  (2.847s,   89.93/s)  LR: 5.080e-04  Data: 0.000 (0.013)
2024-01-31 13:45:47,569 - train - INFO - alphas:tensor([0.5686, 0.2155, 0.2159], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,570 - train - INFO - alphas:tensor([0.4998, 0.2199, 0.2804], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,570 - train - INFO - alphas:tensor([0.5688, 0.2113, 0.2199], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,571 - train - INFO - alphas:tensor([0.4536, 0.2361, 0.3103], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,572 - train - INFO - alphas:tensor([0.5767, 0.2039, 0.2194], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,573 - train - INFO - alphas:tensor([0.3565, 0.1320, 0.1218, 0.1546, 0.2351], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,574 - train - INFO - alphas:tensor([0.5621, 0.2043, 0.2336], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,574 - train - INFO - alphas:tensor([0.4231, 0.2196, 0.3573], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,575 - train - INFO - alphas:tensor([0.5619, 0.2021, 0.2360], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,576 - train - INFO - alphas:tensor([0.3913, 0.2139, 0.3948], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,577 - train - INFO - alphas:tensor([0.4501, 0.1391, 0.1170, 0.1338, 0.1599], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,578 - train - INFO - alphas:tensor([0.4325, 0.1288, 0.1144, 0.1374, 0.1869], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,579 - train - INFO - alphas:tensor([0.4154, 0.1224, 0.1113, 0.1373, 0.2135], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,580 - train - INFO - alphas:tensor([0.2645, 0.0858, 0.0810, 0.1304, 0.4382], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,580 - train - INFO - alphas:tensor([0.4133, 0.1188, 0.1043, 0.1345, 0.2291], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,581 - train - INFO - alphas:tensor([0.2305, 0.0782, 0.0752, 0.1313, 0.4848], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,582 - train - INFO - alphas:tensor([0.4052, 0.1132, 0.1030, 0.1401, 0.2385], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,583 - train - INFO - alphas:tensor([0.2115, 0.0790, 0.0746, 0.1338, 0.5010], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,584 - train - INFO - alphas:tensor([0.5243, 0.1111, 0.1051, 0.1163, 0.1432], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,589 - train - INFO - alphas:tensor([0.4411, 0.1047, 0.0981, 0.1270, 0.2291], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,590 - train - INFO - alphas:tensor([0.4947, 0.1120, 0.0994, 0.1187, 0.1752], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,591 - train - INFO - alphas:tensor([0.3349, 0.0881, 0.0864, 0.1302, 0.3605], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,592 - train - INFO - alphas:tensor([0.5063, 0.1067, 0.0975, 0.1170, 0.1724], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,593 - train - INFO - alphas:tensor([0.2995, 0.0839, 0.0799, 0.1260, 0.4107], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,598 - train - INFO - alphas:tensor([0.5229, 0.1088, 0.1013, 0.1152, 0.1518], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,599 - train - INFO - alphas:tensor([0.4471, 0.0995, 0.0979, 0.1238, 0.2317], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,600 - train - INFO - alphas:tensor([0.3969, 0.0983, 0.0945, 0.1290, 0.2813], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,601 - train - INFO - alphas:tensor([0.2350, 0.0634, 0.0625, 0.0963, 0.5428], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,601 - train - INFO - alphas:tensor([0.4210, 0.0980, 0.0913, 0.1250, 0.2647], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,602 - train - INFO - alphas:tensor([0.1966, 0.0660, 0.0615, 0.1054, 0.5705], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,603 - train - INFO - alphas:tensor([0.5328, 0.1015, 0.0975, 0.1096, 0.1586], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,604 - train - INFO - alphas:tensor([0.2190, 0.0906, 0.0802, 0.1210, 0.4892], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:45:47,604 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 13:45:50,299 - train - INFO - Test: [   0/39]  Time: 2.682 (2.682s) Loss:  0.4084 (0.4084)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)
2024-01-31 13:47:20,730 - train - INFO - Test: [  39/39]  Time: 1.956 (93.114s) Loss:  0.4067 (0.4300)  Acc@1: 93.7500 (93.0500)  Acc@5: 100.0000 (99.8300)
2024-01-31 13:47:23,978 - train - INFO - Train: 28 [   0/195 (  0%)]  Loss:  1.401906 (1.4019)  Time: 3.021s (3.021s),   84.74/s  (3.021s,   84.74/s)  LR: 5.049e-04  Data: 0.362 (0.362)
2024-01-31 13:49:47,690 - train - INFO - Train: 28 [  50/195 ( 26%)]  Loss:  1.445022 (1.4227)  Time: 2.902s (146.726s),   88.21/s  (2.877s,   88.98/s)  LR: 5.049e-04  Data: 0.009 (0.015)
2024-01-31 13:52:09,304 - train - INFO - Train: 28 [ 100/195 ( 52%)]  Loss:  1.300467 (1.4399)  Time: 2.818s (288.337s),   90.85/s  (2.855s,   89.67/s)  LR: 5.049e-04  Data: 0.007 (0.013)
2024-01-31 13:54:33,625 - train - INFO - Train: 28 [ 150/195 ( 77%)]  Loss:  1.399184 (1.4443)  Time: 2.998s (432.655s),   85.40/s  (2.865s,   89.35/s)  LR: 5.049e-04  Data: 0.007 (0.012)
2024-01-31 13:56:42,654 - train - INFO - Train: 28 [ 194/195 (100%)]  Loss:  1.483733 (1.4430)  Time: 3.037s (561.682s),   84.30/s  (2.880s,   88.88/s)  LR: 5.049e-04  Data: 0.000 (0.011)
2024-01-31 13:56:42,659 - train - INFO - alphas:tensor([0.5688, 0.2151, 0.2161], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,660 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,661 - train - INFO - alphas:tensor([0.4990, 0.2190, 0.2820], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,661 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,675 - train - INFO - alphas:tensor([0.5678, 0.2113, 0.2209], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,675 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,676 - train - INFO - alphas:tensor([0.4502, 0.2343, 0.3155], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,676 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,677 - train - INFO - alphas:tensor([0.5793, 0.2028, 0.2179], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,677 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,692 - train - INFO - alphas:tensor([0.3566, 0.1295, 0.1193, 0.1546, 0.2400], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,692 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,693 - train - INFO - alphas:tensor([0.5625, 0.2028, 0.2346], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,693 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,694 - train - INFO - alphas:tensor([0.4229, 0.2171, 0.3599], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,694 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,695 - train - INFO - alphas:tensor([0.5639, 0.2001, 0.2360], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,695 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,696 - train - INFO - alphas:tensor([0.3854, 0.2141, 0.4005], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,696 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,697 - train - INFO - alphas:tensor([0.4575, 0.1366, 0.1148, 0.1322, 0.1590], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,697 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,698 - train - INFO - alphas:tensor([0.4367, 0.1268, 0.1130, 0.1357, 0.1879], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,698 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,708 - train - INFO - alphas:tensor([0.4159, 0.1200, 0.1101, 0.1371, 0.2170], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,708 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,709 - train - INFO - alphas:tensor([0.2631, 0.0837, 0.0795, 0.1286, 0.4452], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,709 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,710 - train - INFO - alphas:tensor([0.4131, 0.1166, 0.1027, 0.1338, 0.2337], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,711 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,711 - train - INFO - alphas:tensor([0.2256, 0.0756, 0.0732, 0.1300, 0.4956], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,712 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,721 - train - INFO - alphas:tensor([0.4085, 0.1116, 0.1009, 0.1380, 0.2410], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,722 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,722 - train - INFO - alphas:tensor([0.2085, 0.0768, 0.0725, 0.1309, 0.5113], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,723 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,724 - train - INFO - alphas:tensor([0.5293, 0.1105, 0.1034, 0.1145, 0.1423], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,724 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,725 - train - INFO - alphas:tensor([0.4439, 0.1021, 0.0959, 0.1252, 0.2329], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,734 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,735 - train - INFO - alphas:tensor([0.4987, 0.1100, 0.0978, 0.1173, 0.1762], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,735 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,736 - train - INFO - alphas:tensor([0.3325, 0.0859, 0.0842, 0.1288, 0.3686], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,736 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,737 - train - INFO - alphas:tensor([0.5119, 0.1037, 0.0952, 0.1157, 0.1735], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,737 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,738 - train - INFO - alphas:tensor([0.2980, 0.0814, 0.0781, 0.1244, 0.4180], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,738 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,739 - train - INFO - alphas:tensor([0.5249, 0.1072, 0.1000, 0.1148, 0.1530], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,739 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,749 - train - INFO - alphas:tensor([0.4478, 0.0978, 0.0958, 0.1224, 0.2361], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,749 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,750 - train - INFO - alphas:tensor([0.3976, 0.0958, 0.0922, 0.1280, 0.2864], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,750 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,751 - train - INFO - alphas:tensor([0.2341, 0.0618, 0.0608, 0.0938, 0.5495], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,751 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,752 - train - INFO - alphas:tensor([0.4192, 0.0964, 0.0899, 0.1238, 0.2706], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,752 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,753 - train - INFO - alphas:tensor([0.1952, 0.0642, 0.0595, 0.1025, 0.5786], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,753 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,754 - train - INFO - alphas:tensor([0.5360, 0.0998, 0.0958, 0.1087, 0.1598], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,754 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,755 - train - INFO - alphas:tensor([0.2184, 0.0887, 0.0782, 0.1192, 0.4955], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 13:56:42,755 - train - INFO - tau:0.053973124931819716
2024-01-31 13:56:42,756 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 13:56:45,250 - train - INFO - Test: [   0/39]  Time: 2.475 (2.475s) Loss:  0.4050 (0.4050)  Acc@1: 94.5312 (94.5312)  Acc@5: 100.0000 (100.0000)
2024-01-31 13:58:13,689 - train - INFO - Test: [  39/39]  Time: 2.291 (90.914s) Loss:  0.4521 (0.4350)  Acc@1: 93.7500 (93.0300)  Acc@5: 100.0000 (99.7600)
2024-01-31 13:58:17,102 - train - INFO - Train: 29 [   0/195 (  0%)]  Loss:  1.485723 (1.4857)  Time: 3.172s (3.172s),   80.70/s  (3.172s,   80.70/s)  LR: 5.017e-04  Data: 0.346 (0.346)
2024-01-31 14:00:40,456 - train - INFO - Train: 29 [  50/195 ( 26%)]  Loss:  1.449345 (1.4619)  Time: 3.036s (146.525s),   84.34/s  (2.873s,   89.10/s)  LR: 5.017e-04  Data: 0.004 (0.018)
2024-01-31 14:02:57,408 - train - INFO - Train: 29 [ 100/195 ( 52%)]  Loss:  1.573526 (1.4563)  Time: 2.625s (283.476s),   97.53/s  (2.807s,   91.21/s)  LR: 5.017e-04  Data: 0.033 (0.014)
2024-01-31 14:05:16,407 - train - INFO - Train: 29 [ 150/195 ( 77%)]  Loss:  1.643825 (1.4465)  Time: 2.932s (422.469s),   87.33/s  (2.798s,   91.50/s)  LR: 5.017e-04  Data: 0.005 (0.013)
2024-01-31 14:07:25,167 - train - INFO - Train: 29 [ 194/195 (100%)]  Loss:  1.320286 (1.4554)  Time: 2.948s (551.216s),   86.83/s  (2.827s,   90.56/s)  LR: 5.017e-04  Data: 0.000 (0.012)
2024-01-31 14:07:25,184 - train - INFO - alphas:tensor([0.5716, 0.2132, 0.2152], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,185 - train - INFO - alphas:tensor([0.4985, 0.2178, 0.2837], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,186 - train - INFO - alphas:tensor([0.5707, 0.2101, 0.2192], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,186 - train - INFO - alphas:tensor([0.4486, 0.2337, 0.3178], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,187 - train - INFO - alphas:tensor([0.5803, 0.2014, 0.2182], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,188 - train - INFO - alphas:tensor([0.3551, 0.1283, 0.1181, 0.1544, 0.2442], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,189 - train - INFO - alphas:tensor([0.5601, 0.2034, 0.2365], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,189 - train - INFO - alphas:tensor([0.4205, 0.2152, 0.3643], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,190 - train - INFO - alphas:tensor([0.5656, 0.1984, 0.2360], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,200 - train - INFO - alphas:tensor([0.3832, 0.2109, 0.4059], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,201 - train - INFO - alphas:tensor([0.4584, 0.1364, 0.1145, 0.1318, 0.1589], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,210 - train - INFO - alphas:tensor([0.4391, 0.1252, 0.1111, 0.1345, 0.1902], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,211 - train - INFO - alphas:tensor([0.4180, 0.1177, 0.1081, 0.1353, 0.2210], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,212 - train - INFO - alphas:tensor([0.2578, 0.0814, 0.0774, 0.1270, 0.4563], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,212 - train - INFO - alphas:tensor([0.4115, 0.1152, 0.1011, 0.1339, 0.2382], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,213 - train - INFO - alphas:tensor([0.2237, 0.0738, 0.0710, 0.1270, 0.5045], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,214 - train - INFO - alphas:tensor([0.4077, 0.1101, 0.0991, 0.1371, 0.2460], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,215 - train - INFO - alphas:tensor([0.2077, 0.0749, 0.0700, 0.1282, 0.5192], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,216 - train - INFO - alphas:tensor([0.5311, 0.1089, 0.1025, 0.1148, 0.1427], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,216 - train - INFO - alphas:tensor([0.4464, 0.1000, 0.0936, 0.1236, 0.2364], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,217 - train - INFO - alphas:tensor([0.5004, 0.1081, 0.0961, 0.1170, 0.1783], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,218 - train - INFO - alphas:tensor([0.3294, 0.0833, 0.0821, 0.1276, 0.3776], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,219 - train - INFO - alphas:tensor([0.5112, 0.1026, 0.0942, 0.1156, 0.1764], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,228 - train - INFO - alphas:tensor([0.2959, 0.0790, 0.0758, 0.1224, 0.4269], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,229 - train - INFO - alphas:tensor([0.5308, 0.1054, 0.0982, 0.1131, 0.1525], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,230 - train - INFO - alphas:tensor([0.4483, 0.0958, 0.0935, 0.1211, 0.2412], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,231 - train - INFO - alphas:tensor([0.3939, 0.0945, 0.0911, 0.1274, 0.2931], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,231 - train - INFO - alphas:tensor([0.2334, 0.0605, 0.0590, 0.0919, 0.5552], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,232 - train - INFO - alphas:tensor([0.4151, 0.0944, 0.0881, 0.1229, 0.2795], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,233 - train - INFO - alphas:tensor([0.1927, 0.0623, 0.0573, 0.1002, 0.5875], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,234 - train - INFO - alphas:tensor([0.5407, 0.0975, 0.0937, 0.1074, 0.1606], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,235 - train - INFO - alphas:tensor([0.2155, 0.0867, 0.0767, 0.1174, 0.5037], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:07:25,235 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 14:07:27,661 - train - INFO - Test: [   0/39]  Time: 2.409 (2.409s) Loss:  0.4221 (0.4221)  Acc@1: 91.7969 (91.7969)  Acc@5: 100.0000 (100.0000)
2024-01-31 14:08:58,175 - train - INFO - Test: [  39/39]  Time: 2.396 (92.922s) Loss:  0.5107 (0.4235)  Acc@1: 93.7500 (92.8700)  Acc@5: 100.0000 (99.7700)
2024-01-31 14:09:01,516 - train - INFO - Train: 30 [   0/195 (  0%)]  Loss:  1.519444 (1.5194)  Time: 3.121s (3.121s),   82.03/s  (3.121s,   82.03/s)  LR: 4.984e-04  Data: 0.303 (0.303)
2024-01-31 14:11:23,839 - train - INFO - Train: 30 [  50/195 ( 26%)]  Loss:  1.631053 (1.4645)  Time: 2.970s (145.439s),   86.19/s  (2.852s,   89.77/s)  LR: 4.984e-04  Data: 0.005 (0.018)
2024-01-31 14:13:49,173 - train - INFO - Train: 30 [ 100/195 ( 52%)]  Loss:  1.576017 (1.4609)  Time: 2.853s (290.772s),   89.72/s  (2.879s,   88.92/s)  LR: 4.984e-04  Data: 0.006 (0.013)
2024-01-31 14:16:10,933 - train - INFO - Train: 30 [ 150/195 ( 77%)]  Loss:  1.515792 (1.4632)  Time: 3.009s (432.529s),   85.08/s  (2.864s,   89.37/s)  LR: 4.984e-04  Data: 0.007 (0.012)
2024-01-31 14:18:22,530 - train - INFO - Train: 30 [ 194/195 (100%)]  Loss:  1.362677 (1.4598)  Time: 2.926s (564.122s),   87.49/s  (2.893s,   88.49/s)  LR: 4.984e-04  Data: 0.000 (0.011)
2024-01-31 14:18:22,533 - train - INFO - alphas:tensor([0.5748, 0.2111, 0.2141], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,534 - train - INFO - alphas:tensor([0.4980, 0.2171, 0.2849], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,534 - train - INFO - alphas:tensor([0.5719, 0.2100, 0.2181], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,535 - train - INFO - alphas:tensor([0.4489, 0.2321, 0.3190], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,536 - train - INFO - alphas:tensor([0.5830, 0.2013, 0.2158], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,537 - train - INFO - alphas:tensor([0.3567, 0.1260, 0.1166, 0.1542, 0.2465], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,537 - train - INFO - alphas:tensor([0.5604, 0.2027, 0.2370], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,538 - train - INFO - alphas:tensor([0.4180, 0.2141, 0.3679], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,539 - train - INFO - alphas:tensor([0.5651, 0.1965, 0.2385], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,540 - train - INFO - alphas:tensor([0.3770, 0.2087, 0.4143], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,540 - train - INFO - alphas:tensor([0.4631, 0.1347, 0.1129, 0.1301, 0.1592], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,541 - train - INFO - alphas:tensor([0.4422, 0.1236, 0.1092, 0.1328, 0.1922], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,542 - train - INFO - alphas:tensor([0.4164, 0.1160, 0.1063, 0.1352, 0.2262], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,543 - train - INFO - alphas:tensor([0.2569, 0.0794, 0.0754, 0.1257, 0.4625], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,543 - train - INFO - alphas:tensor([0.4124, 0.1135, 0.0997, 0.1333, 0.2411], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,544 - train - INFO - alphas:tensor([0.2224, 0.0714, 0.0689, 0.1243, 0.5130], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,545 - train - INFO - alphas:tensor([0.4053, 0.1087, 0.0981, 0.1379, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,546 - train - INFO - alphas:tensor([0.2051, 0.0733, 0.0684, 0.1262, 0.5271], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,547 - train - INFO - alphas:tensor([0.5372, 0.1076, 0.1005, 0.1128, 0.1418], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,547 - train - INFO - alphas:tensor([0.4439, 0.0985, 0.0918, 0.1226, 0.2432], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,548 - train - INFO - alphas:tensor([0.5047, 0.1067, 0.0946, 0.1154, 0.1785], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,549 - train - INFO - alphas:tensor([0.3269, 0.0817, 0.0801, 0.1266, 0.3847], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,550 - train - INFO - alphas:tensor([0.5112, 0.1008, 0.0926, 0.1153, 0.1800], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,550 - train - INFO - alphas:tensor([0.2967, 0.0766, 0.0730, 0.1196, 0.4340], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,551 - train - INFO - alphas:tensor([0.5354, 0.1034, 0.0962, 0.1118, 0.1532], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,552 - train - INFO - alphas:tensor([0.4485, 0.0942, 0.0919, 0.1195, 0.2459], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,553 - train - INFO - alphas:tensor([0.3911, 0.0916, 0.0891, 0.1269, 0.3013], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,553 - train - INFO - alphas:tensor([0.2312, 0.0589, 0.0569, 0.0902, 0.5628], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,554 - train - INFO - alphas:tensor([0.4170, 0.0926, 0.0866, 0.1211, 0.2827], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,555 - train - INFO - alphas:tensor([0.1920, 0.0613, 0.0559, 0.0979, 0.5930], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,556 - train - INFO - alphas:tensor([0.5432, 0.0965, 0.0924, 0.1057, 0.1621], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,557 - train - INFO - alphas:tensor([0.2145, 0.0854, 0.0750, 0.1158, 0.5094], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:18:22,557 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 14:18:25,304 - train - INFO - Test: [   0/39]  Time: 2.738 (2.738s) Loss:  0.4434 (0.4434)  Acc@1: 92.9688 (92.9688)  Acc@5: 100.0000 (100.0000)
2024-01-31 14:19:57,453 - train - INFO - Test: [  39/39]  Time: 2.262 (94.887s) Loss:  0.5283 (0.4409)  Acc@1: 93.7500 (92.9300)  Acc@5: 100.0000 (99.7500)
2024-01-31 14:20:00,821 - train - INFO - Train: 31 [   0/195 (  0%)]  Loss:  1.608913 (1.6089)  Time: 3.196s (3.196s),   80.11/s  (3.196s,   80.11/s)  LR: 4.951e-04  Data: 0.284 (0.284)
2024-01-31 14:22:22,659 - train - INFO - Train: 31 [  50/195 ( 26%)]  Loss:  1.548876 (1.4412)  Time: 2.874s (145.028s),   89.08/s  (2.844s,   90.02/s)  LR: 4.951e-04  Data: 0.018 (0.019)
2024-01-31 14:24:39,525 - train - INFO - Train: 31 [ 100/195 ( 52%)]  Loss:  1.557147 (1.4500)  Time: 2.829s (281.892s),   90.50/s  (2.791s,   91.72/s)  LR: 4.951e-04  Data: 0.020 (0.015)
2024-01-31 14:26:53,987 - train - INFO - Train: 31 [ 150/195 ( 77%)]  Loss:  1.621958 (1.4575)  Time: 2.867s (416.354s),   89.28/s  (2.757s,   92.84/s)  LR: 4.951e-04  Data: 0.005 (0.014)
2024-01-31 14:29:00,006 - train - INFO - Train: 31 [ 194/195 (100%)]  Loss:  1.595333 (1.4705)  Time: 3.135s (542.371s),   81.66/s  (2.781s,   92.04/s)  LR: 4.951e-04  Data: 0.000 (0.013)
2024-01-31 14:29:00,014 - train - INFO - alphas:tensor([0.5770, 0.2101, 0.2130], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,015 - train - INFO - alphas:tensor([0.4991, 0.2155, 0.2854], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,016 - train - INFO - alphas:tensor([0.5741, 0.2074, 0.2185], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,017 - train - INFO - alphas:tensor([0.4458, 0.2315, 0.3227], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,018 - train - INFO - alphas:tensor([0.5862, 0.1993, 0.2145], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,018 - train - INFO - alphas:tensor([0.3599, 0.1242, 0.1146, 0.1518, 0.2495], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,023 - train - INFO - alphas:tensor([0.5603, 0.2021, 0.2375], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,024 - train - INFO - alphas:tensor([0.4156, 0.2131, 0.3713], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,025 - train - INFO - alphas:tensor([0.5669, 0.1943, 0.2388], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,026 - train - INFO - alphas:tensor([0.3771, 0.2055, 0.4174], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,026 - train - INFO - alphas:tensor([0.4649, 0.1336, 0.1121, 0.1294, 0.1601], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,027 - train - INFO - alphas:tensor([0.4447, 0.1224, 0.1084, 0.1318, 0.1927], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,028 - train - INFO - alphas:tensor([0.4183, 0.1141, 0.1038, 0.1344, 0.2295], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,029 - train - INFO - alphas:tensor([0.2555, 0.0772, 0.0729, 0.1231, 0.4714], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,029 - train - INFO - alphas:tensor([0.4124, 0.1113, 0.0977, 0.1328, 0.2458], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,030 - train - INFO - alphas:tensor([0.2206, 0.0699, 0.0672, 0.1219, 0.5204], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,031 - train - INFO - alphas:tensor([0.4063, 0.1067, 0.0962, 0.1365, 0.2543], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,032 - train - INFO - alphas:tensor([0.2042, 0.0719, 0.0663, 0.1232, 0.5344], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,033 - train - INFO - alphas:tensor([0.5403, 0.1062, 0.0998, 0.1120, 0.1416], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,033 - train - INFO - alphas:tensor([0.4435, 0.0975, 0.0904, 0.1215, 0.2470], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,039 - train - INFO - alphas:tensor([0.5070, 0.1048, 0.0936, 0.1144, 0.1803], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,039 - train - INFO - alphas:tensor([0.3263, 0.0797, 0.0784, 0.1243, 0.3913], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,040 - train - INFO - alphas:tensor([0.5147, 0.0995, 0.0911, 0.1135, 0.1812], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,041 - train - INFO - alphas:tensor([0.2953, 0.0750, 0.0712, 0.1175, 0.4411], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,042 - train - INFO - alphas:tensor([0.5384, 0.1021, 0.0948, 0.1113, 0.1535], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,042 - train - INFO - alphas:tensor([0.4501, 0.0921, 0.0897, 0.1176, 0.2504], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,043 - train - INFO - alphas:tensor([0.3885, 0.0895, 0.0871, 0.1258, 0.3091], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,044 - train - INFO - alphas:tensor([0.2292, 0.0572, 0.0552, 0.0882, 0.5701], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,045 - train - INFO - alphas:tensor([0.4157, 0.0915, 0.0853, 0.1200, 0.2876], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,046 - train - INFO - alphas:tensor([0.1901, 0.0596, 0.0544, 0.0959, 0.6000], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,051 - train - INFO - alphas:tensor([0.5465, 0.0944, 0.0914, 0.1051, 0.1627], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,052 - train - INFO - alphas:tensor([0.2160, 0.0846, 0.0736, 0.1139, 0.5119], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:29:00,052 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 14:29:02,637 - train - INFO - Test: [   0/39]  Time: 2.573 (2.573s) Loss:  0.4268 (0.4268)  Acc@1: 92.5781 (92.5781)  Acc@5: 100.0000 (100.0000)
2024-01-31 14:30:35,831 - train - INFO - Test: [  39/39]  Time: 2.334 (95.767s) Loss:  0.5571 (0.4372)  Acc@1: 87.5000 (92.1800)  Acc@5: 100.0000 (99.7800)
2024-01-31 14:30:39,182 - train - INFO - Train: 32 [   0/195 (  0%)]  Loss:  1.527201 (1.5272)  Time: 3.213s (3.213s),   79.67/s  (3.213s,   79.67/s)  LR: 4.916e-04  Data: 0.434 (0.434)
2024-01-31 14:33:01,011 - train - INFO - Train: 32 [  50/195 ( 26%)]  Loss:  1.565747 (1.4503)  Time: 2.646s (145.041s),   96.76/s  (2.844s,   90.02/s)  LR: 4.916e-04  Data: 0.009 (0.020)
2024-01-31 14:35:22,772 - train - INFO - Train: 32 [ 100/195 ( 52%)]  Loss:  1.518035 (1.4494)  Time: 2.852s (286.798s),   89.76/s  (2.840s,   90.15/s)  LR: 4.916e-04  Data: 0.014 (0.017)
2024-01-31 14:37:40,341 - train - INFO - Train: 32 [ 150/195 ( 77%)]  Loss:  1.535035 (1.4546)  Time: 2.910s (424.364s),   87.97/s  (2.810s,   91.09/s)  LR: 4.916e-04  Data: 0.010 (0.015)
2024-01-31 14:39:49,247 - train - INFO - Train: 32 [ 194/195 (100%)]  Loss:  1.379166 (1.4572)  Time: 2.935s (553.267s),   87.21/s  (2.837s,   90.23/s)  LR: 4.916e-04  Data: 0.000 (0.014)
2024-01-31 14:39:49,251 - train - INFO - alphas:tensor([0.5782, 0.2099, 0.2119], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,255 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,256 - train - INFO - alphas:tensor([0.4981, 0.2141, 0.2878], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,256 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,257 - train - INFO - alphas:tensor([0.5784, 0.2045, 0.2171], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,257 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,258 - train - INFO - alphas:tensor([0.4469, 0.2297, 0.3235], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,258 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,258 - train - INFO - alphas:tensor([0.5887, 0.1978, 0.2135], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,259 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,259 - train - INFO - alphas:tensor([0.3607, 0.1225, 0.1133, 0.1512, 0.2523], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,259 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,260 - train - INFO - alphas:tensor([0.5578, 0.2017, 0.2406], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,260 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,261 - train - INFO - alphas:tensor([0.4124, 0.2117, 0.3759], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,261 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,262 - train - INFO - alphas:tensor([0.5678, 0.1926, 0.2396], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,262 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,263 - train - INFO - alphas:tensor([0.3713, 0.2043, 0.4243], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,263 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,263 - train - INFO - alphas:tensor([0.4677, 0.1324, 0.1108, 0.1289, 0.1601], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,263 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,264 - train - INFO - alphas:tensor([0.4501, 0.1199, 0.1065, 0.1301, 0.1934], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,264 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,265 - train - INFO - alphas:tensor([0.4131, 0.1125, 0.1040, 0.1354, 0.2350], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,265 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,266 - train - INFO - alphas:tensor([0.2518, 0.0750, 0.0712, 0.1220, 0.4799], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,266 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,267 - train - INFO - alphas:tensor([0.4096, 0.1099, 0.0971, 0.1330, 0.2504], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,267 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,268 - train - INFO - alphas:tensor([0.2178, 0.0680, 0.0654, 0.1189, 0.5299], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,268 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,268 - train - INFO - alphas:tensor([0.4036, 0.1048, 0.0943, 0.1375, 0.2599], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,269 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,269 - train - INFO - alphas:tensor([0.2011, 0.0700, 0.0649, 0.1211, 0.5428], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,269 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,270 - train - INFO - alphas:tensor([0.5439, 0.1053, 0.0986, 0.1109, 0.1413], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,270 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,271 - train - INFO - alphas:tensor([0.4441, 0.0950, 0.0886, 0.1207, 0.2516], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,271 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,272 - train - INFO - alphas:tensor([0.5088, 0.1028, 0.0923, 0.1140, 0.1822], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,272 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,273 - train - INFO - alphas:tensor([0.3215, 0.0776, 0.0763, 0.1228, 0.4018], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,273 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,273 - train - INFO - alphas:tensor([0.5127, 0.0980, 0.0900, 0.1137, 0.1856], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,274 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,274 - train - INFO - alphas:tensor([0.2918, 0.0738, 0.0701, 0.1164, 0.4479], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,274 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,275 - train - INFO - alphas:tensor([0.5391, 0.1010, 0.0941, 0.1109, 0.1549], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,275 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,276 - train - INFO - alphas:tensor([0.4497, 0.0902, 0.0886, 0.1173, 0.2541], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,276 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,277 - train - INFO - alphas:tensor([0.3871, 0.0881, 0.0855, 0.1245, 0.3149], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,277 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,278 - train - INFO - alphas:tensor([0.2285, 0.0563, 0.0537, 0.0859, 0.5756], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,278 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,279 - train - INFO - alphas:tensor([0.4133, 0.0893, 0.0840, 0.1194, 0.2941], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,279 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,279 - train - INFO - alphas:tensor([0.1897, 0.0582, 0.0528, 0.0941, 0.6052], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,279 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,280 - train - INFO - alphas:tensor([0.5498, 0.0924, 0.0897, 0.1039, 0.1642], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,280 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,281 - train - INFO - alphas:tensor([0.2146, 0.0833, 0.0723, 0.1125, 0.5173], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:39:49,281 - train - INFO - tau:0.04317849994545578
2024-01-31 14:39:49,281 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 14:39:51,768 - train - INFO - Test: [   0/39]  Time: 2.478 (2.478s) Loss:  0.4438 (0.4438)  Acc@1: 92.5781 (92.5781)  Acc@5: 99.6094 (99.6094)
2024-01-31 14:41:24,664 - train - INFO - Test: [  39/39]  Time: 2.446 (95.374s) Loss:  0.3701 (0.4253)  Acc@1: 93.7500 (93.5600)  Acc@5: 100.0000 (99.7400)
2024-01-31 14:41:28,162 - train - INFO - Train: 33 [   0/195 (  0%)]  Loss:  1.358457 (1.3585)  Time: 3.351s (3.351s),   76.40/s  (3.351s,   76.40/s)  LR: 4.880e-04  Data: 0.251 (0.251)
2024-01-31 14:43:51,896 - train - INFO - Train: 33 [  50/195 ( 26%)]  Loss:  1.616555 (1.4522)  Time: 3.039s (147.083s),   84.23/s  (2.884s,   88.77/s)  LR: 4.880e-04  Data: 0.011 (0.015)
2024-01-31 14:46:16,402 - train - INFO - Train: 33 [ 100/195 ( 52%)]  Loss:  1.625243 (1.4514)  Time: 2.643s (291.588s),   96.86/s  (2.887s,   88.67/s)  LR: 4.880e-04  Data: 0.006 (0.013)
2024-01-31 14:48:36,673 - train - INFO - Train: 33 [ 150/195 ( 77%)]  Loss:  1.430673 (1.4518)  Time: 2.846s (431.857s),   89.96/s  (2.860s,   89.51/s)  LR: 4.880e-04  Data: 0.006 (0.013)
2024-01-31 14:50:41,650 - train - INFO - Train: 33 [ 194/195 (100%)]  Loss:  1.313651 (1.4475)  Time: 2.917s (556.832s),   87.75/s  (2.856s,   89.65/s)  LR: 4.880e-04  Data: 0.000 (0.012)
2024-01-31 14:50:41,653 - train - INFO - alphas:tensor([0.5804, 0.2085, 0.2110], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,659 - train - INFO - alphas:tensor([0.4970, 0.2138, 0.2892], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,660 - train - INFO - alphas:tensor([0.5827, 0.2020, 0.2153], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,660 - train - INFO - alphas:tensor([0.4442, 0.2280, 0.3277], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,661 - train - INFO - alphas:tensor([0.5884, 0.1969, 0.2147], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,662 - train - INFO - alphas:tensor([0.3611, 0.1207, 0.1123, 0.1507, 0.2553], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,663 - train - INFO - alphas:tensor([0.5605, 0.1994, 0.2401], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,673 - train - INFO - alphas:tensor([0.4079, 0.2102, 0.3818], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,674 - train - INFO - alphas:tensor([0.5671, 0.1920, 0.2409], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,675 - train - INFO - alphas:tensor([0.3702, 0.2020, 0.4278], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,675 - train - INFO - alphas:tensor([0.4704, 0.1311, 0.1098, 0.1283, 0.1604], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,676 - train - INFO - alphas:tensor([0.4502, 0.1190, 0.1055, 0.1296, 0.1957], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,682 - train - INFO - alphas:tensor([0.4121, 0.1110, 0.1022, 0.1356, 0.2391], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,682 - train - INFO - alphas:tensor([0.2496, 0.0730, 0.0692, 0.1195, 0.4886], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,683 - train - INFO - alphas:tensor([0.4082, 0.1088, 0.0958, 0.1323, 0.2549], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,684 - train - INFO - alphas:tensor([0.2150, 0.0661, 0.0638, 0.1169, 0.5383], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,685 - train - INFO - alphas:tensor([0.4024, 0.1037, 0.0937, 0.1366, 0.2637], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,686 - train - INFO - alphas:tensor([0.1975, 0.0672, 0.0627, 0.1187, 0.5540], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,691 - train - INFO - alphas:tensor([0.5487, 0.1028, 0.0971, 0.1100, 0.1414], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,692 - train - INFO - alphas:tensor([0.4419, 0.0934, 0.0874, 0.1200, 0.2573], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,693 - train - INFO - alphas:tensor([0.5063, 0.1020, 0.0915, 0.1145, 0.1857], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,694 - train - INFO - alphas:tensor([0.3200, 0.0759, 0.0745, 0.1208, 0.4088], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,695 - train - INFO - alphas:tensor([0.5148, 0.0970, 0.0888, 0.1125, 0.1869], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,695 - train - INFO - alphas:tensor([0.2889, 0.0718, 0.0681, 0.1152, 0.4560], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,701 - train - INFO - alphas:tensor([0.5420, 0.0999, 0.0926, 0.1098, 0.1558], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,701 - train - INFO - alphas:tensor([0.4470, 0.0890, 0.0874, 0.1169, 0.2597], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,702 - train - INFO - alphas:tensor([0.3859, 0.0862, 0.0843, 0.1237, 0.3199], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,703 - train - INFO - alphas:tensor([0.2256, 0.0551, 0.0523, 0.0841, 0.5829], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,704 - train - INFO - alphas:tensor([0.4112, 0.0885, 0.0827, 0.1184, 0.2993], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,705 - train - INFO - alphas:tensor([0.1885, 0.0571, 0.0512, 0.0918, 0.6114], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,706 - train - INFO - alphas:tensor([0.5528, 0.0909, 0.0887, 0.1024, 0.1651], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,707 - train - INFO - alphas:tensor([0.2103, 0.0814, 0.0708, 0.1112, 0.5262], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 14:50:41,707 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 14:50:44,475 - train - INFO - Test: [   0/39]  Time: 2.760 (2.760s) Loss:  0.4473 (0.4473)  Acc@1: 92.1875 (92.1875)  Acc@5: 100.0000 (100.0000)
2024-01-31 14:52:16,005 - train - INFO - Test: [  39/39]  Time: 2.117 (94.290s) Loss:  0.4028 (0.4313)  Acc@1: 93.7500 (93.5100)  Acc@5: 100.0000 (99.8200)
2024-01-31 14:52:19,826 - train - INFO - Train: 34 [   0/195 (  0%)]  Loss:  1.282093 (1.2821)  Time: 3.626s (3.626s),   70.59/s  (3.626s,   70.59/s)  LR: 4.844e-04  Data: 0.386 (0.386)
2024-01-31 14:55:10,813 - train - INFO - Train: 34 [  50/195 ( 26%)]  Loss:  1.607217 (1.4542)  Time: 3.233s (174.613s),   79.19/s  (3.424s,   74.77/s)  LR: 4.844e-04  Data: 0.004 (0.019)
2024-01-31 14:57:56,004 - train - INFO - Train: 34 [ 100/195 ( 52%)]  Loss:  1.452715 (1.4561)  Time: 3.588s (339.803s),   71.35/s  (3.364s,   76.09/s)  LR: 4.844e-04  Data: 0.008 (0.015)
2024-01-31 15:00:39,673 - train - INFO - Train: 34 [ 150/195 ( 77%)]  Loss:  1.539753 (1.4623)  Time: 3.573s (503.469s),   71.65/s  (3.334s,   76.78/s)  LR: 4.844e-04  Data: 0.009 (0.013)
2024-01-31 15:03:08,013 - train - INFO - Train: 34 [ 194/195 (100%)]  Loss:  1.345765 (1.4659)  Time: 3.522s (651.808s),   72.68/s  (3.343s,   76.59/s)  LR: 4.844e-04  Data: 0.000 (0.012)
2024-01-31 15:03:08,014 - train - INFO - alphas:tensor([0.5813, 0.2083, 0.2104], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,015 - train - INFO - alphas:tensor([0.4947, 0.2119, 0.2933], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,016 - train - INFO - alphas:tensor([0.5796, 0.2027, 0.2177], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,017 - train - INFO - alphas:tensor([0.4449, 0.2265, 0.3286], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,018 - train - INFO - alphas:tensor([0.5917, 0.1958, 0.2125], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,018 - train - INFO - alphas:tensor([0.3630, 0.1188, 0.1103, 0.1495, 0.2584], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,020 - train - INFO - alphas:tensor([0.5617, 0.1986, 0.2397], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,022 - train - INFO - alphas:tensor([0.4078, 0.2083, 0.3839], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,022 - train - INFO - alphas:tensor([0.5655, 0.1916, 0.2428], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,023 - train - INFO - alphas:tensor([0.3698, 0.1993, 0.4309], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,024 - train - INFO - alphas:tensor([0.4758, 0.1297, 0.1080, 0.1267, 0.1597], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,025 - train - INFO - alphas:tensor([0.4515, 0.1173, 0.1044, 0.1288, 0.1980], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,026 - train - INFO - alphas:tensor([0.4111, 0.1099, 0.1005, 0.1354, 0.2430], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,027 - train - INFO - alphas:tensor([0.2473, 0.0709, 0.0673, 0.1171, 0.4974], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,028 - train - INFO - alphas:tensor([0.4101, 0.1071, 0.0942, 0.1318, 0.2569], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,028 - train - INFO - alphas:tensor([0.2143, 0.0649, 0.0622, 0.1143, 0.5443], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,029 - train - INFO - alphas:tensor([0.4027, 0.1017, 0.0923, 0.1353, 0.2680], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,030 - train - INFO - alphas:tensor([0.1965, 0.0652, 0.0611, 0.1163, 0.5609], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,031 - train - INFO - alphas:tensor([0.5523, 0.1013, 0.0962, 0.1085, 0.1417], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,032 - train - INFO - alphas:tensor([0.4432, 0.0919, 0.0858, 0.1190, 0.2601], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,033 - train - INFO - alphas:tensor([0.5054, 0.1003, 0.0907, 0.1146, 0.1891], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,033 - train - INFO - alphas:tensor([0.3207, 0.0740, 0.0724, 0.1187, 0.4142], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,034 - train - INFO - alphas:tensor([0.5171, 0.0951, 0.0877, 0.1120, 0.1881], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,035 - train - INFO - alphas:tensor([0.2857, 0.0703, 0.0667, 0.1134, 0.4638], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,038 - train - INFO - alphas:tensor([0.5449, 0.0986, 0.0910, 0.1086, 0.1569], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,039 - train - INFO - alphas:tensor([0.4461, 0.0875, 0.0860, 0.1158, 0.2646], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,040 - train - INFO - alphas:tensor([0.3877, 0.0848, 0.0824, 0.1217, 0.3234], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,042 - train - INFO - alphas:tensor([0.2263, 0.0542, 0.0507, 0.0820, 0.5869], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,043 - train - INFO - alphas:tensor([0.4100, 0.0868, 0.0813, 0.1169, 0.3050], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,044 - train - INFO - alphas:tensor([0.1880, 0.0560, 0.0496, 0.0895, 0.6169], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,045 - train - INFO - alphas:tensor([0.5548, 0.0889, 0.0871, 0.1017, 0.1675], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,046 - train - INFO - alphas:tensor([0.2078, 0.0801, 0.0695, 0.1098, 0.5327], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:03:08,046 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 15:03:11,122 - train - INFO - Test: [   0/39]  Time: 3.050 (3.050s) Loss:  0.4268 (0.4268)  Acc@1: 91.7969 (91.7969)  Acc@5: 100.0000 (100.0000)
2024-01-31 15:05:03,212 - train - INFO - Test: [  39/39]  Time: 2.778 (115.140s) Loss:  0.5537 (0.4375)  Acc@1: 87.5000 (93.3300)  Acc@5: 100.0000 (99.7600)
2024-01-31 15:05:07,317 - train - INFO - Train: 35 [   0/195 (  0%)]  Loss:  1.437707 (1.4377)  Time: 3.768s (3.768s),   67.95/s  (3.768s,   67.95/s)  LR: 4.806e-04  Data: 0.308 (0.308)
2024-01-31 15:07:59,570 - train - INFO - Train: 35 [  50/195 ( 26%)]  Loss:  1.594057 (1.4511)  Time: 3.129s (176.019s),   81.81/s  (3.451s,   74.17/s)  LR: 4.806e-04  Data: 0.010 (0.020)
2024-01-31 15:10:44,212 - train - INFO - Train: 35 [ 100/195 ( 52%)]  Loss:  1.466629 (1.4500)  Time: 3.244s (340.653s),   78.92/s  (3.373s,   75.90/s)  LR: 4.806e-04  Data: 0.029 (0.017)
2024-01-31 15:13:28,490 - train - INFO - Train: 35 [ 150/195 ( 77%)]  Loss:  1.525068 (1.4445)  Time: 3.348s (504.926s),   76.46/s  (3.344s,   76.56/s)  LR: 4.806e-04  Data: 0.017 (0.015)
2024-01-31 15:15:59,422 - train - INFO - Train: 35 [ 194/195 (100%)]  Loss:  1.399079 (1.4493)  Time: 3.467s (655.852s),   73.84/s  (3.363s,   76.11/s)  LR: 4.806e-04  Data: 0.000 (0.014)
2024-01-31 15:15:59,424 - train - INFO - alphas:tensor([0.5839, 0.2064, 0.2097], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,425 - train - INFO - alphas:tensor([0.4939, 0.2122, 0.2939], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,426 - train - INFO - alphas:tensor([0.5803, 0.2029, 0.2169], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,427 - train - INFO - alphas:tensor([0.4428, 0.2253, 0.3319], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,428 - train - INFO - alphas:tensor([0.5936, 0.1951, 0.2113], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,429 - train - INFO - alphas:tensor([0.3625, 0.1165, 0.1095, 0.1499, 0.2616], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,429 - train - INFO - alphas:tensor([0.5633, 0.1976, 0.2391], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,430 - train - INFO - alphas:tensor([0.4062, 0.2061, 0.3877], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,435 - train - INFO - alphas:tensor([0.5676, 0.1893, 0.2430], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,436 - train - INFO - alphas:tensor([0.3694, 0.1963, 0.4343], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,437 - train - INFO - alphas:tensor([0.4774, 0.1284, 0.1074, 0.1265, 0.1602], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,438 - train - INFO - alphas:tensor([0.4515, 0.1160, 0.1031, 0.1286, 0.2008], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,438 - train - INFO - alphas:tensor([0.4077, 0.1089, 0.0998, 0.1359, 0.2477], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,444 - train - INFO - alphas:tensor([0.2451, 0.0696, 0.0655, 0.1149, 0.5049], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,445 - train - INFO - alphas:tensor([0.4071, 0.1061, 0.0932, 0.1313, 0.2623], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,445 - train - INFO - alphas:tensor([0.2119, 0.0631, 0.0606, 0.1127, 0.5517], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,446 - train - INFO - alphas:tensor([0.4026, 0.1000, 0.0903, 0.1343, 0.2728], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,447 - train - INFO - alphas:tensor([0.1959, 0.0636, 0.0590, 0.1142, 0.5673], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,452 - train - INFO - alphas:tensor([0.5551, 0.1005, 0.0948, 0.1080, 0.1416], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,453 - train - INFO - alphas:tensor([0.4398, 0.0909, 0.0851, 0.1185, 0.2656], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,454 - train - INFO - alphas:tensor([0.5032, 0.0996, 0.0896, 0.1146, 0.1930], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,455 - train - INFO - alphas:tensor([0.3191, 0.0725, 0.0705, 0.1167, 0.4213], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,456 - train - INFO - alphas:tensor([0.5182, 0.0936, 0.0868, 0.1116, 0.1899], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,457 - train - INFO - alphas:tensor([0.2836, 0.0688, 0.0650, 0.1112, 0.4715], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,458 - train - INFO - alphas:tensor([0.5468, 0.0976, 0.0900, 0.1078, 0.1578], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,459 - train - INFO - alphas:tensor([0.4443, 0.0859, 0.0848, 0.1154, 0.2697], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,460 - train - INFO - alphas:tensor([0.3847, 0.0837, 0.0807, 0.1210, 0.3299], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,460 - train - INFO - alphas:tensor([0.2239, 0.0526, 0.0495, 0.0806, 0.5934], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,461 - train - INFO - alphas:tensor([0.4080, 0.0847, 0.0797, 0.1162, 0.3113], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,462 - train - INFO - alphas:tensor([0.1849, 0.0543, 0.0478, 0.0871, 0.6258], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,463 - train - INFO - alphas:tensor([0.5549, 0.0880, 0.0862, 0.1015, 0.1694], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,464 - train - INFO - alphas:tensor([0.2078, 0.0793, 0.0682, 0.1082, 0.5365], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:15:59,464 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 15:16:02,731 - train - INFO - Test: [   0/39]  Time: 3.255 (3.255s) Loss:  0.4387 (0.4387)  Acc@1: 91.4062 (91.4062)  Acc@5: 100.0000 (100.0000)
2024-01-31 15:17:54,065 - train - INFO - Test: [  39/39]  Time: 2.944 (114.589s) Loss:  0.5674 (0.4347)  Acc@1: 93.7500 (93.2100)  Acc@5: 100.0000 (99.7500)
2024-01-31 15:17:58,184 - train - INFO - Train: 36 [   0/195 (  0%)]  Loss:  1.306660 (1.3067)  Time: 3.863s (3.863s),   66.27/s  (3.863s,   66.27/s)  LR: 4.768e-04  Data: 0.349 (0.349)
2024-01-31 15:20:57,820 - train - INFO - Train: 36 [  50/195 ( 26%)]  Loss:  1.296585 (1.4677)  Time: 3.601s (183.498s),   71.09/s  (3.598s,   71.15/s)  LR: 4.768e-04  Data: 0.005 (0.016)
2024-01-31 15:23:44,549 - train - INFO - Train: 36 [ 100/195 ( 52%)]  Loss:  1.322643 (1.4611)  Time: 3.073s (350.226s),   83.31/s  (3.468s,   73.83/s)  LR: 4.768e-04  Data: 0.014 (0.014)
2024-01-31 15:26:34,206 - train - INFO - Train: 36 [ 150/195 ( 77%)]  Loss:  1.314133 (1.4554)  Time: 3.476s (519.879s),   73.65/s  (3.443s,   74.36/s)  LR: 4.768e-04  Data: 0.005 (0.013)
2024-01-31 15:29:06,511 - train - INFO - Train: 36 [ 194/195 (100%)]  Loss:  1.614609 (1.4542)  Time: 3.522s (672.182s),   72.68/s  (3.447s,   74.27/s)  LR: 4.768e-04  Data: 0.000 (0.012)
2024-01-31 15:29:06,513 - train - INFO - alphas:tensor([0.5849, 0.2056, 0.2095], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,513 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,513 - train - INFO - alphas:tensor([0.4950, 0.2113, 0.2937], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,514 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,514 - train - INFO - alphas:tensor([0.5834, 0.2006, 0.2160], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,514 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,515 - train - INFO - alphas:tensor([0.4416, 0.2235, 0.3349], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,515 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,516 - train - INFO - alphas:tensor([0.5968, 0.1931, 0.2101], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,516 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,517 - train - INFO - alphas:tensor([0.3608, 0.1149, 0.1080, 0.1491, 0.2672], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,518 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,519 - train - INFO - alphas:tensor([0.5598, 0.1979, 0.2423], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,519 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,520 - train - INFO - alphas:tensor([0.4041, 0.2044, 0.3915], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,520 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,521 - train - INFO - alphas:tensor([0.5648, 0.1904, 0.2448], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,521 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,522 - train - INFO - alphas:tensor([0.3653, 0.1948, 0.4399], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,522 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,523 - train - INFO - alphas:tensor([0.4796, 0.1280, 0.1067, 0.1259, 0.1598], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,523 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,524 - train - INFO - alphas:tensor([0.4527, 0.1144, 0.1018, 0.1282, 0.2028], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,524 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,525 - train - INFO - alphas:tensor([0.4071, 0.1081, 0.0990, 0.1358, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,525 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,526 - train - INFO - alphas:tensor([0.2436, 0.0681, 0.0640, 0.1134, 0.5109], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,526 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,527 - train - INFO - alphas:tensor([0.4068, 0.1048, 0.0926, 0.1308, 0.2650], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,527 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,528 - train - INFO - alphas:tensor([0.2090, 0.0616, 0.0591, 0.1109, 0.5594], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,528 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,529 - train - INFO - alphas:tensor([0.3972, 0.0989, 0.0898, 0.1341, 0.2799], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,529 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,530 - train - INFO - alphas:tensor([0.1920, 0.0624, 0.0574, 0.1118, 0.5764], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,530 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,531 - train - INFO - alphas:tensor([0.5591, 0.0993, 0.0936, 0.1071, 0.1408], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,531 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,531 - train - INFO - alphas:tensor([0.4382, 0.0892, 0.0840, 0.1175, 0.2711], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,532 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,532 - train - INFO - alphas:tensor([0.5040, 0.0986, 0.0887, 0.1134, 0.1953], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,533 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,533 - train - INFO - alphas:tensor([0.3150, 0.0710, 0.0694, 0.1160, 0.4286], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,534 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,534 - train - INFO - alphas:tensor([0.5169, 0.0924, 0.0852, 0.1117, 0.1938], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,535 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,535 - train - INFO - alphas:tensor([0.2838, 0.0676, 0.0638, 0.1088, 0.4761], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,536 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,536 - train - INFO - alphas:tensor([0.5498, 0.0961, 0.0888, 0.1067, 0.1586], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,537 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,537 - train - INFO - alphas:tensor([0.4418, 0.0839, 0.0834, 0.1146, 0.2763], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,538 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,538 - train - INFO - alphas:tensor([0.3830, 0.0819, 0.0793, 0.1203, 0.3355], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,539 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,539 - train - INFO - alphas:tensor([0.2240, 0.0515, 0.0481, 0.0792, 0.5972], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,539 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,540 - train - INFO - alphas:tensor([0.4071, 0.0834, 0.0780, 0.1144, 0.3171], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,540 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,541 - train - INFO - alphas:tensor([0.1849, 0.0533, 0.0465, 0.0856, 0.6297], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,541 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,542 - train - INFO - alphas:tensor([0.5582, 0.0865, 0.0845, 0.1007, 0.1701], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,542 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,543 - train - INFO - alphas:tensor([0.2072, 0.0783, 0.0671, 0.1067, 0.5407], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:29:06,543 - train - INFO - tau:0.034542799956364625
2024-01-31 15:29:06,544 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 15:29:09,824 - train - INFO - Test: [   0/39]  Time: 3.272 (3.272s) Loss:  0.4290 (0.4290)  Acc@1: 92.1875 (92.1875)  Acc@5: 100.0000 (100.0000)
2024-01-31 15:31:02,547 - train - INFO - Test: [  39/39]  Time: 2.928 (115.996s) Loss:  0.4443 (0.4267)  Acc@1: 93.7500 (93.4500)  Acc@5: 100.0000 (99.8400)
2024-01-31 15:31:06,567 - train - INFO - Train: 37 [   0/195 (  0%)]  Loss:  1.428615 (1.4286)  Time: 3.660s (3.660s),   69.94/s  (3.660s,   69.94/s)  LR: 4.729e-04  Data: 0.322 (0.322)
2024-01-31 15:34:00,283 - train - INFO - Train: 37 [  50/195 ( 26%)]  Loss:  1.624696 (1.4375)  Time: 3.288s (177.374s),   77.86/s  (3.478s,   73.61/s)  LR: 4.729e-04  Data: 0.017 (0.019)
2024-01-31 15:36:46,423 - train - INFO - Train: 37 [ 100/195 ( 52%)]  Loss:  1.474708 (1.4328)  Time: 3.465s (343.501s),   73.87/s  (3.401s,   75.27/s)  LR: 4.729e-04  Data: 0.005 (0.016)
2024-01-31 15:39:38,045 - train - INFO - Train: 37 [ 150/195 ( 77%)]  Loss:  1.420391 (1.4459)  Time: 3.530s (515.118s),   72.53/s  (3.411s,   75.04/s)  LR: 4.729e-04  Data: 0.008 (0.014)
2024-01-31 15:42:04,994 - train - INFO - Train: 37 [ 194/195 (100%)]  Loss:  1.360442 (1.4424)  Time: 3.344s (662.063s),   76.56/s  (3.395s,   75.40/s)  LR: 4.729e-04  Data: 0.000 (0.013)
2024-01-31 15:42:04,996 - train - INFO - alphas:tensor([0.5859, 0.2050, 0.2091], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:04,997 - train - INFO - alphas:tensor([0.4943, 0.2095, 0.2962], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,002 - train - INFO - alphas:tensor([0.5847, 0.1986, 0.2167], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,003 - train - INFO - alphas:tensor([0.4398, 0.2223, 0.3379], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,004 - train - INFO - alphas:tensor([0.5972, 0.1926, 0.2102], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,011 - train - INFO - alphas:tensor([0.3613, 0.1136, 0.1064, 0.1479, 0.2708], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,012 - train - INFO - alphas:tensor([0.5627, 0.1960, 0.2413], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,012 - train - INFO - alphas:tensor([0.4057, 0.2024, 0.3919], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,013 - train - INFO - alphas:tensor([0.5662, 0.1887, 0.2451], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,014 - train - INFO - alphas:tensor([0.3621, 0.1935, 0.4444], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,015 - train - INFO - alphas:tensor([0.4800, 0.1274, 0.1061, 0.1255, 0.1609], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,016 - train - INFO - alphas:tensor([0.4540, 0.1136, 0.1007, 0.1272, 0.2045], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,017 - train - INFO - alphas:tensor([0.4089, 0.1062, 0.0974, 0.1343, 0.2532], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,018 - train - INFO - alphas:tensor([0.2428, 0.0664, 0.0628, 0.1120, 0.5160], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,018 - train - INFO - alphas:tensor([0.4056, 0.1035, 0.0922, 0.1305, 0.2682], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,024 - train - INFO - alphas:tensor([0.2080, 0.0599, 0.0576, 0.1089, 0.5656], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,025 - train - INFO - alphas:tensor([0.3928, 0.0978, 0.0889, 0.1342, 0.2862], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,026 - train - INFO - alphas:tensor([0.1900, 0.0608, 0.0558, 0.1096, 0.5838], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,026 - train - INFO - alphas:tensor([0.5623, 0.0978, 0.0927, 0.1064, 0.1408], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,027 - train - INFO - alphas:tensor([0.4369, 0.0876, 0.0828, 0.1166, 0.2760], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,028 - train - INFO - alphas:tensor([0.5052, 0.0969, 0.0870, 0.1125, 0.1983], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,029 - train - INFO - alphas:tensor([0.3134, 0.0694, 0.0678, 0.1141, 0.4352], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,030 - train - INFO - alphas:tensor([0.5201, 0.0904, 0.0838, 0.1106, 0.1952], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,031 - train - INFO - alphas:tensor([0.2823, 0.0664, 0.0626, 0.1079, 0.4808], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,031 - train - INFO - alphas:tensor([0.5515, 0.0950, 0.0875, 0.1059, 0.1600], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,037 - train - INFO - alphas:tensor([0.4384, 0.0829, 0.0819, 0.1143, 0.2825], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,037 - train - INFO - alphas:tensor([0.3804, 0.0806, 0.0777, 0.1194, 0.3419], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,038 - train - INFO - alphas:tensor([0.2211, 0.0502, 0.0466, 0.0777, 0.6044], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,039 - train - INFO - alphas:tensor([0.4047, 0.0824, 0.0766, 0.1133, 0.3230], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,040 - train - INFO - alphas:tensor([0.1854, 0.0525, 0.0454, 0.0839, 0.6329], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,041 - train - INFO - alphas:tensor([0.5580, 0.0858, 0.0836, 0.1001, 0.1726], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,042 - train - INFO - alphas:tensor([0.2074, 0.0774, 0.0661, 0.1055, 0.5436], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:42:05,042 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 15:42:08,045 - train - INFO - Test: [   0/39]  Time: 2.987 (2.987s) Loss:  0.4194 (0.4194)  Acc@1: 92.5781 (92.5781)  Acc@5: 100.0000 (100.0000)
2024-01-31 15:44:00,847 - train - INFO - Test: [  39/39]  Time: 2.919 (115.765s) Loss:  0.4387 (0.4207)  Acc@1: 93.7500 (93.4900)  Acc@5: 100.0000 (99.8000)
2024-01-31 15:44:04,779 - train - INFO - Train: 38 [   0/195 (  0%)]  Loss:  1.367800 (1.3678)  Time: 3.689s (3.689s),   69.40/s  (3.689s,   69.40/s)  LR: 4.689e-04  Data: 0.383 (0.383)
2024-01-31 15:46:58,663 - train - INFO - Train: 38 [  50/195 ( 26%)]  Loss:  1.553543 (1.4472)  Time: 3.408s (177.572s),   75.11/s  (3.482s,   73.53/s)  LR: 4.689e-04  Data: 0.015 (0.019)
2024-01-31 15:49:41,844 - train - INFO - Train: 38 [ 100/195 ( 52%)]  Loss:  1.303723 (1.4491)  Time: 3.382s (340.751s),   75.70/s  (3.374s,   75.88/s)  LR: 4.689e-04  Data: 0.017 (0.014)
2024-01-31 15:52:33,030 - train - INFO - Train: 38 [ 150/195 ( 77%)]  Loss:  1.599956 (1.4555)  Time: 3.385s (511.921s),   75.63/s  (3.390s,   75.51/s)  LR: 4.689e-04  Data: 0.005 (0.013)
2024-01-31 15:55:02,929 - train - INFO - Train: 38 [ 194/195 (100%)]  Loss:  1.533353 (1.4521)  Time: 3.556s (661.819s),   72.00/s  (3.394s,   75.43/s)  LR: 4.689e-04  Data: 0.000 (0.012)
2024-01-31 15:55:02,936 - train - INFO - alphas:tensor([0.5873, 0.2043, 0.2084], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:02,937 - train - INFO - alphas:tensor([0.4970, 0.2074, 0.2956], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:02,938 - train - INFO - alphas:tensor([0.5900, 0.1962, 0.2139], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:02,939 - train - INFO - alphas:tensor([0.4381, 0.2216, 0.3403], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:02,939 - train - INFO - alphas:tensor([0.5975, 0.1921, 0.2103], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:02,940 - train - INFO - alphas:tensor([0.3621, 0.1115, 0.1048, 0.1477, 0.2740], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:02,955 - train - INFO - alphas:tensor([0.5638, 0.1948, 0.2414], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:02,956 - train - INFO - alphas:tensor([0.4049, 0.2009, 0.3942], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:02,957 - train - INFO - alphas:tensor([0.5640, 0.1895, 0.2465], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:02,958 - train - INFO - alphas:tensor([0.3601, 0.1913, 0.4486], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:02,959 - train - INFO - alphas:tensor([0.4823, 0.1262, 0.1055, 0.1248, 0.1612], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:02,973 - train - INFO - alphas:tensor([0.4542, 0.1125, 0.1000, 0.1272, 0.2060], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:02,974 - train - INFO - alphas:tensor([0.4053, 0.1053, 0.0967, 0.1350, 0.2577], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:02,975 - train - INFO - alphas:tensor([0.2417, 0.0655, 0.0614, 0.1102, 0.5212], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:02,976 - train - INFO - alphas:tensor([0.4031, 0.1024, 0.0910, 0.1303, 0.2732], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:02,981 - train - INFO - alphas:tensor([0.2054, 0.0584, 0.0560, 0.1073, 0.5729], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:02,991 - train - INFO - alphas:tensor([0.3908, 0.0962, 0.0874, 0.1339, 0.2918], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:02,991 - train - INFO - alphas:tensor([0.1882, 0.0595, 0.0543, 0.1074, 0.5907], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:03,003 - train - INFO - alphas:tensor([0.5680, 0.0965, 0.0904, 0.1047, 0.1404], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:03,004 - train - INFO - alphas:tensor([0.4367, 0.0863, 0.0811, 0.1154, 0.2806], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:03,005 - train - INFO - alphas:tensor([0.5075, 0.0955, 0.0859, 0.1120, 0.1991], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:03,006 - train - INFO - alphas:tensor([0.3127, 0.0684, 0.0663, 0.1131, 0.4395], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:03,007 - train - INFO - alphas:tensor([0.5175, 0.0899, 0.0835, 0.1107, 0.1983], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:03,008 - train - INFO - alphas:tensor([0.2790, 0.0650, 0.0612, 0.1069, 0.4878], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:03,009 - train - INFO - alphas:tensor([0.5525, 0.0942, 0.0867, 0.1058, 0.1608], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:03,010 - train - INFO - alphas:tensor([0.4392, 0.0818, 0.0806, 0.1129, 0.2855], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:03,010 - train - INFO - alphas:tensor([0.3800, 0.0796, 0.0760, 0.1179, 0.3465], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:03,011 - train - INFO - alphas:tensor([0.2211, 0.0494, 0.0454, 0.0761, 0.6080], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:03,012 - train - INFO - alphas:tensor([0.4036, 0.0805, 0.0751, 0.1122, 0.3286], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:03,013 - train - INFO - alphas:tensor([0.1844, 0.0516, 0.0441, 0.0825, 0.6375], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:03,018 - train - INFO - alphas:tensor([0.5594, 0.0842, 0.0824, 0.0996, 0.1743], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:03,019 - train - INFO - alphas:tensor([0.2062, 0.0765, 0.0651, 0.1046, 0.5476], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 15:55:03,019 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 15:55:06,274 - train - INFO - Test: [   0/39]  Time: 3.236 (3.236s) Loss:  0.4170 (0.4170)  Acc@1: 94.1406 (94.1406)  Acc@5: 99.6094 (99.6094)
2024-01-31 15:56:58,530 - train - INFO - Test: [  39/39]  Time: 2.655 (115.492s) Loss:  0.5098 (0.4231)  Acc@1: 93.7500 (93.2800)  Acc@5: 100.0000 (99.8100)
2024-01-31 15:57:02,427 - train - INFO - Train: 39 [   0/195 (  0%)]  Loss:  1.525701 (1.5257)  Time: 3.762s (3.762s),   68.05/s  (3.762s,   68.05/s)  LR: 4.648e-04  Data: 0.379 (0.379)
2024-01-31 15:59:58,126 - train - INFO - Train: 39 [  50/195 ( 26%)]  Loss:  1.572695 (1.4721)  Time: 3.345s (179.460s),   76.54/s  (3.519s,   72.75/s)  LR: 4.648e-04  Data: 0.004 (0.019)
2024-01-31 16:02:42,166 - train - INFO - Train: 39 [ 100/195 ( 52%)]  Loss:  1.267512 (1.4578)  Time: 3.439s (343.496s),   74.43/s  (3.401s,   75.27/s)  LR: 4.648e-04  Data: 0.006 (0.016)
2024-01-31 16:05:27,001 - train - INFO - Train: 39 [ 150/195 ( 77%)]  Loss:  1.304514 (1.4570)  Time: 3.512s (508.326s),   72.90/s  (3.366s,   76.05/s)  LR: 4.648e-04  Data: 0.010 (0.015)
2024-01-31 16:07:54,190 - train - INFO - Train: 39 [ 194/195 (100%)]  Loss:  1.613162 (1.4576)  Time: 3.464s (655.499s),   73.91/s  (3.362s,   76.16/s)  LR: 4.648e-04  Data: 0.000 (0.014)
2024-01-31 16:07:54,192 - train - INFO - alphas:tensor([0.5895, 0.2037, 0.2068], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,193 - train - INFO - alphas:tensor([0.4940, 0.2077, 0.2984], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,194 - train - INFO - alphas:tensor([0.5893, 0.1963, 0.2144], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,195 - train - INFO - alphas:tensor([0.4371, 0.2204, 0.3425], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,196 - train - INFO - alphas:tensor([0.6003, 0.1906, 0.2091], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,196 - train - INFO - alphas:tensor([0.3618, 0.1100, 0.1041, 0.1471, 0.2769], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,198 - train - INFO - alphas:tensor([0.5640, 0.1943, 0.2417], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,199 - train - INFO - alphas:tensor([0.4011, 0.1995, 0.3994], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,200 - train - INFO - alphas:tensor([0.5615, 0.1903, 0.2482], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,201 - train - INFO - alphas:tensor([0.3573, 0.1905, 0.4522], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,202 - train - INFO - alphas:tensor([0.4839, 0.1253, 0.1049, 0.1239, 0.1620], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,202 - train - INFO - alphas:tensor([0.4566, 0.1108, 0.0982, 0.1264, 0.2080], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,203 - train - INFO - alphas:tensor([0.4028, 0.1050, 0.0966, 0.1348, 0.2609], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,204 - train - INFO - alphas:tensor([0.2380, 0.0641, 0.0599, 0.1086, 0.5294], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,205 - train - INFO - alphas:tensor([0.4021, 0.1012, 0.0895, 0.1288, 0.2785], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,206 - train - INFO - alphas:tensor([0.2030, 0.0570, 0.0544, 0.1048, 0.5809], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,207 - train - INFO - alphas:tensor([0.3899, 0.0951, 0.0869, 0.1336, 0.2945], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,208 - train - INFO - alphas:tensor([0.1877, 0.0584, 0.0529, 0.1052, 0.5958], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,208 - train - INFO - alphas:tensor([0.5708, 0.0957, 0.0892, 0.1041, 0.1401], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,214 - train - INFO - alphas:tensor([0.4360, 0.0852, 0.0795, 0.1145, 0.2847], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,214 - train - INFO - alphas:tensor([0.5074, 0.0949, 0.0850, 0.1116, 0.2012], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,215 - train - INFO - alphas:tensor([0.3093, 0.0674, 0.0652, 0.1118, 0.4463], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,216 - train - INFO - alphas:tensor([0.5187, 0.0890, 0.0825, 0.1105, 0.1993], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,217 - train - INFO - alphas:tensor([0.2776, 0.0635, 0.0600, 0.1053, 0.4936], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,218 - train - INFO - alphas:tensor([0.5532, 0.0928, 0.0855, 0.1055, 0.1631], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,219 - train - INFO - alphas:tensor([0.4342, 0.0805, 0.0797, 0.1126, 0.2931], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,220 - train - INFO - alphas:tensor([0.3803, 0.0780, 0.0744, 0.1167, 0.3506], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,220 - train - INFO - alphas:tensor([0.2195, 0.0480, 0.0442, 0.0749, 0.6135], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,221 - train - INFO - alphas:tensor([0.4016, 0.0787, 0.0739, 0.1121, 0.3336], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,222 - train - INFO - alphas:tensor([0.1823, 0.0507, 0.0427, 0.0806, 0.6437], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,223 - train - INFO - alphas:tensor([0.5614, 0.0826, 0.0809, 0.0987, 0.1764], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,228 - train - INFO - alphas:tensor([0.2048, 0.0755, 0.0639, 0.1030, 0.5528], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:07:54,229 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 16:07:57,201 - train - INFO - Test: [   0/39]  Time: 2.964 (2.964s) Loss:  0.4221 (0.4221)  Acc@1: 92.9688 (92.9688)  Acc@5: 99.2188 (99.2188)
2024-01-31 16:09:50,262 - train - INFO - Test: [  39/39]  Time: 2.288 (116.025s) Loss:  0.5166 (0.4215)  Acc@1: 93.7500 (93.4000)  Acc@5: 100.0000 (99.7400)
2024-01-31 16:09:53,702 - train - INFO - Train: 40 [   0/195 (  0%)]  Loss:  1.564602 (1.5646)  Time: 3.172s (3.172s),   80.70/s  (3.172s,   80.70/s)  LR: 4.607e-04  Data: 0.337 (0.337)
2024-01-31 16:12:16,682 - train - INFO - Train: 40 [  50/195 ( 26%)]  Loss:  1.498158 (1.4724)  Time: 2.679s (146.145s),   95.55/s  (2.866s,   89.34/s)  LR: 4.607e-04  Data: 0.005 (0.018)
2024-01-31 16:14:24,180 - train - INFO - Train: 40 [ 100/195 ( 52%)]  Loss:  1.427589 (1.4717)  Time: 2.874s (273.638s),   89.08/s  (2.709s,   94.49/s)  LR: 4.607e-04  Data: 0.017 (0.014)
2024-01-31 16:16:47,822 - train - INFO - Train: 40 [ 150/195 ( 77%)]  Loss:  1.554447 (1.4648)  Time: 2.838s (417.275s),   90.21/s  (2.763s,   92.64/s)  LR: 4.607e-04  Data: 0.014 (0.013)
2024-01-31 16:18:55,948 - train - INFO - Train: 40 [ 194/195 (100%)]  Loss:  1.630903 (1.4621)  Time: 2.754s (545.399s),   92.95/s  (2.797s,   91.53/s)  LR: 4.607e-04  Data: 0.000 (0.012)
2024-01-31 16:18:55,950 - train - INFO - alphas:tensor([0.5893, 0.2029, 0.2077], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:55,950 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:55,951 - train - INFO - alphas:tensor([0.4953, 0.2057, 0.2989], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:55,951 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:55,958 - train - INFO - alphas:tensor([0.5894, 0.1962, 0.2144], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:55,958 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:55,959 - train - INFO - alphas:tensor([0.4358, 0.2191, 0.3451], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:55,962 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:55,963 - train - INFO - alphas:tensor([0.6007, 0.1900, 0.2094], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:55,963 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:55,964 - train - INFO - alphas:tensor([0.3598, 0.1093, 0.1034, 0.1464, 0.2810], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:55,964 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:55,965 - train - INFO - alphas:tensor([0.5631, 0.1941, 0.2428], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:55,965 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:55,972 - train - INFO - alphas:tensor([0.3983, 0.1979, 0.4038], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:55,973 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:55,973 - train - INFO - alphas:tensor([0.5610, 0.1902, 0.2488], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:55,974 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:55,974 - train - INFO - alphas:tensor([0.3554, 0.1881, 0.4565], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:55,977 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:55,978 - train - INFO - alphas:tensor([0.4860, 0.1247, 0.1041, 0.1238, 0.1614], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:55,978 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:55,979 - train - INFO - alphas:tensor([0.4550, 0.1099, 0.0976, 0.1264, 0.2111], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:55,979 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:55,981 - train - INFO - alphas:tensor([0.4012, 0.1048, 0.0963, 0.1351, 0.2626], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:55,981 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:55,982 - train - INFO - alphas:tensor([0.2343, 0.0631, 0.0589, 0.1074, 0.5362], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:55,982 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:55,983 - train - INFO - alphas:tensor([0.4030, 0.0999, 0.0884, 0.1271, 0.2815], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:55,983 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:55,993 - train - INFO - alphas:tensor([0.2009, 0.0554, 0.0527, 0.1029, 0.5881], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:55,993 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:55,994 - train - INFO - alphas:tensor([0.3894, 0.0934, 0.0858, 0.1323, 0.2992], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:55,994 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:55,995 - train - INFO - alphas:tensor([0.1861, 0.0566, 0.0512, 0.1029, 0.6032], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:55,995 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:55,996 - train - INFO - alphas:tensor([0.5731, 0.0947, 0.0880, 0.1034, 0.1408], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:55,996 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:55,997 - train - INFO - alphas:tensor([0.4347, 0.0850, 0.0783, 0.1134, 0.2886], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:55,997 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:55,998 - train - INFO - alphas:tensor([0.5065, 0.0939, 0.0839, 0.1116, 0.2041], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:55,998 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:55,999 - train - INFO - alphas:tensor([0.3079, 0.0662, 0.0639, 0.1096, 0.4524], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:55,999 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:55,999 - train - INFO - alphas:tensor([0.5192, 0.0880, 0.0817, 0.1094, 0.2017], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:56,000 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:56,000 - train - INFO - alphas:tensor([0.2771, 0.0624, 0.0583, 0.1039, 0.4982], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:56,001 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:56,001 - train - INFO - alphas:tensor([0.5531, 0.0916, 0.0849, 0.1058, 0.1645], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:56,002 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:56,011 - train - INFO - alphas:tensor([0.4342, 0.0787, 0.0782, 0.1117, 0.2972], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:56,011 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:56,012 - train - INFO - alphas:tensor([0.3770, 0.0765, 0.0734, 0.1163, 0.3568], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:56,012 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:56,013 - train - INFO - alphas:tensor([0.2200, 0.0472, 0.0432, 0.0733, 0.6162], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:56,013 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:56,014 - train - INFO - alphas:tensor([0.4007, 0.0777, 0.0730, 0.1114, 0.3373], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:56,014 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:56,015 - train - INFO - alphas:tensor([0.1816, 0.0500, 0.0419, 0.0790, 0.6475], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:56,015 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:56,016 - train - INFO - alphas:tensor([0.5597, 0.0823, 0.0809, 0.0990, 0.1781], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:56,016 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:56,021 - train - INFO - alphas:tensor([0.2036, 0.0746, 0.0628, 0.1019, 0.5571], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:18:56,022 - train - INFO - tau:0.027634239965091702
2024-01-31 16:18:56,022 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 16:18:58,700 - train - INFO - Test: [   0/39]  Time: 2.656 (2.656s) Loss:  0.4363 (0.4363)  Acc@1: 92.9688 (92.9688)  Acc@5: 99.6094 (99.6094)
2024-01-31 16:20:32,455 - train - INFO - Test: [  39/39]  Time: 2.325 (96.412s) Loss:  0.4897 (0.4389)  Acc@1: 93.7500 (93.1900)  Acc@5: 100.0000 (99.7900)
2024-01-31 16:20:35,801 - train - INFO - Train: 41 [   0/195 (  0%)]  Loss:  1.590562 (1.5906)  Time: 3.179s (3.179s),   80.54/s  (3.179s,   80.54/s)  LR: 4.564e-04  Data: 0.331 (0.331)
2024-01-31 16:23:02,812 - train - INFO - Train: 41 [  50/195 ( 26%)]  Loss:  1.513137 (1.4502)  Time: 2.917s (150.188s),   87.75/s  (2.945s,   86.93/s)  LR: 4.564e-04  Data: 0.005 (0.015)
2024-01-31 16:25:19,835 - train - INFO - Train: 41 [ 100/195 ( 52%)]  Loss:  1.514989 (1.4487)  Time: 2.769s (287.210s),   92.45/s  (2.844s,   90.02/s)  LR: 4.564e-04  Data: 0.016 (0.013)
2024-01-31 16:27:39,042 - train - INFO - Train: 41 [ 150/195 ( 77%)]  Loss:  1.530612 (1.4527)  Time: 2.910s (426.416s),   87.99/s  (2.824s,   90.65/s)  LR: 4.564e-04  Data: 0.008 (0.012)
2024-01-31 16:29:44,788 - train - INFO - Train: 41 [ 194/195 (100%)]  Loss:  1.519965 (1.4522)  Time: 2.926s (552.161s),   87.49/s  (2.832s,   90.41/s)  LR: 4.564e-04  Data: 0.000 (0.012)
2024-01-31 16:29:44,790 - train - INFO - alphas:tensor([0.5900, 0.2029, 0.2071], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,791 - train - INFO - alphas:tensor([0.4961, 0.2042, 0.2998], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,792 - train - INFO - alphas:tensor([0.5891, 0.1954, 0.2155], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,792 - train - INFO - alphas:tensor([0.4348, 0.2186, 0.3466], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,793 - train - INFO - alphas:tensor([0.6016, 0.1895, 0.2089], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,794 - train - INFO - alphas:tensor([0.3577, 0.1078, 0.1022, 0.1461, 0.2862], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,795 - train - INFO - alphas:tensor([0.5617, 0.1940, 0.2443], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,795 - train - INFO - alphas:tensor([0.3969, 0.1974, 0.4057], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,796 - train - INFO - alphas:tensor([0.5605, 0.1891, 0.2503], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,797 - train - INFO - alphas:tensor([0.3538, 0.1853, 0.4609], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,798 - train - INFO - alphas:tensor([0.4878, 0.1245, 0.1034, 0.1233, 0.1610], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,799 - train - INFO - alphas:tensor([0.4570, 0.1085, 0.0965, 0.1258, 0.2123], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,799 - train - INFO - alphas:tensor([0.4015, 0.1028, 0.0947, 0.1341, 0.2669], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,800 - train - INFO - alphas:tensor([0.2329, 0.0613, 0.0574, 0.1055, 0.5428], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,801 - train - INFO - alphas:tensor([0.3997, 0.0991, 0.0879, 0.1274, 0.2860], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,802 - train - INFO - alphas:tensor([0.1997, 0.0544, 0.0516, 0.1011, 0.5933], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,803 - train - INFO - alphas:tensor([0.3878, 0.0924, 0.0850, 0.1314, 0.3034], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,804 - train - INFO - alphas:tensor([0.1858, 0.0556, 0.0499, 0.1006, 0.6081], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,804 - train - INFO - alphas:tensor([0.5765, 0.0938, 0.0873, 0.1025, 0.1399], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,805 - train - INFO - alphas:tensor([0.4326, 0.0837, 0.0776, 0.1126, 0.2935], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,806 - train - INFO - alphas:tensor([0.5112, 0.0921, 0.0823, 0.1101, 0.2043], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,807 - train - INFO - alphas:tensor([0.3081, 0.0648, 0.0622, 0.1075, 0.4573], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,808 - train - INFO - alphas:tensor([0.5208, 0.0875, 0.0807, 0.1084, 0.2026], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,809 - train - INFO - alphas:tensor([0.2768, 0.0610, 0.0569, 0.1019, 0.5034], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,809 - train - INFO - alphas:tensor([0.5578, 0.0901, 0.0836, 0.1039, 0.1646], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,810 - train - INFO - alphas:tensor([0.4364, 0.0774, 0.0768, 0.1104, 0.2990], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,811 - train - INFO - alphas:tensor([0.3765, 0.0760, 0.0717, 0.1152, 0.3606], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,812 - train - INFO - alphas:tensor([0.2185, 0.0465, 0.0423, 0.0719, 0.6208], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,813 - train - INFO - alphas:tensor([0.3999, 0.0769, 0.0721, 0.1103, 0.3408], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,818 - train - INFO - alphas:tensor([0.1804, 0.0491, 0.0410, 0.0776, 0.6520], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,819 - train - INFO - alphas:tensor([0.5587, 0.0816, 0.0806, 0.0990, 0.1802], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,820 - train - INFO - alphas:tensor([0.2027, 0.0737, 0.0620, 0.1008, 0.5607], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:29:44,820 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 16:29:47,634 - train - INFO - Test: [   0/39]  Time: 2.786 (2.786s) Loss:  0.4509 (0.4509)  Acc@1: 93.3594 (93.3594)  Acc@5: 99.6094 (99.6094)
2024-01-31 16:31:20,717 - train - INFO - Test: [  39/39]  Time: 1.771 (95.870s) Loss:  0.4885 (0.4372)  Acc@1: 93.7500 (93.6800)  Acc@5: 100.0000 (99.7700)
2024-01-31 16:31:23,990 - train - INFO - Train: 42 [   0/195 (  0%)]  Loss:  1.605419 (1.6054)  Time: 2.988s (2.988s),   85.67/s  (2.988s,   85.67/s)  LR: 4.521e-04  Data: 0.295 (0.295)
2024-01-31 16:33:43,487 - train - INFO - Train: 42 [  50/195 ( 26%)]  Loss:  1.601614 (1.4258)  Time: 2.830s (142.484s),   90.47/s  (2.794s,   91.63/s)  LR: 4.521e-04  Data: 0.006 (0.019)
2024-01-31 16:36:01,293 - train - INFO - Train: 42 [ 100/195 ( 52%)]  Loss:  1.383553 (1.4426)  Time: 2.903s (280.289s),   88.20/s  (2.775s,   92.25/s)  LR: 4.521e-04  Data: 0.006 (0.015)
2024-01-31 16:38:26,361 - train - INFO - Train: 42 [ 150/195 ( 77%)]  Loss:  1.375170 (1.4534)  Time: 2.862s (425.353s),   89.45/s  (2.817s,   90.88/s)  LR: 4.521e-04  Data: 0.005 (0.013)
2024-01-31 16:40:25,592 - train - INFO - Train: 42 [ 194/195 (100%)]  Loss:  1.503579 (1.4566)  Time: 2.439s (544.581s),  104.97/s  (2.793s,   91.67/s)  LR: 4.521e-04  Data: 0.000 (0.012)
2024-01-31 16:40:25,593 - train - INFO - alphas:tensor([0.5906, 0.2023, 0.2071], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,594 - train - INFO - alphas:tensor([0.4963, 0.2032, 0.3005], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,595 - train - INFO - alphas:tensor([0.5928, 0.1934, 0.2138], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,596 - train - INFO - alphas:tensor([0.4344, 0.2169, 0.3487], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,597 - train - INFO - alphas:tensor([0.6020, 0.1890, 0.2090], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,597 - train - INFO - alphas:tensor([0.3575, 0.1068, 0.1012, 0.1459, 0.2886], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,598 - train - INFO - alphas:tensor([0.5617, 0.1929, 0.2454], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,599 - train - INFO - alphas:tensor([0.3958, 0.1959, 0.4083], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,600 - train - INFO - alphas:tensor([0.5598, 0.1881, 0.2522], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,600 - train - INFO - alphas:tensor([0.3504, 0.1846, 0.4650], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,601 - train - INFO - alphas:tensor([0.4904, 0.1237, 0.1030, 0.1223, 0.1606], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,602 - train - INFO - alphas:tensor([0.4571, 0.1075, 0.0958, 0.1253, 0.2143], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,603 - train - INFO - alphas:tensor([0.3990, 0.1014, 0.0937, 0.1343, 0.2716], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,603 - train - INFO - alphas:tensor([0.2296, 0.0601, 0.0559, 0.1039, 0.5506], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,604 - train - INFO - alphas:tensor([0.3991, 0.0968, 0.0863, 0.1271, 0.2907], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,605 - train - INFO - alphas:tensor([0.2018, 0.0535, 0.0504, 0.0984, 0.5959], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,606 - train - INFO - alphas:tensor([0.3888, 0.0904, 0.0836, 0.1299, 0.3074], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,606 - train - INFO - alphas:tensor([0.1851, 0.0546, 0.0489, 0.0991, 0.6123], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,607 - train - INFO - alphas:tensor([0.5783, 0.0927, 0.0863, 0.1023, 0.1405], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,608 - train - INFO - alphas:tensor([0.4299, 0.0827, 0.0770, 0.1128, 0.2976], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,609 - train - INFO - alphas:tensor([0.5126, 0.0906, 0.0815, 0.1092, 0.2062], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,609 - train - INFO - alphas:tensor([0.3075, 0.0632, 0.0608, 0.1056, 0.4629], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,610 - train - INFO - alphas:tensor([0.5220, 0.0860, 0.0794, 0.1079, 0.2047], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,611 - train - INFO - alphas:tensor([0.2758, 0.0603, 0.0560, 0.1004, 0.5076], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,612 - train - INFO - alphas:tensor([0.5601, 0.0890, 0.0823, 0.1033, 0.1653], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,612 - train - INFO - alphas:tensor([0.4319, 0.0768, 0.0763, 0.1100, 0.3051], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,613 - train - INFO - alphas:tensor([0.3777, 0.0747, 0.0705, 0.1139, 0.3632], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,614 - train - INFO - alphas:tensor([0.2160, 0.0456, 0.0413, 0.0704, 0.6267], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,615 - train - INFO - alphas:tensor([0.4002, 0.0763, 0.0712, 0.1088, 0.3434], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,616 - train - INFO - alphas:tensor([0.1785, 0.0480, 0.0396, 0.0758, 0.6581], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,616 - train - INFO - alphas:tensor([0.5614, 0.0802, 0.0788, 0.0977, 0.1818], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,617 - train - INFO - alphas:tensor([0.2021, 0.0732, 0.0611, 0.1001, 0.5635], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:40:25,617 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 16:40:27,833 - train - INFO - Test: [   0/39]  Time: 2.208 (2.208s) Loss:  0.4097 (0.4097)  Acc@1: 94.9219 (94.9219)  Acc@5: 99.2188 (99.2188)
2024-01-31 16:41:39,117 - train - INFO - Test: [  39/39]  Time: 1.534 (73.492s) Loss:  0.5093 (0.4312)  Acc@1: 87.5000 (93.2700)  Acc@5: 100.0000 (99.7100)
2024-01-31 16:41:41,519 - train - INFO - Train: 43 [   0/195 (  0%)]  Loss:  1.295142 (1.2951)  Time: 2.163s (2.163s),  118.37/s  (2.163s,  118.37/s)  LR: 4.477e-04  Data: 0.190 (0.190)
2024-01-31 16:43:33,925 - train - INFO - Train: 43 [  50/195 ( 26%)]  Loss:  1.588009 (1.4246)  Time: 1.986s (114.568s),  128.92/s  (2.246s,  113.96/s)  LR: 4.477e-04  Data: 0.004 (0.013)
2024-01-31 16:45:22,512 - train - INFO - Train: 43 [ 100/195 ( 52%)]  Loss:  1.627753 (1.4330)  Time: 2.228s (223.153s),  114.89/s  (2.209s,  115.87/s)  LR: 4.477e-04  Data: 0.005 (0.012)
2024-01-31 16:47:14,616 - train - INFO - Train: 43 [ 150/195 ( 77%)]  Loss:  1.676457 (1.4553)  Time: 2.329s (335.254s),  109.91/s  (2.220s,  115.30/s)  LR: 4.477e-04  Data: 0.005 (0.011)
2024-01-31 16:48:50,377 - train - INFO - Train: 43 [ 194/195 (100%)]  Loss:  1.374727 (1.4500)  Time: 2.230s (431.013s),  114.80/s  (2.210s,  115.82/s)  LR: 4.477e-04  Data: 0.000 (0.010)
2024-01-31 16:48:50,381 - train - INFO - alphas:tensor([0.5917, 0.2024, 0.2058], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,382 - train - INFO - alphas:tensor([0.4947, 0.2029, 0.3025], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,382 - train - INFO - alphas:tensor([0.5905, 0.1936, 0.2159], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,383 - train - INFO - alphas:tensor([0.4335, 0.2166, 0.3499], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,384 - train - INFO - alphas:tensor([0.6043, 0.1878, 0.2079], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,385 - train - INFO - alphas:tensor([0.3568, 0.1058, 0.1004, 0.1456, 0.2914], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,385 - train - INFO - alphas:tensor([0.5631, 0.1917, 0.2452], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,386 - train - INFO - alphas:tensor([0.3920, 0.1944, 0.4136], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,387 - train - INFO - alphas:tensor([0.5574, 0.1887, 0.2539], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,388 - train - INFO - alphas:tensor([0.3491, 0.1821, 0.4689], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,389 - train - INFO - alphas:tensor([0.4915, 0.1232, 0.1024, 0.1218, 0.1611], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,390 - train - INFO - alphas:tensor([0.4567, 0.1064, 0.0950, 0.1249, 0.2170], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,391 - train - INFO - alphas:tensor([0.3987, 0.1002, 0.0927, 0.1334, 0.2750], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,391 - train - INFO - alphas:tensor([0.2283, 0.0587, 0.0543, 0.1016, 0.5570], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,392 - train - INFO - alphas:tensor([0.3973, 0.0959, 0.0852, 0.1271, 0.2944], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,393 - train - INFO - alphas:tensor([0.1985, 0.0519, 0.0487, 0.0970, 0.6039], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,394 - train - INFO - alphas:tensor([0.3883, 0.0889, 0.0822, 0.1288, 0.3117], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,395 - train - INFO - alphas:tensor([0.1820, 0.0528, 0.0471, 0.0972, 0.6210], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,396 - train - INFO - alphas:tensor([0.5806, 0.0917, 0.0854, 0.1016, 0.1408], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,396 - train - INFO - alphas:tensor([0.4306, 0.0814, 0.0755, 0.1114, 0.3011], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,397 - train - INFO - alphas:tensor([0.5102, 0.0902, 0.0809, 0.1087, 0.2100], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,398 - train - INFO - alphas:tensor([0.3066, 0.0623, 0.0598, 0.1042, 0.4672], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,399 - train - INFO - alphas:tensor([0.5204, 0.0843, 0.0789, 0.1084, 0.2080], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,400 - train - INFO - alphas:tensor([0.2733, 0.0593, 0.0550, 0.0995, 0.5130], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,400 - train - INFO - alphas:tensor([0.5630, 0.0885, 0.0813, 0.1021, 0.1651], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,401 - train - INFO - alphas:tensor([0.4329, 0.0753, 0.0745, 0.1084, 0.3089], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,402 - train - INFO - alphas:tensor([0.3726, 0.0737, 0.0694, 0.1135, 0.3708], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,403 - train - INFO - alphas:tensor([0.2150, 0.0448, 0.0405, 0.0694, 0.6302], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,404 - train - INFO - alphas:tensor([0.3982, 0.0753, 0.0705, 0.1083, 0.3477], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,404 - train - INFO - alphas:tensor([0.1774, 0.0473, 0.0386, 0.0745, 0.6622], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,405 - train - INFO - alphas:tensor([0.5607, 0.0792, 0.0779, 0.0976, 0.1845], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,406 - train - INFO - alphas:tensor([0.1998, 0.0724, 0.0602, 0.0993, 0.5683], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:48:50,406 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 16:48:52,446 - train - INFO - Test: [   0/39]  Time: 2.028 (2.028s) Loss:  0.4243 (0.4243)  Acc@1: 94.5312 (94.5312)  Acc@5: 100.0000 (100.0000)
2024-01-31 16:50:04,508 - train - INFO - Test: [  39/39]  Time: 1.776 (74.090s) Loss:  0.4971 (0.4318)  Acc@1: 87.5000 (93.4700)  Acc@5: 100.0000 (99.8400)
2024-01-31 16:50:07,160 - train - INFO - Train: 44 [   0/195 (  0%)]  Loss:  1.529037 (1.5290)  Time: 2.532s (2.532s),  101.10/s  (2.532s,  101.10/s)  LR: 4.432e-04  Data: 0.202 (0.202)
2024-01-31 16:52:02,668 - train - INFO - Train: 44 [  50/195 ( 26%)]  Loss:  1.327387 (1.4325)  Time: 1.693s (118.039s),  151.26/s  (2.314s,  110.61/s)  LR: 4.432e-04  Data: 0.009 (0.011)
2024-01-31 16:53:56,518 - train - INFO - Train: 44 [ 100/195 ( 52%)]  Loss:  1.273906 (1.4490)  Time: 2.338s (231.888s),  109.50/s  (2.296s,  111.50/s)  LR: 4.432e-04  Data: 0.005 (0.009)
2024-01-31 16:55:53,218 - train - INFO - Train: 44 [ 150/195 ( 77%)]  Loss:  1.507940 (1.4460)  Time: 2.093s (348.587s),  122.30/s  (2.309s,  110.89/s)  LR: 4.432e-04  Data: 0.009 (0.009)
2024-01-31 16:57:27,636 - train - INFO - Train: 44 [ 194/195 (100%)]  Loss:  1.401047 (1.4516)  Time: 2.235s (442.996s),  114.57/s  (2.272s,  112.69/s)  LR: 4.432e-04  Data: 0.000 (0.009)
2024-01-31 16:57:27,638 - train - INFO - alphas:tensor([0.5919, 0.2023, 0.2059], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,638 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,639 - train - INFO - alphas:tensor([0.4923, 0.2029, 0.3048], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,639 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,640 - train - INFO - alphas:tensor([0.5889, 0.1937, 0.2174], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,640 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,641 - train - INFO - alphas:tensor([0.4312, 0.2160, 0.3528], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,641 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,642 - train - INFO - alphas:tensor([0.6074, 0.1853, 0.2073], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,642 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,642 - train - INFO - alphas:tensor([0.3557, 0.1045, 0.0991, 0.1450, 0.2958], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,642 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,643 - train - INFO - alphas:tensor([0.5637, 0.1912, 0.2451], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,643 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,644 - train - INFO - alphas:tensor([0.3897, 0.1927, 0.4175], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,644 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,645 - train - INFO - alphas:tensor([0.5592, 0.1864, 0.2544], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,645 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,646 - train - INFO - alphas:tensor([0.3452, 0.1812, 0.4735], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,646 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,647 - train - INFO - alphas:tensor([0.4940, 0.1219, 0.1014, 0.1217, 0.1609], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,647 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,648 - train - INFO - alphas:tensor([0.4550, 0.1059, 0.0949, 0.1251, 0.2191], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,648 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,648 - train - INFO - alphas:tensor([0.3970, 0.0990, 0.0921, 0.1331, 0.2788], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,648 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,649 - train - INFO - alphas:tensor([0.2275, 0.0579, 0.0532, 0.1001, 0.5612], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,649 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,650 - train - INFO - alphas:tensor([0.3951, 0.0954, 0.0841, 0.1269, 0.2985], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,650 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,651 - train - INFO - alphas:tensor([0.1961, 0.0508, 0.0473, 0.0951, 0.6107], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,651 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,652 - train - INFO - alphas:tensor([0.3878, 0.0876, 0.0813, 0.1289, 0.3144], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,652 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,653 - train - INFO - alphas:tensor([0.1816, 0.0519, 0.0460, 0.0949, 0.6255], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,653 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,654 - train - INFO - alphas:tensor([0.5829, 0.0913, 0.0844, 0.1007, 0.1407], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,654 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,655 - train - INFO - alphas:tensor([0.4274, 0.0801, 0.0746, 0.1115, 0.3064], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,655 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,656 - train - INFO - alphas:tensor([0.5092, 0.0894, 0.0804, 0.1089, 0.2120], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,656 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,657 - train - INFO - alphas:tensor([0.3030, 0.0611, 0.0586, 0.1032, 0.4740], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,657 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,657 - train - INFO - alphas:tensor([0.5209, 0.0838, 0.0782, 0.1074, 0.2097], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,658 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,658 - train - INFO - alphas:tensor([0.2712, 0.0575, 0.0535, 0.0986, 0.5192], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,658 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,659 - train - INFO - alphas:tensor([0.5604, 0.0879, 0.0806, 0.1025, 0.1686], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,659 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,660 - train - INFO - alphas:tensor([0.4331, 0.0741, 0.0737, 0.1075, 0.3117], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,660 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,661 - train - INFO - alphas:tensor([0.3702, 0.0740, 0.0694, 0.1131, 0.3734], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,661 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,662 - train - INFO - alphas:tensor([0.2142, 0.0441, 0.0399, 0.0686, 0.6331], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,662 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,663 - train - INFO - alphas:tensor([0.3980, 0.0744, 0.0700, 0.1078, 0.3498], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,663 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,664 - train - INFO - alphas:tensor([0.1765, 0.0468, 0.0376, 0.0731, 0.6661], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,664 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,665 - train - INFO - alphas:tensor([0.5605, 0.0782, 0.0773, 0.0973, 0.1868], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,665 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,666 - train - INFO - alphas:tensor([0.1986, 0.0714, 0.0594, 0.0985, 0.5721], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 16:57:27,666 - train - INFO - tau:0.022107391972073363
2024-01-31 16:57:27,666 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 16:57:29,535 - train - INFO - Test: [   0/39]  Time: 1.861 (1.861s) Loss:  0.3894 (0.3894)  Acc@1: 94.9219 (94.9219)  Acc@5: 100.0000 (100.0000)
2024-01-31 16:58:41,766 - train - INFO - Test: [  39/39]  Time: 1.712 (74.092s) Loss:  0.4834 (0.4270)  Acc@1: 93.7500 (93.2200)  Acc@5: 100.0000 (99.7700)
2024-01-31 16:58:44,414 - train - INFO - Train: 45 [   0/195 (  0%)]  Loss:  1.415250 (1.4153)  Time: 2.417s (2.417s),  105.90/s  (2.417s,  105.90/s)  LR: 4.387e-04  Data: 0.255 (0.255)
2024-01-31 17:00:36,847 - train - INFO - Train: 45 [  50/195 ( 26%)]  Loss:  1.311701 (1.4324)  Time: 2.398s (114.848s),  106.77/s  (2.252s,  113.68/s)  LR: 4.387e-04  Data: 0.023 (0.013)
2024-01-31 17:02:35,223 - train - INFO - Train: 45 [ 100/195 ( 52%)]  Loss:  1.384095 (1.4308)  Time: 2.438s (233.223s),  104.99/s  (2.309s,  110.86/s)  LR: 4.387e-04  Data: 0.009 (0.010)
2024-01-31 17:04:28,371 - train - INFO - Train: 45 [ 150/195 ( 77%)]  Loss:  1.560827 (1.4318)  Time: 2.304s (346.370s),  111.09/s  (2.294s,  111.60/s)  LR: 4.387e-04  Data: 0.005 (0.009)
2024-01-31 17:06:11,008 - train - INFO - Train: 45 [ 194/195 (100%)]  Loss:  1.364725 (1.4399)  Time: 2.402s (449.005s),  106.59/s  (2.303s,  111.18/s)  LR: 4.387e-04  Data: 0.000 (0.009)
2024-01-31 17:06:11,009 - train - INFO - alphas:tensor([0.5947, 0.2005, 0.2048], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,010 - train - INFO - alphas:tensor([0.4909, 0.2022, 0.3069], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,011 - train - INFO - alphas:tensor([0.5891, 0.1929, 0.2180], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,012 - train - INFO - alphas:tensor([0.4303, 0.2153, 0.3544], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,012 - train - INFO - alphas:tensor([0.6074, 0.1851, 0.2075], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,013 - train - INFO - alphas:tensor([0.3547, 0.1037, 0.0984, 0.1449, 0.2983], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,014 - train - INFO - alphas:tensor([0.5631, 0.1913, 0.2456], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,015 - train - INFO - alphas:tensor([0.3885, 0.1908, 0.4207], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,017 - train - INFO - alphas:tensor([0.5589, 0.1858, 0.2554], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,017 - train - INFO - alphas:tensor([0.3439, 0.1798, 0.4763], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,018 - train - INFO - alphas:tensor([0.4940, 0.1212, 0.1012, 0.1220, 0.1616], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,019 - train - INFO - alphas:tensor([0.4582, 0.1041, 0.0939, 0.1241, 0.2197], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,020 - train - INFO - alphas:tensor([0.3940, 0.0981, 0.0913, 0.1335, 0.2830], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,020 - train - INFO - alphas:tensor([0.2262, 0.0570, 0.0523, 0.0988, 0.5658], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,021 - train - INFO - alphas:tensor([0.3957, 0.0946, 0.0834, 0.1258, 0.3005], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,022 - train - INFO - alphas:tensor([0.1939, 0.0498, 0.0462, 0.0938, 0.6162], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,023 - train - INFO - alphas:tensor([0.3844, 0.0870, 0.0808, 0.1286, 0.3192], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,024 - train - INFO - alphas:tensor([0.1804, 0.0512, 0.0448, 0.0928, 0.6308], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,024 - train - INFO - alphas:tensor([0.5837, 0.0910, 0.0842, 0.1004, 0.1407], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,025 - train - INFO - alphas:tensor([0.4257, 0.0794, 0.0735, 0.1108, 0.3105], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,026 - train - INFO - alphas:tensor([0.5102, 0.0880, 0.0791, 0.1086, 0.2141], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,027 - train - INFO - alphas:tensor([0.3012, 0.0597, 0.0573, 0.1015, 0.4803], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,028 - train - INFO - alphas:tensor([0.5194, 0.0829, 0.0777, 0.1073, 0.2127], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,029 - train - INFO - alphas:tensor([0.2690, 0.0566, 0.0524, 0.0970, 0.5250], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,029 - train - INFO - alphas:tensor([0.5625, 0.0869, 0.0792, 0.1013, 0.1702], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,030 - train - INFO - alphas:tensor([0.4300, 0.0733, 0.0732, 0.1076, 0.3159], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,031 - train - INFO - alphas:tensor([0.3695, 0.0732, 0.0686, 0.1123, 0.3764], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,032 - train - INFO - alphas:tensor([0.2116, 0.0432, 0.0389, 0.0669, 0.6394], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,032 - train - INFO - alphas:tensor([0.3937, 0.0730, 0.0689, 0.1071, 0.3573], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,033 - train - INFO - alphas:tensor([0.1768, 0.0463, 0.0369, 0.0722, 0.6678], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,034 - train - INFO - alphas:tensor([0.5614, 0.0776, 0.0767, 0.0964, 0.1879], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,035 - train - INFO - alphas:tensor([0.1966, 0.0707, 0.0585, 0.0975, 0.5766], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:06:11,035 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 17:06:13,214 - train - INFO - Test: [   0/39]  Time: 2.172 (2.172s) Loss:  0.4133 (0.4133)  Acc@1: 93.7500 (93.7500)  Acc@5: 99.6094 (99.6094)
2024-01-31 17:07:23,298 - train - INFO - Test: [  39/39]  Time: 2.103 (72.254s) Loss:  0.5122 (0.4195)  Acc@1: 87.5000 (93.5400)  Acc@5: 100.0000 (99.7800)
2024-01-31 17:07:26,038 - train - INFO - Train: 46 [   0/195 (  0%)]  Loss:  1.434696 (1.4347)  Time: 2.638s (2.638s),   97.04/s  (2.638s,   97.04/s)  LR: 4.341e-04  Data: 0.238 (0.238)
2024-01-31 17:09:20,175 - train - INFO - Train: 46 [  50/195 ( 26%)]  Loss:  1.381977 (1.4409)  Time: 2.261s (116.773s),  113.20/s  (2.290s,  111.81/s)  LR: 4.341e-04  Data: 0.004 (0.013)
2024-01-31 17:11:12,598 - train - INFO - Train: 46 [ 100/195 ( 52%)]  Loss:  1.313752 (1.4372)  Time: 2.356s (229.194s),  108.65/s  (2.269s,  112.81/s)  LR: 4.341e-04  Data: 0.007 (0.012)
2024-01-31 17:13:08,009 - train - INFO - Train: 46 [ 150/195 ( 77%)]  Loss:  1.421899 (1.4455)  Time: 2.445s (344.604s),  104.70/s  (2.282s,  112.18/s)  LR: 4.341e-04  Data: 0.008 (0.011)
2024-01-31 17:14:51,916 - train - INFO - Train: 46 [ 194/195 (100%)]  Loss:  1.361275 (1.4454)  Time: 2.193s (448.504s),  116.73/s  (2.300s,  111.30/s)  LR: 4.341e-04  Data: 0.000 (0.010)
2024-01-31 17:14:51,929 - train - INFO - alphas:tensor([0.5946, 0.2001, 0.2053], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,934 - train - INFO - alphas:tensor([0.4907, 0.2014, 0.3079], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,935 - train - INFO - alphas:tensor([0.5904, 0.1925, 0.2171], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,940 - train - INFO - alphas:tensor([0.4268, 0.2141, 0.3591], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,941 - train - INFO - alphas:tensor([0.6072, 0.1850, 0.2078], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,942 - train - INFO - alphas:tensor([0.3523, 0.1034, 0.0977, 0.1442, 0.3024], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,943 - train - INFO - alphas:tensor([0.5590, 0.1917, 0.2493], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,943 - train - INFO - alphas:tensor([0.3866, 0.1891, 0.4243], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,944 - train - INFO - alphas:tensor([0.5568, 0.1860, 0.2573], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,949 - train - INFO - alphas:tensor([0.3407, 0.1774, 0.4819], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,950 - train - INFO - alphas:tensor([0.4957, 0.1208, 0.1006, 0.1209, 0.1620], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,951 - train - INFO - alphas:tensor([0.4587, 0.1028, 0.0928, 0.1237, 0.2220], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,952 - train - INFO - alphas:tensor([0.3941, 0.0971, 0.0901, 0.1336, 0.2851], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,953 - train - INFO - alphas:tensor([0.2243, 0.0554, 0.0511, 0.0969, 0.5724], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,953 - train - INFO - alphas:tensor([0.3917, 0.0940, 0.0826, 0.1258, 0.3059], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,959 - train - INFO - alphas:tensor([0.1917, 0.0486, 0.0451, 0.0921, 0.6225], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,959 - train - INFO - alphas:tensor([0.3823, 0.0872, 0.0803, 0.1282, 0.3221], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,960 - train - INFO - alphas:tensor([0.1785, 0.0502, 0.0438, 0.0916, 0.6359], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,961 - train - INFO - alphas:tensor([0.5850, 0.0901, 0.0831, 0.1002, 0.1415], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,962 - train - INFO - alphas:tensor([0.4242, 0.0783, 0.0728, 0.1104, 0.3143], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,962 - train - INFO - alphas:tensor([0.5119, 0.0873, 0.0783, 0.1079, 0.2146], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,965 - train - INFO - alphas:tensor([0.2990, 0.0583, 0.0559, 0.1002, 0.4865], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,969 - train - INFO - alphas:tensor([0.5206, 0.0825, 0.0766, 0.1070, 0.2133], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,972 - train - INFO - alphas:tensor([0.2664, 0.0559, 0.0516, 0.0964, 0.5297], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,973 - train - INFO - alphas:tensor([0.5623, 0.0857, 0.0786, 0.1011, 0.1724], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,974 - train - INFO - alphas:tensor([0.4285, 0.0722, 0.0718, 0.1060, 0.3216], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,979 - train - INFO - alphas:tensor([0.3679, 0.0718, 0.0676, 0.1105, 0.3822], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,980 - train - INFO - alphas:tensor([0.2122, 0.0429, 0.0380, 0.0655, 0.6414], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,981 - train - INFO - alphas:tensor([0.3926, 0.0716, 0.0676, 0.1059, 0.3622], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,982 - train - INFO - alphas:tensor([0.1761, 0.0457, 0.0361, 0.0716, 0.6705], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,983 - train - INFO - alphas:tensor([0.5615, 0.0768, 0.0759, 0.0954, 0.1904], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,983 - train - INFO - alphas:tensor([0.1958, 0.0701, 0.0578, 0.0966, 0.5797], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:14:51,984 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 17:14:54,002 - train - INFO - Test: [   0/39]  Time: 2.001 (2.001s) Loss:  0.4211 (0.4211)  Acc@1: 94.1406 (94.1406)  Acc@5: 99.6094 (99.6094)
2024-01-31 17:16:05,061 - train - INFO - Test: [  39/39]  Time: 1.687 (73.060s) Loss:  0.4736 (0.4267)  Acc@1: 93.7500 (93.5500)  Acc@5: 100.0000 (99.7900)
2024-01-31 17:16:07,593 - train - INFO - Train: 47 [   0/195 (  0%)]  Loss:  1.521405 (1.5214)  Time: 2.339s (2.339s),  109.45/s  (2.339s,  109.45/s)  LR: 4.294e-04  Data: 0.230 (0.230)
2024-01-31 17:18:02,064 - train - INFO - Train: 47 [  50/195 ( 26%)]  Loss:  1.426977 (1.4654)  Time: 1.813s (116.808s),  141.18/s  (2.290s,  111.77/s)  LR: 4.294e-04  Data: 0.031 (0.013)
2024-01-31 17:19:57,663 - train - INFO - Train: 47 [ 100/195 ( 52%)]  Loss:  1.533157 (1.4542)  Time: 2.309s (232.406s),  110.88/s  (2.301s,  111.25/s)  LR: 4.294e-04  Data: 0.021 (0.011)
2024-01-31 17:21:53,750 - train - INFO - Train: 47 [ 150/195 ( 77%)]  Loss:  1.570785 (1.4523)  Time: 2.180s (348.491s),  117.42/s  (2.308s,  110.92/s)  LR: 4.294e-04  Data: 0.005 (0.010)
2024-01-31 17:23:32,166 - train - INFO - Train: 47 [ 194/195 (100%)]  Loss:  1.559895 (1.4569)  Time: 2.262s (446.906s),  113.18/s  (2.292s,  111.70/s)  LR: 4.294e-04  Data: 0.000 (0.010)
2024-01-31 17:23:32,167 - train - INFO - alphas:tensor([0.5951, 0.1998, 0.2051], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,168 - train - INFO - alphas:tensor([0.4893, 0.2007, 0.3100], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,169 - train - INFO - alphas:tensor([0.5908, 0.1917, 0.2175], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,170 - train - INFO - alphas:tensor([0.4257, 0.2132, 0.3612], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,170 - train - INFO - alphas:tensor([0.6100, 0.1838, 0.2063], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,172 - train - INFO - alphas:tensor([0.3516, 0.1015, 0.0962, 0.1437, 0.3071], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,173 - train - INFO - alphas:tensor([0.5582, 0.1914, 0.2504], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,174 - train - INFO - alphas:tensor([0.3857, 0.1883, 0.4260], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,174 - train - INFO - alphas:tensor([0.5577, 0.1843, 0.2581], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,175 - train - INFO - alphas:tensor([0.3373, 0.1760, 0.4867], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,176 - train - INFO - alphas:tensor([0.4973, 0.1204, 0.0997, 0.1205, 0.1620], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,177 - train - INFO - alphas:tensor([0.4607, 0.1022, 0.0918, 0.1223, 0.2230], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,178 - train - INFO - alphas:tensor([0.3928, 0.0965, 0.0898, 0.1328, 0.2881], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,178 - train - INFO - alphas:tensor([0.2227, 0.0539, 0.0501, 0.0954, 0.5780], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,179 - train - INFO - alphas:tensor([0.3887, 0.0930, 0.0821, 0.1253, 0.3110], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,180 - train - INFO - alphas:tensor([0.1922, 0.0481, 0.0442, 0.0901, 0.6254], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,181 - train - INFO - alphas:tensor([0.3788, 0.0865, 0.0799, 0.1279, 0.3270], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,182 - train - INFO - alphas:tensor([0.1764, 0.0492, 0.0428, 0.0899, 0.6417], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,182 - train - INFO - alphas:tensor([0.5880, 0.0895, 0.0827, 0.0989, 0.1408], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,183 - train - INFO - alphas:tensor([0.4244, 0.0770, 0.0717, 0.1102, 0.3167], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,184 - train - INFO - alphas:tensor([0.5087, 0.0865, 0.0780, 0.1078, 0.2190], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,185 - train - INFO - alphas:tensor([0.2993, 0.0573, 0.0548, 0.0991, 0.4895], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,186 - train - INFO - alphas:tensor([0.5223, 0.0814, 0.0753, 0.1060, 0.2150], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,187 - train - INFO - alphas:tensor([0.2664, 0.0551, 0.0507, 0.0949, 0.5330], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,188 - train - INFO - alphas:tensor([0.5626, 0.0849, 0.0780, 0.1005, 0.1741], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,188 - train - INFO - alphas:tensor([0.4239, 0.0713, 0.0714, 0.1064, 0.3270], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,189 - train - INFO - alphas:tensor([0.3688, 0.0710, 0.0664, 0.1090, 0.3848], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,190 - train - INFO - alphas:tensor([0.2116, 0.0423, 0.0373, 0.0647, 0.6441], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,191 - train - INFO - alphas:tensor([0.3931, 0.0710, 0.0667, 0.1050, 0.3641], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,192 - train - INFO - alphas:tensor([0.1764, 0.0453, 0.0354, 0.0704, 0.6724], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,193 - train - INFO - alphas:tensor([0.5602, 0.0756, 0.0751, 0.0957, 0.1935], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,194 - train - INFO - alphas:tensor([0.1958, 0.0698, 0.0572, 0.0958, 0.5814], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:23:32,194 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 17:23:34,241 - train - INFO - Test: [   0/39]  Time: 2.038 (2.038s) Loss:  0.4307 (0.4307)  Acc@1: 92.1875 (92.1875)  Acc@5: 100.0000 (100.0000)
2024-01-31 17:24:46,250 - train - INFO - Test: [  39/39]  Time: 1.812 (74.047s) Loss:  0.4551 (0.4328)  Acc@1: 93.7500 (92.9700)  Acc@5: 100.0000 (99.7400)
2024-01-31 17:24:48,918 - train - INFO - Train: 48 [   0/195 (  0%)]  Loss:  1.565053 (1.5651)  Time: 2.560s (2.560s),  100.02/s  (2.560s,  100.02/s)  LR: 4.247e-04  Data: 0.283 (0.283)
2024-01-31 17:26:38,976 - train - INFO - Train: 48 [  50/195 ( 26%)]  Loss:  1.370441 (1.4507)  Time: 2.394s (112.616s),  106.91/s  (2.208s,  115.93/s)  LR: 4.247e-04  Data: 0.018 (0.015)
2024-01-31 17:28:34,446 - train - INFO - Train: 48 [ 100/195 ( 52%)]  Loss:  1.478996 (1.4451)  Time: 2.193s (228.085s),  116.72/s  (2.258s,  113.36/s)  LR: 4.247e-04  Data: 0.005 (0.012)
2024-01-31 17:30:24,437 - train - INFO - Train: 48 [ 150/195 ( 77%)]  Loss:  1.450433 (1.4452)  Time: 2.423s (338.074s),  105.65/s  (2.239s,  114.34/s)  LR: 4.247e-04  Data: 0.009 (0.011)
2024-01-31 17:32:08,253 - train - INFO - Train: 48 [ 194/195 (100%)]  Loss:  1.598179 (1.4444)  Time: 2.357s (441.890s),  108.62/s  (2.266s,  112.97/s)  LR: 4.247e-04  Data: 0.000 (0.010)
2024-01-31 17:32:08,255 - train - INFO - alphas:tensor([0.5952, 0.2004, 0.2044], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,255 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,256 - train - INFO - alphas:tensor([0.4878, 0.2007, 0.3115], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,256 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,257 - train - INFO - alphas:tensor([0.5903, 0.1916, 0.2181], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,257 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,257 - train - INFO - alphas:tensor([0.4242, 0.2116, 0.3642], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,257 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,258 - train - INFO - alphas:tensor([0.6105, 0.1832, 0.2063], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,258 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,259 - train - INFO - alphas:tensor([0.3505, 0.1003, 0.0953, 0.1436, 0.3102], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,259 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,260 - train - INFO - alphas:tensor([0.5563, 0.1909, 0.2528], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,260 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,261 - train - INFO - alphas:tensor([0.3829, 0.1870, 0.4301], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,261 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,261 - train - INFO - alphas:tensor([0.5529, 0.1852, 0.2619], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,262 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,262 - train - INFO - alphas:tensor([0.3349, 0.1740, 0.4911], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,263 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,263 - train - INFO - alphas:tensor([0.4979, 0.1199, 0.0997, 0.1201, 0.1625], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,263 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,264 - train - INFO - alphas:tensor([0.4605, 0.1015, 0.0912, 0.1220, 0.2248], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,264 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,265 - train - INFO - alphas:tensor([0.3952, 0.0959, 0.0893, 0.1312, 0.2884], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,265 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,266 - train - INFO - alphas:tensor([0.2205, 0.0532, 0.0491, 0.0938, 0.5835], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,266 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,267 - train - INFO - alphas:tensor([0.3877, 0.0919, 0.0814, 0.1245, 0.3145], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,267 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,268 - train - INFO - alphas:tensor([0.1900, 0.0470, 0.0431, 0.0884, 0.6315], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,268 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,268 - train - INFO - alphas:tensor([0.3774, 0.0855, 0.0783, 0.1271, 0.3317], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,268 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,269 - train - INFO - alphas:tensor([0.1761, 0.0483, 0.0421, 0.0883, 0.6453], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,269 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,270 - train - INFO - alphas:tensor([0.5896, 0.0889, 0.0825, 0.0986, 0.1404], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,270 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,271 - train - INFO - alphas:tensor([0.4234, 0.0763, 0.0706, 0.1089, 0.3208], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,271 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,272 - train - INFO - alphas:tensor([0.5069, 0.0858, 0.0775, 0.1078, 0.2220], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,272 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,273 - train - INFO - alphas:tensor([0.2970, 0.0562, 0.0540, 0.0984, 0.4944], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,273 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,273 - train - INFO - alphas:tensor([0.5237, 0.0803, 0.0742, 0.1057, 0.2161], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,273 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,274 - train - INFO - alphas:tensor([0.2650, 0.0542, 0.0496, 0.0935, 0.5377], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,274 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,275 - train - INFO - alphas:tensor([0.5640, 0.0837, 0.0766, 0.0998, 0.1758], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,275 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,276 - train - INFO - alphas:tensor([0.4261, 0.0701, 0.0703, 0.1054, 0.3282], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,276 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,277 - train - INFO - alphas:tensor([0.3683, 0.0705, 0.0659, 0.1084, 0.3869], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,277 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,277 - train - INFO - alphas:tensor([0.2087, 0.0415, 0.0365, 0.0639, 0.6493], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,278 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,278 - train - INFO - alphas:tensor([0.3899, 0.0702, 0.0659, 0.1047, 0.3694], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,279 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,279 - train - INFO - alphas:tensor([0.1756, 0.0446, 0.0346, 0.0694, 0.6759], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,279 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,280 - train - INFO - alphas:tensor([0.5614, 0.0747, 0.0740, 0.0952, 0.1948], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,280 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,281 - train - INFO - alphas:tensor([0.1945, 0.0691, 0.0564, 0.0948, 0.5852], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:32:08,281 - train - INFO - tau:0.017685913577658693
2024-01-31 17:32:08,281 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 17:32:10,470 - train - INFO - Test: [   0/39]  Time: 2.181 (2.181s) Loss:  0.4033 (0.4033)  Acc@1: 93.7500 (93.7500)  Acc@5: 99.6094 (99.6094)
2024-01-31 17:33:20,317 - train - INFO - Test: [  39/39]  Time: 1.633 (72.028s) Loss:  0.5474 (0.4295)  Acc@1: 93.7500 (93.4800)  Acc@5: 100.0000 (99.7900)
2024-01-31 17:33:22,884 - train - INFO - Train: 49 [   0/195 (  0%)]  Loss:  1.352216 (1.3522)  Time: 2.397s (2.397s),  106.81/s  (2.397s,  106.81/s)  LR: 4.199e-04  Data: 0.151 (0.151)
2024-01-31 17:35:21,524 - train - INFO - Train: 49 [  50/195 ( 26%)]  Loss:  1.400767 (1.4384)  Time: 2.434s (121.035s),  105.16/s  (2.373s,  107.87/s)  LR: 4.199e-04  Data: 0.004 (0.012)
2024-01-31 17:37:12,149 - train - INFO - Train: 49 [ 100/195 ( 52%)]  Loss:  1.413291 (1.4306)  Time: 2.119s (231.658s),  120.81/s  (2.294s,  111.61/s)  LR: 4.199e-04  Data: 0.009 (0.011)
2024-01-31 17:38:59,164 - train - INFO - Train: 49 [ 150/195 ( 77%)]  Loss:  1.325193 (1.4330)  Time: 1.833s (338.672s),  139.68/s  (2.243s,  114.14/s)  LR: 4.199e-04  Data: 0.009 (0.010)
2024-01-31 17:40:36,659 - train - INFO - Train: 49 [ 194/195 (100%)]  Loss:  1.439378 (1.4371)  Time: 2.272s (436.166s),  112.67/s  (2.237s,  114.45/s)  LR: 4.199e-04  Data: 0.000 (0.010)
2024-01-31 17:40:36,661 - train - INFO - alphas:tensor([0.5953, 0.1999, 0.2048], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,662 - train - INFO - alphas:tensor([0.4866, 0.2000, 0.3134], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,663 - train - INFO - alphas:tensor([0.5932, 0.1899, 0.2169], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,664 - train - INFO - alphas:tensor([0.4222, 0.2109, 0.3669], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,665 - train - INFO - alphas:tensor([0.6112, 0.1828, 0.2060], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,666 - train - INFO - alphas:tensor([0.3497, 0.0993, 0.0943, 0.1430, 0.3137], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,667 - train - INFO - alphas:tensor([0.5547, 0.1909, 0.2544], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,668 - train - INFO - alphas:tensor([0.3801, 0.1849, 0.4350], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,669 - train - INFO - alphas:tensor([0.5521, 0.1848, 0.2632], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,670 - train - INFO - alphas:tensor([0.3312, 0.1724, 0.4964], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,671 - train - INFO - alphas:tensor([0.4976, 0.1195, 0.0996, 0.1201, 0.1632], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,672 - train - INFO - alphas:tensor([0.4608, 0.1006, 0.0902, 0.1218, 0.2266], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,673 - train - INFO - alphas:tensor([0.3908, 0.0945, 0.0888, 0.1326, 0.2933], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,673 - train - INFO - alphas:tensor([0.2174, 0.0516, 0.0479, 0.0923, 0.5908], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,675 - train - INFO - alphas:tensor([0.3868, 0.0913, 0.0804, 0.1235, 0.3179], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,676 - train - INFO - alphas:tensor([0.1879, 0.0462, 0.0421, 0.0869, 0.6369], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,677 - train - INFO - alphas:tensor([0.3773, 0.0852, 0.0777, 0.1262, 0.3336], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,678 - train - INFO - alphas:tensor([0.1731, 0.0468, 0.0408, 0.0863, 0.6530], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,679 - train - INFO - alphas:tensor([0.5902, 0.0887, 0.0821, 0.0979, 0.1411], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,679 - train - INFO - alphas:tensor([0.4210, 0.0752, 0.0696, 0.1086, 0.3255], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,681 - train - INFO - alphas:tensor([0.5081, 0.0849, 0.0767, 0.1075, 0.2228], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,682 - train - INFO - alphas:tensor([0.2946, 0.0552, 0.0532, 0.0975, 0.4995], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,682 - train - INFO - alphas:tensor([0.5223, 0.0794, 0.0736, 0.1056, 0.2191], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,683 - train - INFO - alphas:tensor([0.2654, 0.0532, 0.0484, 0.0926, 0.5405], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,684 - train - INFO - alphas:tensor([0.5626, 0.0829, 0.0758, 0.0996, 0.1791], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,685 - train - INFO - alphas:tensor([0.4252, 0.0693, 0.0695, 0.1050, 0.3311], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,686 - train - INFO - alphas:tensor([0.3666, 0.0695, 0.0648, 0.1078, 0.3913], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,687 - train - INFO - alphas:tensor([0.2071, 0.0408, 0.0359, 0.0633, 0.6530], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,688 - train - INFO - alphas:tensor([0.3877, 0.0701, 0.0654, 0.1047, 0.3721], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,689 - train - INFO - alphas:tensor([0.1748, 0.0444, 0.0340, 0.0681, 0.6786], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,689 - train - INFO - alphas:tensor([0.5607, 0.0741, 0.0731, 0.0947, 0.1974], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,690 - train - INFO - alphas:tensor([0.1924, 0.0684, 0.0557, 0.0945, 0.5889], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:40:36,691 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 17:40:38,622 - train - INFO - Test: [   0/39]  Time: 1.924 (1.924s) Loss:  0.4211 (0.4211)  Acc@1: 92.5781 (92.5781)  Acc@5: 99.6094 (99.6094)
2024-01-31 17:41:49,597 - train - INFO - Test: [  39/39]  Time: 2.019 (72.898s) Loss:  0.4824 (0.4345)  Acc@1: 93.7500 (93.4900)  Acc@5: 100.0000 (99.7100)
2024-01-31 17:41:52,200 - train - INFO - Train: 50 [   0/195 (  0%)]  Loss:  1.310530 (1.3105)  Time: 2.510s (2.510s),  101.98/s  (2.510s,  101.98/s)  LR: 4.150e-04  Data: 0.162 (0.162)
2024-01-31 17:43:43,120 - train - INFO - Train: 50 [  50/195 ( 26%)]  Loss:  1.284074 (1.4444)  Time: 2.292s (113.429s),  111.69/s  (2.224s,  115.10/s)  LR: 4.150e-04  Data: 0.004 (0.012)
2024-01-31 17:45:36,929 - train - INFO - Train: 50 [ 100/195 ( 52%)]  Loss:  1.335504 (1.4289)  Time: 2.295s (227.235s),  111.55/s  (2.250s,  113.79/s)  LR: 4.150e-04  Data: 0.007 (0.011)
2024-01-31 17:47:23,899 - train - INFO - Train: 50 [ 150/195 ( 77%)]  Loss:  1.484254 (1.4349)  Time: 1.992s (334.205s),  128.53/s  (2.213s,  115.67/s)  LR: 4.150e-04  Data: 0.015 (0.010)
2024-01-31 17:49:03,981 - train - INFO - Train: 50 [ 194/195 (100%)]  Loss:  1.400754 (1.4321)  Time: 2.101s (434.285s),  121.86/s  (2.227s,  114.95/s)  LR: 4.150e-04  Data: 0.000 (0.009)
2024-01-31 17:49:03,984 - train - INFO - alphas:tensor([0.5972, 0.1988, 0.2040], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:03,985 - train - INFO - alphas:tensor([0.4851, 0.1987, 0.3162], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:03,986 - train - INFO - alphas:tensor([0.5920, 0.1900, 0.2180], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:03,987 - train - INFO - alphas:tensor([0.4202, 0.2096, 0.3703], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:03,989 - train - INFO - alphas:tensor([0.6111, 0.1820, 0.2069], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:03,990 - train - INFO - alphas:tensor([0.3492, 0.0984, 0.0935, 0.1422, 0.3168], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:03,991 - train - INFO - alphas:tensor([0.5539, 0.1915, 0.2545], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:03,992 - train - INFO - alphas:tensor([0.3777, 0.1849, 0.4375], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:03,992 - train - INFO - alphas:tensor([0.5507, 0.1835, 0.2657], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:03,993 - train - INFO - alphas:tensor([0.3295, 0.1708, 0.4997], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:03,994 - train - INFO - alphas:tensor([0.5000, 0.1187, 0.0987, 0.1196, 0.1630], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:03,995 - train - INFO - alphas:tensor([0.4604, 0.0996, 0.0895, 0.1219, 0.2287], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:03,996 - train - INFO - alphas:tensor([0.3905, 0.0938, 0.0882, 0.1326, 0.2948], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:03,997 - train - INFO - alphas:tensor([0.2171, 0.0506, 0.0468, 0.0912, 0.5944], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:03,998 - train - INFO - alphas:tensor([0.3845, 0.0902, 0.0794, 0.1237, 0.3222], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:03,998 - train - INFO - alphas:tensor([0.1864, 0.0453, 0.0411, 0.0854, 0.6418], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:03,999 - train - INFO - alphas:tensor([0.3749, 0.0850, 0.0772, 0.1263, 0.3367], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:04,000 - train - INFO - alphas:tensor([0.1718, 0.0457, 0.0398, 0.0853, 0.6573], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:04,001 - train - INFO - alphas:tensor([0.5920, 0.0882, 0.0814, 0.0976, 0.1408], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:04,002 - train - INFO - alphas:tensor([0.4169, 0.0746, 0.0694, 0.1083, 0.3308], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:04,003 - train - INFO - alphas:tensor([0.5077, 0.0848, 0.0763, 0.1071, 0.2242], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:04,004 - train - INFO - alphas:tensor([0.2922, 0.0543, 0.0522, 0.0963, 0.5050], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:04,004 - train - INFO - alphas:tensor([0.5183, 0.0791, 0.0734, 0.1062, 0.2229], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:04,005 - train - INFO - alphas:tensor([0.2632, 0.0523, 0.0478, 0.0920, 0.5448], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:04,006 - train - INFO - alphas:tensor([0.5643, 0.0822, 0.0756, 0.0990, 0.1788], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:04,007 - train - INFO - alphas:tensor([0.4242, 0.0683, 0.0690, 0.1043, 0.3343], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:04,008 - train - INFO - alphas:tensor([0.3623, 0.0687, 0.0640, 0.1082, 0.3968], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:04,009 - train - INFO - alphas:tensor([0.2059, 0.0399, 0.0349, 0.0621, 0.6573], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:04,009 - train - INFO - alphas:tensor([0.3849, 0.0692, 0.0645, 0.1037, 0.3777], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:04,010 - train - INFO - alphas:tensor([0.1727, 0.0435, 0.0331, 0.0668, 0.6838], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:04,011 - train - INFO - alphas:tensor([0.5606, 0.0734, 0.0724, 0.0942, 0.1994], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:04,012 - train - INFO - alphas:tensor([0.1920, 0.0682, 0.0551, 0.0937, 0.5910], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:49:04,012 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 17:49:05,926 - train - INFO - Test: [   0/39]  Time: 1.905 (1.905s) Loss:  0.4133 (0.4133)  Acc@1: 93.3594 (93.3594)  Acc@5: 100.0000 (100.0000)
2024-01-31 17:50:17,901 - train - INFO - Test: [  39/39]  Time: 1.944 (73.879s) Loss:  0.4673 (0.4137)  Acc@1: 93.7500 (93.7300)  Acc@5: 100.0000 (99.8100)
2024-01-31 17:50:20,452 - train - INFO - Train: 51 [   0/195 (  0%)]  Loss:  1.311472 (1.3115)  Time: 2.455s (2.455s),  104.29/s  (2.455s,  104.29/s)  LR: 4.101e-04  Data: 0.188 (0.188)
2024-01-31 17:52:16,022 - train - INFO - Train: 51 [  50/195 ( 26%)]  Loss:  1.577597 (1.4493)  Time: 2.439s (118.023s),  104.95/s  (2.314s,  110.62/s)  LR: 4.101e-04  Data: 0.004 (0.012)
2024-01-31 17:54:05,213 - train - INFO - Train: 51 [ 100/195 ( 52%)]  Loss:  1.576850 (1.4597)  Time: 2.092s (227.213s),  122.38/s  (2.250s,  113.80/s)  LR: 4.101e-04  Data: 0.026 (0.011)
2024-01-31 17:56:02,952 - train - INFO - Train: 51 [ 150/195 ( 77%)]  Loss:  1.471490 (1.4517)  Time: 2.402s (344.949s),  106.56/s  (2.284s,  112.06/s)  LR: 4.101e-04  Data: 0.009 (0.010)
2024-01-31 17:57:44,387 - train - INFO - Train: 51 [ 194/195 (100%)]  Loss:  1.323118 (1.4413)  Time: 2.447s (446.380s),  104.60/s  (2.289s,  111.83/s)  LR: 4.101e-04  Data: 0.000 (0.010)
2024-01-31 17:57:44,390 - train - INFO - alphas:tensor([0.5988, 0.1981, 0.2032], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,391 - train - INFO - alphas:tensor([0.4838, 0.1992, 0.3170], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,392 - train - INFO - alphas:tensor([0.5910, 0.1904, 0.2186], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,393 - train - INFO - alphas:tensor([0.4190, 0.2094, 0.3716], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,393 - train - INFO - alphas:tensor([0.6147, 0.1799, 0.2054], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,394 - train - INFO - alphas:tensor([0.3475, 0.0974, 0.0927, 0.1422, 0.3202], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,395 - train - INFO - alphas:tensor([0.5525, 0.1917, 0.2558], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,396 - train - INFO - alphas:tensor([0.3756, 0.1837, 0.4407], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,396 - train - INFO - alphas:tensor([0.5495, 0.1839, 0.2666], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,410 - train - INFO - alphas:tensor([0.3281, 0.1697, 0.5023], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,416 - train - INFO - alphas:tensor([0.5012, 0.1179, 0.0980, 0.1195, 0.1634], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,420 - train - INFO - alphas:tensor([0.4602, 0.0987, 0.0889, 0.1218, 0.2304], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,421 - train - INFO - alphas:tensor([0.3877, 0.0930, 0.0875, 0.1321, 0.2997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,426 - train - INFO - alphas:tensor([0.2150, 0.0494, 0.0457, 0.0893, 0.6006], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,426 - train - INFO - alphas:tensor([0.3812, 0.0889, 0.0789, 0.1240, 0.3271], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,427 - train - INFO - alphas:tensor([0.1844, 0.0443, 0.0405, 0.0840, 0.6469], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,428 - train - INFO - alphas:tensor([0.3731, 0.0837, 0.0765, 0.1262, 0.3405], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,429 - train - INFO - alphas:tensor([0.1709, 0.0450, 0.0390, 0.0838, 0.6613], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,429 - train - INFO - alphas:tensor([0.5921, 0.0872, 0.0807, 0.0976, 0.1424], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,430 - train - INFO - alphas:tensor([0.4148, 0.0736, 0.0688, 0.1077, 0.3351], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,431 - train - INFO - alphas:tensor([0.5054, 0.0840, 0.0756, 0.1074, 0.2276], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,432 - train - INFO - alphas:tensor([0.2892, 0.0533, 0.0513, 0.0956, 0.5106], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,433 - train - INFO - alphas:tensor([0.5156, 0.0791, 0.0737, 0.1064, 0.2251], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,433 - train - INFO - alphas:tensor([0.2601, 0.0516, 0.0471, 0.0907, 0.5505], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,434 - train - INFO - alphas:tensor([0.5612, 0.0825, 0.0752, 0.0997, 0.1815], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,435 - train - INFO - alphas:tensor([0.4240, 0.0674, 0.0681, 0.1032, 0.3373], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,436 - train - INFO - alphas:tensor([0.3616, 0.0680, 0.0631, 0.1072, 0.4001], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,437 - train - INFO - alphas:tensor([0.2061, 0.0393, 0.0342, 0.0610, 0.6594], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,437 - train - INFO - alphas:tensor([0.3818, 0.0688, 0.0642, 0.1036, 0.3816], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,438 - train - INFO - alphas:tensor([0.1715, 0.0429, 0.0323, 0.0657, 0.6876], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,439 - train - INFO - alphas:tensor([0.5581, 0.0727, 0.0725, 0.0943, 0.2023], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,440 - train - INFO - alphas:tensor([0.1913, 0.0675, 0.0544, 0.0930, 0.5937], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 17:57:44,440 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 17:57:46,563 - train - INFO - Test: [   0/39]  Time: 2.110 (2.110s) Loss:  0.4082 (0.4082)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)
2024-01-31 17:58:58,421 - train - INFO - Test: [  39/39]  Time: 1.904 (73.968s) Loss:  0.4683 (0.4130)  Acc@1: 93.7500 (93.4000)  Acc@5: 100.0000 (99.7500)
2024-01-31 17:59:01,298 - train - INFO - Train: 52 [   0/195 (  0%)]  Loss:  1.334874 (1.3349)  Time: 2.795s (2.795s),   91.58/s  (2.795s,   91.58/s)  LR: 4.051e-04  Data: 0.168 (0.168)
2024-01-31 18:00:56,794 - train - INFO - Train: 52 [  50/195 ( 26%)]  Loss:  1.626624 (1.4522)  Time: 2.550s (118.290s),  100.39/s  (2.319s,  110.37/s)  LR: 4.051e-04  Data: 0.005 (0.014)
2024-01-31 18:02:52,604 - train - INFO - Train: 52 [ 100/195 ( 52%)]  Loss:  1.442688 (1.4458)  Time: 2.499s (234.099s),  102.44/s  (2.318s,  110.45/s)  LR: 4.051e-04  Data: 0.010 (0.011)
2024-01-31 18:04:49,162 - train - INFO - Train: 52 [ 150/195 ( 77%)]  Loss:  1.283278 (1.4448)  Time: 2.313s (350.653s),  110.69/s  (2.322s,  110.24/s)  LR: 4.051e-04  Data: 0.008 (0.010)
2024-01-31 18:06:33,545 - train - INFO - Train: 52 [ 194/195 (100%)]  Loss:  1.530713 (1.4462)  Time: 2.220s (455.033s),  115.30/s  (2.334s,  109.71/s)  LR: 4.051e-04  Data: 0.000 (0.009)
2024-01-31 18:06:33,548 - train - INFO - alphas:tensor([0.5999, 0.1974, 0.2027], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,548 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,549 - train - INFO - alphas:tensor([0.4815, 0.1996, 0.3189], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,549 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,550 - train - INFO - alphas:tensor([0.5916, 0.1903, 0.2180], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,550 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,551 - train - INFO - alphas:tensor([0.4174, 0.2084, 0.3742], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,551 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,552 - train - INFO - alphas:tensor([0.6153, 0.1794, 0.2053], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,552 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,553 - train - INFO - alphas:tensor([0.3456, 0.0966, 0.0922, 0.1419, 0.3237], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,553 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,554 - train - INFO - alphas:tensor([0.5515, 0.1912, 0.2573], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,554 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,555 - train - INFO - alphas:tensor([0.3724, 0.1828, 0.4448], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,555 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,555 - train - INFO - alphas:tensor([0.5513, 0.1831, 0.2655], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,556 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,556 - train - INFO - alphas:tensor([0.3262, 0.1683, 0.5055], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,557 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,558 - train - INFO - alphas:tensor([0.5022, 0.1175, 0.0977, 0.1194, 0.1632], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,558 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,558 - train - INFO - alphas:tensor([0.4604, 0.0976, 0.0879, 0.1215, 0.2326], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,559 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,559 - train - INFO - alphas:tensor([0.3873, 0.0922, 0.0871, 0.1313, 0.3021], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,560 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,560 - train - INFO - alphas:tensor([0.2130, 0.0486, 0.0446, 0.0877, 0.6061], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,560 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,561 - train - INFO - alphas:tensor([0.3835, 0.0883, 0.0785, 0.1228, 0.3268], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,561 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,562 - train - INFO - alphas:tensor([0.1834, 0.0431, 0.0394, 0.0826, 0.6514], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,562 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,563 - train - INFO - alphas:tensor([0.3742, 0.0827, 0.0754, 0.1249, 0.3428], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,563 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,564 - train - INFO - alphas:tensor([0.1691, 0.0439, 0.0378, 0.0825, 0.6666], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,573 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,574 - train - INFO - alphas:tensor([0.5942, 0.0867, 0.0802, 0.0966, 0.1424], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,574 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,575 - train - INFO - alphas:tensor([0.4153, 0.0731, 0.0677, 0.1068, 0.3370], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,575 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,576 - train - INFO - alphas:tensor([0.5067, 0.0828, 0.0746, 0.1065, 0.2293], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,576 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,577 - train - INFO - alphas:tensor([0.2903, 0.0527, 0.0504, 0.0941, 0.5125], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,577 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,582 - train - INFO - alphas:tensor([0.5146, 0.0785, 0.0733, 0.1065, 0.2271], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,582 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,583 - train - INFO - alphas:tensor([0.2572, 0.0512, 0.0465, 0.0896, 0.5555], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,583 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,584 - train - INFO - alphas:tensor([0.5607, 0.0815, 0.0747, 0.0993, 0.1838], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,584 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,585 - train - INFO - alphas:tensor([0.4209, 0.0666, 0.0676, 0.1033, 0.3417], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,585 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,585 - train - INFO - alphas:tensor([0.3611, 0.0672, 0.0623, 0.1061, 0.4033], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,586 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,591 - train - INFO - alphas:tensor([0.2030, 0.0386, 0.0335, 0.0601, 0.6648], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,591 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,592 - train - INFO - alphas:tensor([0.3812, 0.0684, 0.0636, 0.1024, 0.3844], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,592 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,593 - train - INFO - alphas:tensor([0.1706, 0.0425, 0.0319, 0.0647, 0.6903], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,593 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,593 - train - INFO - alphas:tensor([0.5564, 0.0722, 0.0720, 0.0940, 0.2055], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,593 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,594 - train - INFO - alphas:tensor([0.1891, 0.0669, 0.0538, 0.0927, 0.5974], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-01-31 18:06:33,594 - train - INFO - tau:0.014148730862126955
2024-01-31 18:06:33,594 - train - INFO - lasso_alpha:4.831530000000003e-05
2024-01-31 18:06:35,692 - train - INFO - Test: [   0/39]  Time: 2.084 (2.084s) Loss:  0.4028 (0.4028)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)
2024-01-31 18:07:45,975 - train - INFO - Test: [  39/39]  Time: 1.861 (72.367s) Loss:  0.5264 (0.4034)  Acc@1: 93.7500 (93.6000)  Acc@5: 100.0000 (99.7800)
2024-01-31 18:07:48,621 - train - INFO - Train: 53 [   0/195 (  0%)]  Loss:  1.576304 (1.5763)  Time: 2.550s (2.550s),  100.37/s  (2.550s,  100.37/s)  LR: 4.001e-04  Data: 0.211 (0.211)
2024-01-31 18:10:08,649 - train - INFO - Train: 53 [  50/195 ( 26%)]  Loss:  1.426443 (1.4340)  Time: 2.597s (142.577s),   98.56/s  (2.796s,   91.57/s)  LR: 4.001e-04  Data: 0.006 (0.016)
2024-01-31 18:12:28,778 - train - INFO - Train: 53 [ 100/195 ( 52%)]  Loss:  1.502633 (1.4459)  Time: 3.006s (282.705s),   85.16/s  (2.799s,   91.46/s)  LR: 4.001e-04  Data: 0.010 (0.014)
2024-01-31 18:14:12,454 - train - INFO - *** Best metric: 93.73 (epoch 50)
