{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
Files already downloaded and verified
In layer:  QConv2d(
  3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=8, pos=127, neg=-127, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=8, pos=127, neg=-128, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(3428., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(12., device='cuda:0')
In layer:  QConv2d(
  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(429., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(9., device='cuda:0')
In layer:  QConv2d(
  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(389., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(9., device='cuda:0')
In layer:  QConv2d(
  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(388., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(9., device='cuda:0')
In layer:  QConv2d(
  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(384., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(9., device='cuda:0')
In layer:  QConv2d(
  64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(389., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(9., device='cuda:0')
In layer:  QConv2d(
  64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(55., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(6., device='cuda:0')
In layer:  QConv2d(
  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(699., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(10., device='cuda:0')
In layer:  QConv2d(
  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(710., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(10., device='cuda:0')
In layer:  QConv2d(
  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(702., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(10., device='cuda:0')
In layer:  QConv2d(
  128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(702., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(10., device='cuda:0')
In layer:  QConv2d(
  128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(98., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(7., device='cuda:0')
In layer:  QConv2d(
  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(1360., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(11., device='cuda:0')
In layer:  QConv2d(
  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(1415., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(11., device='cuda:0')
In layer:  QConv2d(
  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(1374., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(11., device='cuda:0')
In layer:  QConv2d(
  256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(1423., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(11., device='cuda:0')
In layer:  QConv2d(
  256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(196., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(8., device='cuda:0')
In layer:  QConv2d(
  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(2798., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(12., device='cuda:0')
In layer:  QConv2d(
  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(2742., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(12., device='cuda:0')
In layer:  QConv2d(
  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(2256., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(12., device='cuda:0')
total ok
