{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
Files already downloaded and verified
In layer:  QConv2d(
  3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=8, pos=127, neg=-127, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=8, pos=127, neg=-128, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(3428., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(12., device='cuda:0')
In layer:  QConv2d(
  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(445., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(9., device='cuda:0')
In layer:  QConv2d(
  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(538., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(10., device='cuda:0')
In layer:  QConv2d(
  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(411., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(9., device='cuda:0')
In layer:  QConv2d(
  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(422., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(9., device='cuda:0')
In layer:  QConv2d(
  64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(397., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(9., device='cuda:0')
In layer:  QConv2d(
  64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(54., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(6., device='cuda:0')
In layer:  QConv2d(
  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(752., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(10., device='cuda:0')
In layer:  QConv2d(
  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(783., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(10., device='cuda:0')
In layer:  QConv2d(
  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(730., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(10., device='cuda:0')
In layer:  QConv2d(
  128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(714., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(10., device='cuda:0')
In layer:  QConv2d(
  128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(98., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(7., device='cuda:0')
In layer:  QConv2d(
  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(1379., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(11., device='cuda:0')
In layer:  QConv2d(
  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(1388., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(11., device='cuda:0')
In layer:  QConv2d(
  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(1360., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(11., device='cuda:0')
In layer:  QConv2d(
  256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(1450., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(11., device='cuda:0')
In layer:  QConv2d(
  256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(256., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(8., device='cuda:0')
In layer:  QConv2d(
  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(2840., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(12., device='cuda:0')
In layer:  QConv2d(
  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(4608., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(13., device='cuda:0')
In layer:  QConv2d(
  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(2592., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(12., device='cuda:0')
total ok
