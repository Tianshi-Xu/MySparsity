{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 2, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
In layer:  QConv2d(
  3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=8, pos=127, neg=-127, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=8, pos=127, neg=-128, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(3428., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(12., device='cuda:0')
In layer:  QConv2d(
  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(411., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(9., device='cuda:0')
In layer:  QConv2d(
  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(438., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(9., device='cuda:0')
In layer:  QConv2d(
  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(421., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(9., device='cuda:0')
In layer:  QConv2d(
  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(410., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(9., device='cuda:0')
In layer:  QConv2d(
  64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(398., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(9., device='cuda:0')
In layer:  QConv2d(
  64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(54., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(6., device='cuda:0')
In layer:  QConv2d(
  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(753., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(10., device='cuda:0')
In layer:  QConv2d(
  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(741., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(10., device='cuda:0')
In layer:  QConv2d(
  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(729., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(10., device='cuda:0')
In layer:  QConv2d(
  128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(715., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(10., device='cuda:0')
In layer:  QConv2d(
  128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(99., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(7., device='cuda:0')
In layer:  QConv2d(
  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(1407., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(11., device='cuda:0')
In layer:  QConv2d(
  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(1390., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(11., device='cuda:0')
In layer:  QConv2d(
  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(1427., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(11., device='cuda:0')
In layer:  QConv2d(
  256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(1404., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(11., device='cuda:0')
In layer:  QConv2d(
  256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(201., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(8., device='cuda:0')
In layer:  QConv2d(
  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(2812., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(12., device='cuda:0')
In layer:  QConv2d(
  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(2872., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(12., device='cuda:0')
In layer:  QConv2d(
  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(2716., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(12., device='cuda:0')
total ok
