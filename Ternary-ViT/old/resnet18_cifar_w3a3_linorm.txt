{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 3, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': True, 'per_channel': True, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
{'enable': True, 'mode': 'LSQ', 'bit': 8, 'thd_pos': None, 'thd_neg': None, 'all_positive': False, 'symmetric': False, 'per_channel': False, 'normalize_first': False}
Files already downloaded and verified
In layer:  QConv2d(
  3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=8, pos=127, neg=-127, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=8, pos=127, neg=-128, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(3428., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(12., device='cuda:0')
In layer:  QConv2d(
  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-3, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(1184., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(11., device='cuda:0')
In layer:  QConv2d(
  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-3, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(797., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(10., device='cuda:0')
In layer:  QConv2d(
  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-3, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(840., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(10., device='cuda:0')
In layer:  QConv2d(
  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-3, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(794., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(10., device='cuda:0')
In layer:  QConv2d(
  64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-3, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(882., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(10., device='cuda:0')
In layer:  QConv2d(
  64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
  (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-3, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(192., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(8., device='cuda:0')
In layer:  QConv2d(
  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-3, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(1493., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(11., device='cuda:0')
In layer:  QConv2d(
  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-3, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(1573., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(11., device='cuda:0')
In layer:  QConv2d(
  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-3, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(1615., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(11., device='cuda:0')
In layer:  QConv2d(
  128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-3, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(1593., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(11., device='cuda:0')
In layer:  QConv2d(
  128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
  (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-3, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(280., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(9., device='cuda:0')
In layer:  QConv2d(
  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-3, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(3168., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(12., device='cuda:0')
In layer:  QConv2d(
  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-3, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(3280., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(12., device='cuda:0')
In layer:  QConv2d(
  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-3, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(3256., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(12., device='cuda:0')
In layer:  QConv2d(
  256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-3, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(3504., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(12., device='cuda:0')
In layer:  QConv2d(
  256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
  (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-3, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(750., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(10., device='cuda:0')
In layer:  QConv2d(
  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-3, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(6808., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(13., device='cuda:0')
In layer:  QConv2d(
  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-3, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(6764., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(13., device='cuda:0')
In layer:  QConv2d(
  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
  (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-3, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
  (quan_a_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=False)
  (sparse_w_fn): IdentitySparsifier()
  (sparse_a_fn): IdentitySparsifier()
)
max l1 norm:  tensor(4860., device='cuda:0', dtype=torch.float16)
max l1 norm bit: tensor(13., device='cuda:0')
total ok
