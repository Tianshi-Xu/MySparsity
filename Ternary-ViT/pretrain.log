2024-01-30 10:05:53,837 - train - INFO - aa: rand-m9-mstd0.5-inc1
amp: true
apex_amp: false
aq_asym: false
aq_bitw: null
aq_enable: false
aq_mode: lsq
aq_neg: null
aq_pos: null
as_enable: false
as_mode: Identity
as_patterns: '1:1'
aug_splits: 0
batch_size: 256
bn_eps: null
bn_momentum: null
bn_tf: false
channels_last: false
checkpoint_hist: 5
clip_grad: null
clip_mode: norm
color_jitter: 0.4
cooldown_epochs: 10
crop_pct: 1.0
cutmix: 1.0
cutmix_minmax: null
data_dir: /home/xts/code/dataset/cifar10
dataset: torch/cifar10
decay_epochs: 30
decay_rate: 0.1
dist_bn: ''
distributed: false
down_block_type: default
drop: 0.0
drop_block: null
drop_connect: null
drop_path: null
epoch_repeats: 0.0
epochs: 300
eval_metric: top1
experiment: ''
finetune: false
gp: null
hflip: 0.5
img_size: 32
initial_checkpoint: ''
input_size: null
interpolation: bicubic
jsd: false
kd_alpha: 4
kd_type: last
lasso_alpha: 0
local_rank: 0
log_interval: 50
log_wandb: false
lr: 0.00055
lr_cycle_limit: 1
lr_cycle_mul: 1.0
lr_noise: null
lr_noise_pct: 0.67
lr_noise_std: 1.0
mean:
- 0.4914
- 0.4822
- 0.4465
min_lr: 1.0e-05
mixup: 0.8
mixup_mode: batch
mixup_off_epoch: 175
mixup_prob: 1.0
mixup_switch_prob: 0.5
model: pretrain_cifar_cir_nas_mobilenetv2
model_ema: false
model_ema_decay: 0.9998
model_ema_force_cpu: false
momentum: 0.9
native_amp: false
no_aug: false
no_bn: false
no_prefetcher: false
no_resume_opt: false
num_classes: 10
opt: adamw
opt_betas: null
opt_eps: null
output: ''
patience_epochs: 10
pin_mem: false
post_res_bn: false
pretrain: true
pretrained: false
qmodules: []
quant_teacher: false
ratio:
- 0.75
- 1.3333333333333333
recount: 1
recovery_interval: 0
remode: pixel
replace_ln_by_bn: false
replace_relu: false
reprob: 0.25
resplit: false
resq_asym: false
resq_bitw: null
resq_enable: false
resq_mode: lsq
resq_modules: []
resq_neg: null
resq_pos: null
resume: ''
save_images: false
scale:
- 0.8
- 1.0
sched: cosine
seed: 42
smoothing: 0.1
split_bn: false
start_epoch: null
std:
- 0.247
- 0.2435
- 0.2616
sync_bn: false
teacher: resnet101
teacher_checkpoint: ''
torchscript: false
train_interpolation: random
train_split: train
tta: 0
use_bn: true
use_distill_head: false
use_dual_skip: false
use_kd: false
use_layer_scale: false
use_multi_epochs_loader: false
use_relu: false
use_skip: false
use_token_kd: false
val_split: validation
validation_batch_size_multiplier: 1
vflip: 0.0
warmup_epochs: 10
warmup_lr: 1.0e-05
weight_decay: 0.06
workers: 32
wq_asym: false
wq_bitw: null
wq_enable: false
wq_mode: LSQ
wq_neg: null
wq_per_channel: false
wq_pos: null
ws_enable: false
ws_mode: Identity
ws_patterns: '1:1'

2024-01-30 10:05:53,837 - train - INFO - Training with a single process on 1 GPUs.
2024-01-30 10:05:53,943 - train - INFO - Model CirNasMobileNetV2(
  (features): Sequential(
    (0): Sequential(
      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
    )
    (1): CirNasInvertedResidual(
      (conv): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (7): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (8): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (9): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (10): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (11): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (12): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (13): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (14): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)
        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (15): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (16): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (17): CirNasInvertedResidual(
      (conv): Sequential(
        (0): LearnableCir()
        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): LearnableCir()
        (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (18): Sequential(
      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
    )
  )
  (classifier): Sequential(
    (0): Dropout(p=0.2, inplace=False)
    (1): Linear(in_features=1280, out_features=10, bias=True)
  )
)
pretrain: True
fine-tune: False
2024-01-30 10:05:53,944 - train - INFO - Model pretrain_cifar_cir_nas_mobilenetv2 created, param count:2236842
2024-01-30 10:05:54,988 - train - INFO - Using native Torch AMP. Training in mixed precision.
2024-01-30 10:05:54,988 - train - INFO - Scheduled epochs: 310
2024-01-30 10:05:56,375 - train - INFO - Trainer transform: Compose(
    RandomResizedCropAndInterpolation(size=(32, 32), scale=(0.8, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear bicubic)
    RandomHorizontalFlip(p=0.5)
    RandAugment(n=2, ops=
	AugmentOp(name=AutoContrast, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=Equalize, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=Invert, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=Rotate, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=PosterizeIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=SolarizeIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=SolarizeAdd, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ColorIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ContrastIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=BrightnessIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=SharpnessIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ShearX, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ShearY, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=TranslateXRel, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=TranslateYRel, p=0.5, m=9, mstd=0.5))
    <timm.data.transforms.ToNumpy object at 0x7fa0cd9a6070>
)
2024-01-30 10:05:56,376 - train - INFO - Validate transform: Compose(
    Resize(size=32, interpolation=bicubic, max_size=None, antialias=warn)
    CenterCrop(size=(32, 32))
    <timm.data.transforms.ToNumpy object at 0x7fa0cda00d00>
)
2024-01-30 10:05:56,376 - train - INFO - Train loss SoftTargetCrossEntropy()
2024-01-30 10:06:01,095 - train - INFO - Train: 0 [   0/195 (  0%)]  Loss:  2.320761 (2.3208)  Time: 4.716s (4.716s),   54.28/s  (4.716s,   54.28/s)  LR: 1.000e-05  Data: 1.090 (1.090)
2024-01-30 10:06:03,550 - train - INFO - Train: 0 [  50/195 ( 26%)]  Loss:  2.309097 (2.3111)  Time: 0.051s (7.170s), 5054.97/s  (0.141s, 1820.81/s)  LR: 1.000e-05  Data: 0.007 (0.030)
2024-01-30 10:06:06,017 - train - INFO - Train: 0 [ 100/195 ( 52%)]  Loss:  2.300024 (2.3086)  Time: 0.049s (9.636s), 5227.82/s  (0.095s, 2683.23/s)  LR: 1.000e-05  Data: 0.009 (0.020)
2024-01-30 10:06:08,318 - train - INFO - Train: 0 [ 150/195 ( 77%)]  Loss:  2.296155 (2.3070)  Time: 0.059s (11.937s), 4327.96/s  (0.079s, 3238.47/s)  LR: 1.000e-05  Data: 0.015 (0.016)
2024-01-30 10:06:10,343 - train - INFO - Train: 0 [ 194/195 (100%)]  Loss:  2.299080 (2.3056)  Time: 0.038s (13.960s), 6787.63/s  (0.072s, 3575.96/s)  LR: 1.000e-05  Data: 0.000 (0.014)
2024-01-30 10:06:10,343 - train - INFO - lasso_alpha:0
2024-01-30 10:06:11,826 - train - INFO - Test: [   0/39]  Time: 1.479 (1.479s) Loss:  2.2871 (2.2871)  Acc@1: 11.7188 (11.7188)  Acc@5: 63.2812 (63.2812)
2024-01-30 10:06:12,604 - train - INFO - Test: [  39/39]  Time: 0.475 (2.257s) Loss:  2.2754 (2.2846)  Acc@1: 18.7500 (13.6800)  Acc@5: 68.7500 (60.9900)
2024-01-30 10:06:13,046 - train - INFO - Train: 1 [   0/195 (  0%)]  Loss:  2.310291 (2.3103)  Time: 0.348s (0.348s),  736.17/s  (0.348s,  736.17/s)  LR: 6.400e-05  Data: 0.287 (0.287)
